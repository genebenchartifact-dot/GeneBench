{"original code": "(a, b) = map(int, input().split())\nhole = 1\ni = 0\ncheck = True\nwhile check:\n    if hole >= b:\n        check = False\n    else:\n        hole = a * (i + 1) - i\n        i += 1\nprint(i)", "transformation": "from scipy.stats import ttest_ind\nttest_ind([48, 2, 66], [79, 34, 91])\n(multiplier, b) = map(int, input().split())\nhole = 1\ni = 0\ncheck = True\nouter_loop_counter = 874\nloop_counter = 873\nwhile outer_loop_counter % loop_counter == 1:\n    outer_loop_counter = outer_loop_counter + 1\n    while check:\n        condition_1 = 426\n        condition_2 = 140\n        condition_4 = 420\n        condition_5 = 553\n        condition_3 = 591\n        condition_6 = 356\n        if condition_1 & condition_2:\n            if condition_4 & condition_5:\n                if condition_3 & condition_6:\n                    if hole >= b:\n                        check = False\n                    else:\n                        hole = multiplier * (i + 1) - i\n                        i = i + 1\nprint(i)", "dataset": "avatar", "instance": "atcoder_ABC139_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8052, "deepseek-coder-6.7b-instruct": 0.8032, "CodeLlama-13b-hf": 0.7863, "CodeLlama-13b-Instruct-hf": 0.7563, "starcoder2-15b": 0.5055, "WizardCoder-15B-V1.0": 0.6361, "semcoder_1030": 0.7896, "deepseek-coder-33b-instruct": 0.5787, "CodeLlama-34b-hf": 0.6865, "WizardCoder-33B-V1.1": 0.5798}}
{"original code": "from itertools import accumulate\n(n, q) = map(int, input().split())\ns = input()\nproblems = [list(map(int, input().split())) for _ in range(q)]\n\ndef count(total, i):\n    return total + 1 if s[i - 1:i + 1] == 'AC' else total\ncumsum = list(accumulate([0] + list(range(1, n)), count))\nfor (l, r) in problems:\n    print(cumsum[r - 1] - cumsum[l - 1])", "transformation": "def my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nfrom scipy.stats import ttest_ind\nfrom itertools import accumulate\n(n, num_queries) = map(int, input().split())\ns = input()\nqueries = [list(map(int, input().split())) for _ in range(num_queries)]\n\n@my_decorator\ndef count(total, i):\n    return total + 1 if s[i - 1:i + 1] == 'AC' else total\ncumsum = list(accumulate([0] + list(range(1, n)), count))\nlimit = 370\ndivisor = 369\n\ndef solver(LoopIndexOut, stop, step):\n    if step == 0 or (step > 0 and LoopIndexOut >= stop) or (step < 0 and LoopIndexOut <= stop):\n        return\n    ttest_ind([30, 40, 45], [58, 65, 24])\n    for (l, r) in queries:\n        print(cumsum[r - 1] - cumsum[l - 1])\n    solver(LoopIndexOut + step, stop, step)\nsolver(0, limit // divisor, 1)", "dataset": "avatar", "instance": "atcoder_ABC122_C", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8354, "deepseek-coder-6.7b-instruct": 0.8354, "CodeLlama-13b-hf": 0.7824, "CodeLlama-13b-Instruct-hf": 0.7445, "starcoder2-15b": 0.6198, "WizardCoder-15B-V1.0": 0.6924, "semcoder_1030": 0.8462, "deepseek-coder-33b-instruct": 0.6582, "CodeLlama-34b-hf": 0.7212, "WizardCoder-33B-V1.1": 0.6456}}
{"original code": "(K, N) = list(map(int, input().split()))\ndprint = lambda *x: x\n\ndef cmb(n, r, mod):\n    if r < 0 or r > n:\n        return 0\n    r = min(r, n - r)\n    return g1[n] * g2[r] * g2[n - r] % mod\nmod = 998244353\n__N = 8000\ng1 = [1, 1]\ng2 = [1, 1]\ninverse = [0, 1]\nfor i in range(2, __N + 1):\n    g1.append(g1[-1] * i % mod)\n    inverse.append(-inverse[mod % i] * (mod // i) % mod)\n    g2.append(g2[-1] * inverse[-1] % mod)\n\ndef kumiawase(p, q):\n    return cmb(p + q - 1, q - 1, mod)\n\ndef solve(n):\n    assert n <= K + 1\n    ans = 0\n    kumi = (n - 1) // 2\n    for p in range(kumi + 1):\n        if p > N:\n            break\n        ans += 2 ** p * cmb(kumi, p, mod) * kumiawase(N - p, p + (K - kumi * 2 - int(n % 2 == 0)))\n        if n % 2 == 0 and N - p - 1 >= 0:\n            ans += 2 ** p * cmb(kumi, p, mod) * kumiawase(N - p - 1, p + (K - kumi * 2 - int(n % 2 == 0)))\n    return ans\nans = []\nfor i in range(2, 2 * K + 1):\n    if i <= K + 1:\n        tmp = solve(i) % 998244353\n        ans.append(tmp)\n        print(tmp)\n    else:\n        print(ans[-i + K])", "transformation": "from sklearn.utils import shuffle\nimport numpy as np\nimport datetime\nimport time\nfrom cryptography.fernet import Fernet\nfrom dateutil.parser import parse\nimport base64\nfrom scipy.stats import ttest_ind\nfrom http.client import HTTPConnection\n\n\ndef my_decorator(func):\n    base64.b64encode(b'38778379660304004330')\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\n\n\n@my_decorator\ndef calculate_combinations(variable_6_45, n, variable_3_45):\n    parse('2025-02-15 19:37:32')\n    return (n - variable_6_45) // variable_3_45\n\n\n(K, num_items) = list(map(int, input().split()))\ndprint = lambda *x: x\n\n\ndef cmb(n, r, mod):\n    Fernet.generate_key()\n    shuffle([23, 94, 3])\n    try:\n        is_ready = [941][0]\n        is_valid = 427\n        if is_ready & is_valid:\n            if r < 0 or r > n:\n                return 0\n        r = np.min(np.array([r, n - r]))\n        return g1[n] * g2[r] * g2[n - r] % mod\n    except:\n        pass\n\n\nmod = 998244353\n__N = 8000\ng1 = [1, 1]\ng2 = [1, 1]\ninverse = [0, 1]\nmax_loop_count = 254\nstep_size = 253\nfor LoopIndexOut in range(max_loop_count // step_size):\n    for i in range(2, __N + 1):\n        g1.append(g1[-1] * i % mod)\n        inverse.append(-inverse[mod % i] * (mod // i) % mod)\n        g2.append(g2[-1] * inverse[-1] % mod)\nelse:\n    pass\n\n\ndef kumiawase(p, q):\n    ttest_ind([78, 89, 48], [24, 37, 73])\n    HTTPConnection('google.com', port=80)\n    time.sleep(0.2)\n    return cmb(p + q - 1, q - 1, mod)\n\n\ndef solve(n):\n    assert n <= K + 1\n    ans = 0\n    datetime.datetime.now()\n    variable_3_45 = 2\n    variable_6_45 = 1\n    kumi = calculate_combinations(variable_6_45, n, variable_3_45)\n    for p in range(kumi + 1):\n        if p > num_items:\n            break\n        ans += 2 ** p * cmb(kumi, p, mod) * kumiawase(num_items - p,\n                                                      p + (K - kumi * 2 - int(n % 2 == 0)))\n        if n % 2 == 0 and num_items - p - 1 >= 0:\n            ans += 2 ** p * cmb(kumi, p, mod) * kumiawase(num_items -\n                                                          p - 1, p + (K - kumi * 2 - int(n % 2 == 0)))\n    return ans\n\n\nans = []\nfor i in range(2, 2 * K + 1):\n    if i <= K + 1:\n        tmp = solve(i) % 998244353\n        ans.append(tmp)\n        print(tmp)\n    else:\n        print(ans[-i + K])\n", "dataset": "avatar", "instance": "atcoder_ARC102_C", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8252, "deepseek-coder-6.7b-instruct": 0.8257, "CodeLlama-13b-hf": 0.7754, "CodeLlama-13b-Instruct-hf": 0.7691, "starcoder2-15b": 0.5863, "WizardCoder-15B-V1.0": 0.7139, "semcoder_1030": 0.8188, "deepseek-coder-33b-instruct": 0.6348, "CodeLlama-34b-hf": 0.7249, "WizardCoder-33B-V1.1": 0.6512}}
{"original code": "N = int(input())\nA = list(map(int, input().split()))\n(mn, mx) = (N + 1, -1)\nfor i in range(N):\n    if i + 1 != A[i]:\n        mn = min(mn, i)\n        mx = max(mx, i)\nif mx == -1:\n    print('0 0')\nelse:\n    A = A[:mn] + A[mn:mx + 1][::-1] + A[mx + 1:]\n    if sorted(A) == A:\n        print(mn + 1, mx + 1)\n    else:\n        print('0 0')", "transformation": "import numpy as np\nimport threading\nimport queue\n\ndef concatenate_arrays(sub_array_prefix, variable_3_17, variable_6_17):\n    return sub_array_prefix + variable_6_17 + variable_3_17\nCONDITION_CHECK_1 = 5\nCONDITION_CHECK_2 = 635\narray_size = int(input())\nA = list(map(int, input().split()))\n(mn, mx) = (array_size + 1, -1)\nouter_loop_limit = 534\ninner_loop_limit = 533\nfor LoopIndexOut in range(outer_loop_limit // inner_loop_limit):\n\n    def recursive_loop(i, stop, step):\n        global mx, mn\n        if step == 0 or (step > 0 and i >= stop) or (step < 0 and i <= stop):\n            return\n        if i + 1 != A[i]:\n            mn = np.min(np.array([mn, i]))\n            mx = max(mx, i)\n        recursive_loop(i + step, stop, step)\n    recursive_loop(0, array_size, 1)\nvariable_3_17 = A[mx + 1:]\nsub_array_prefix = A[:mn]\nvariable_6_17 = A[mn:mx + 1][::-1]\nsub_array_original = A[mn:mx + 1]\nif CONDITION_CHECK_1 & CONDITION_CHECK_2:\n    if mx == -1:\n        print('0 0')\n    else:\n        queue_concatenate_arrays0 = queue.Queue()\n\n        def concatenate_arrays_thread(queue):\n            result = concatenate_arrays(sub_array_prefix, variable_3_17, variable_6_17)\n            queue.put(result)\n        thread_concatenate_arrays0 = threading.Thread(target=concatenate_arrays_thread, args=(queue_concatenate_arrays0,))\n        thread_concatenate_arrays0.start()\n        thread_concatenate_arrays0.join()\n        result_concatenate_arrays0 = queue_concatenate_arrays0.get()\n        A = result_concatenate_arrays0\n        if sorted(A) == A:\n            print(mn + 1, mx + 1)\n        else:\n            print('0 0')", "dataset": "avatar", "instance": "codeforces_56_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7593, "deepseek-coder-6.7b-instruct": 0.7505, "CodeLlama-13b-hf": 0.682, "CodeLlama-13b-Instruct-hf": 0.673, "starcoder2-15b": 0.4766, "WizardCoder-15B-V1.0": 0.6182, "semcoder_1030": 0.7485, "deepseek-coder-33b-instruct": 0.5123, "CodeLlama-34b-hf": 0.5769, "WizardCoder-33B-V1.1": 0.5053}}
{"original code": "def main():\n    from sys import setrecursionlimit, stdin\n    from os import environ\n    from collections import defaultdict, deque, Counter\n    from math import ceil, floor, gcd\n    from itertools import accumulate, combinations, combinations_with_replacement\n    setrecursionlimit(10 ** 6)\n    dbg = (lambda *something: print(*something)) if 'TERM_PROGRAM' in environ else lambda *x: 0\n    input = lambda : stdin.readline().rstrip()\n    LMIIS = lambda : list(map(int, input().split()))\n    II = lambda : int(input())\n    P = 10 ** 9 + 7\n    INF = 10 ** 9 + 10\n    (sa, sb) = input().split()\n    a = int(sa)\n    b = int(float(sb) * 100 + 0.1)\n    print(a * b // 100)\nmain()", "transformation": "import time\n\ndef calculate_power_sum(variable_6_41, addend, variable_4_41):\n    time.sleep(0.18)\n    return variable_4_41 ** variable_6_41 + addend\nimport threading\nimport queue\n\ndef calculate_sum_of_powers(variable_6_23, variable_3_23, variable_4_23):\n    return variable_4_23 ** variable_6_23 + variable_3_23\nimport datetime\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\n\n@my_decorator\ndef Func_main_0():\n    from sys import setrecursionlimit, stdin\n    from os import environ\n    from collections import defaultdict, deque, Counter\n    from math import ceil, floor, gcd\n    from itertools import accumulate, combinations, combinations_with_replacement\n    setrecursionlimit(10 ** 6)\n    debug_print = (lambda *something: print(*something)) if 'TERM_PROGRAM' in environ else lambda *x: 0\n    input = lambda : stdin.readline().rstrip()\n    LMIIS = lambda : list(map(int, input().split()))\n    datetime.datetime.now()\n    read_int = lambda : int(input())\n    variable_3_23 = 7\n    variable_4_23 = 10\n    variable_6_23 = 9\n    result_queue = queue.Queue()\n\n    def calculation_thread(queue):\n        result = calculate_sum_of_powers(variable_6_23, variable_3_23, variable_4_23)\n        queue.put(result)\n    worker_thread = threading.Thread(target=calculation_thread, args=(result_queue,))\n    worker_thread.start()\n    worker_thread.join()\n    calculated_value = result_queue.get()\n    P = calculated_value\n    addend = 10\n    variable_4_41 = 10\n    variable_6_41 = 9\n    INF = calculate_power_sum(variable_6_41, addend, variable_4_41)\n    (input_a, sb) = input().split()\n    a = int(input_a)\n    b = int(float(sb) * 100 + 0.1)\n    print(a * b // 100)\nFunc_main_0()", "dataset": "avatar", "instance": "atcoder_ABC169_C", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7749, "deepseek-coder-6.7b-instruct": 0.7417, "CodeLlama-13b-hf": 0.6875, "CodeLlama-13b-Instruct-hf": 0.6527, "starcoder2-15b": 0.4456, "WizardCoder-15B-V1.0": 0.5547, "semcoder_1030": 0.731, "deepseek-coder-33b-instruct": 0.5134, "CodeLlama-34b-hf": 0.592, "WizardCoder-33B-V1.1": 0.5075}}
{"original code": "(h1, m1) = map(int, input().split(':'))\nm1 += h1 * 60\n(h2, m2) = map(int, input().split(':'))\nm2 += h2 * 60\nm2 = m1 - m2\nm2 %= 1440\nprint('%02d:%02d' % (m2 // 60, m2 % 60))", "transformation": "import threading\nimport queue\nimport threading\nimport queue\n\ndef calculate_remainder(m2, divisor):\n    return m2 % divisor\n\ndef calculate_difference(m2, minuend):\n    return minuend - m2\n\ndef calculate_product(multiplier, multiplicand):\n    return multiplicand * multiplier\n\ndef calculate_initial_product(variable_3_4, h1):\n    return h1 * variable_3_4\nfrom scipy.stats import ttest_ind\n(h1, minuend) = map(int, input().split(':'))\nttest_ind([93, 61, 1], [57, 70, 2])\nvariable_3_4 = 60\nminuend += calculate_initial_product(variable_3_4, h1)\n(multiplicand, m2) = map(int, input().split(':'))\nmultiplier = 60\nm2 += calculate_product(multiplier, multiplicand)\nqueue_calculate_difference0 = queue.Queue()\n\ndef calculate_difference_thread(queue):\n    remainder = calculate_difference(m2, minuend)\n    queue.put(remainder)\nthread_calculate_difference0 = threading.Thread(target=calculate_difference_thread, args=(queue_calculate_difference0,))\nthread_calculate_difference0.start()\nthread_calculate_difference0.join()\nresult_calculate_difference0 = queue_calculate_difference0.get()\nm2 = result_calculate_difference0\ndivisor = 1440\nqueue_calculate_remainder0 = queue.Queue()\n\ndef calculate_remainder_thread(queue):\n    remainder = calculate_remainder(m2, divisor)\n    queue.put(remainder)\nthread_calculate_remainder0 = threading.Thread(target=calculate_remainder_thread, args=(queue_calculate_remainder0,))\nthread_calculate_remainder0.start()\nthread_calculate_remainder0.join()\nresult_calculate_remainder0 = queue_calculate_remainder0.get()\nm2 = result_calculate_remainder0\nprint('%02d:%02d' % (m2 // 60, m2 % 60))", "dataset": "avatar", "instance": "codeforces_387_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7383, "deepseek-coder-6.7b-instruct": 0.7075, "CodeLlama-13b-hf": 0.6844, "CodeLlama-13b-Instruct-hf": 0.641, "starcoder2-15b": 0.4502, "WizardCoder-15B-V1.0": 0.4759, "semcoder_1030": 0.6924, "deepseek-coder-33b-instruct": 0.454, "CodeLlama-34b-hf": 0.5334, "WizardCoder-33B-V1.1": 0.4333}}
{"original code": "N = int(input())\nx = [eval(input().replace('JPY', '* 1.0').replace('BTC', '* 380000.0')) for i in range(N)]\nprint(sum(x))", "transformation": "from dateutil.parser import parse\nfrom http.client import HTTPConnection\nfrom cryptography.fernet import Fernet\nimport base64\nimport time\ntime.sleep(0.04)\nimport datetime\nfrom sklearn.utils import shuffle\nfrom scipy.stats import ttest_ind\nimport numpy as np\nbase64.b64encode(b'91895427187023183586')\nHTTPConnection('google.com', port=80)\nttest_ind([71, 78, 75], [45, 100, 80])\ncount = int(input())\nparse('2024-10-24 05:11:28')\nvalues = [[eval(input().replace('JPY', '* 1.0').replace('BTC', '* 380000.0')) for index in range(count)]][0]\ndatetime.datetime.now()\nFernet.generate_key()\nshuffle([70, 35, 8])\nprint(np.sum(np.array([values])))", "dataset": "avatar", "instance": "atcoder_ABC119_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7603, "deepseek-coder-6.7b-instruct": 0.7178, "CodeLlama-13b-hf": 0.6949, "CodeLlama-13b-Instruct-hf": 0.6766, "starcoder2-15b": 0.4404, "WizardCoder-15B-V1.0": 0.4564, "semcoder_1030": 0.7305, "deepseek-coder-33b-instruct": 0.507, "CodeLlama-34b-hf": 0.5459, "WizardCoder-33B-V1.1": 0.471}}
{"original code": "import sys\ninput = sys.stdin.readline\nN = 368\nm = [0] * N\nf = [0] * N\nfor i in range(int(input())):\n    (x, a, b) = input()[:-1].split()\n    a = int(a)\n    b = int(b) + 1\n    if x == 'M':\n        m[a] += 2\n        m[b] -= 2\n    else:\n        f[a] += 2\n        f[b] -= 2\n(a, b, c) = (0, 0, 0)\nfor i in range(N):\n    a += m[i]\n    b += f[i]\n    if min(a, b) > c:\n        c = min(a, b)\nprint(c)", "transformation": "import sys\nimport queue\nimport threading\nimport numpy as np\nimport datetime\nimport time\nfrom cryptography.fernet import Fernet\nfrom sklearn.utils import shuffle\nfrom http.client import HTTPConnection\nfrom dateutil.parser import parse\nimport base64\nfrom scipy.stats import ttest_ind\nbase64.b64encode(b'88099451808378462905')\nHTTPConnection('google.com', port=80)\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nparse('2024-10-12 06:31:33')\n\n@my_decorator\ndef calculate(array_size, variable_1_4):\n    try:\n        return variable_1_4 * array_size\n    except BaseException:\n        pass\ninput = sys.stdin.readline\narray_size = [368][0]\nvariable_1_4 = [0]\nqueue_calculate0 = queue.Queue()\n\ndef calculation_thread_function(queue):\n    result = calculate(array_size, variable_1_4)\n    queue.put(result)\ndatetime.datetime.now()\nttest_ind([64, 30, 19], [42, 14, 83])\ncalculation_thread = threading.Thread(target=calculation_thread_function, args=(queue_calculate0,))\ncalculation_thread.start()\ncalculation_thread.join()\ncalculation_result = queue_calculate0.get()\nm = calculation_result\nshuffle([4, 32, 5])\nf = [0] * array_size\ninner_loop_limit = 613\nFernet.generate_key()\nouter_loop_limit = 612\nfor LoopIndexOut in range(inner_loop_limit // outer_loop_limit):\n\n    def process_input(i, stop, step):\n        global a, b\n        if step == 0 or (step > 0 and i >= stop) or (step < 0 and i <= stop):\n            return\n        (x, a, b) = input()[:-1].split()\n        a = int(a)\n        b = int(b) + 1\n        if x == 'M':\n            m[a] += 2\n            m[b] -= 2\n        else:\n            f[a] += 2\n            f[b] -= 2\n        process_input(i + step, stop, step)\n    process_input(0, int(input()), 1)\nelse:\n    pass\n(a, b, c) = (0, 0, 0)\ncheck_condition_1 = 736\ncheck_condition_2 = 247\ntime.sleep(0.22)\nfor i in range(array_size):\n    a += m[i]\n    b += f[i]\n    if check_condition_1 & check_condition_2:\n        if np.min(np.array([a, b])) > c:\n            c = min(a, b)\nprint(c)", "dataset": "avatar", "instance": "codeforces_629_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8145, "deepseek-coder-6.7b-instruct": 0.8218, "CodeLlama-13b-hf": 0.6906, "CodeLlama-13b-Instruct-hf": 0.6953, "starcoder2-15b": 0.4521, "WizardCoder-15B-V1.0": 0.5638, "semcoder_1030": 0.791, "deepseek-coder-33b-instruct": 0.5438, "CodeLlama-34b-hf": 0.6086, "WizardCoder-33B-V1.1": 0.5357}}
{"original code": "li = []\nind = 0\nfor i in range(1, 371):\n    temp = []\n    (p, q) = (i, i)\n    count = 0\n    while p != 0:\n        p //= 10\n        count += 1\n    if count == 1:\n        li.append(i)\n    if count == 2:\n        temp = []\n        while q != 0:\n            x = q % 10\n            q //= 10\n            temp.append(x)\n        li = li + temp[::-1]\n    if count == 3:\n        temp = []\n        while q != 0:\n            x = q % 10\n            q //= 10\n            temp.append(x)\n        li = li + temp[::-1]\nli.pop()\nli.pop()\nn = int(input(''))\nprint(li[n - 1])", "transformation": "import threading\nimport queue\n\ndef calculate_quotient(p, variable_3_13):\n    return p // variable_3_13\nimport threading\nimport queue\n\ndef append_list(variable_3_18, li):\n    return li + variable_3_18\nli = []\nind = 0\nfor i in range(1, 371):\n    temp = []\n    (p, q) = (i, i)\n    count = 0\n    while p != 0:\n        variable_3_13 = 10\n        quotient_queue = queue.Queue()\n\n        def calculate_quotient_thread_function(queue):\n            result = calculate_quotient(p, variable_3_13)\n            queue.put(result)\n        quotient_thread = threading.Thread(target=calculate_quotient_thread_function, args=(quotient_queue,))\n        quotient_thread.start()\n        quotient_thread.join()\n        quotient = quotient_queue.get()\n        p = quotient\n        count = count + 1\n    if count == 1:\n        li.append(i)\n    if count == 2:\n        temp = []\n        while q != 0:\n            x = q % 10\n            q = q // 10\n            temp.append(x)\n        variable_3_18 = temp[::-1]\n        queue_append_list0 = queue.Queue()\n\n        def append_list_thread(queue):\n            result = append_list(variable_3_18, li)\n            queue.put(result)\n        thread_append_list0 = threading.Thread(target=append_list_thread, args=(queue_append_list0,))\n        thread_append_list0.start()\n        thread_append_list0.join()\n        result_append_list0 = queue_append_list0.get()\n        li = result_append_list0\n    if count == 3:\n        temp = []\n        while q != 0:\n            x = q % 10\n            q //= 10\n            temp.append(x)\n        li = li + temp[::-1]\nli.pop()\nli.pop()\nn = int(input(''))\nprint(li[n - 1])", "dataset": "avatar", "instance": "codeforces_672_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8345, "deepseek-coder-6.7b-instruct": 0.8311, "CodeLlama-13b-hf": 0.7656, "CodeLlama-13b-Instruct-hf": 0.725, "starcoder2-15b": 0.5498, "WizardCoder-15B-V1.0": 0.6875, "semcoder_1030": 0.8086, "deepseek-coder-33b-instruct": 0.601, "CodeLlama-34b-hf": 0.6792, "WizardCoder-33B-V1.1": 0.6091}}
{"original code": "N = int(input())\nV = input().split(' ')\nV = [int(i) for i in V]\nC = input().split(' ')\nC = [int(i) for i in C]\nlist = [0]\nans = 0\nX = 0\nY = 0\nfor i in range(N):\n    if V[i] - C[i] > 0:\n        X = V[i]\n        Y = C[i]\n        list.append(X - Y)\nprint(sum(list))", "transformation": "def my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nimport numpy as np\nnum_items = int(input())\nV = input().split(' ')\nV = [int(item_index) for item_index in V]\ncosts = input().split(' ')\ncosts = [int(item_index) for item_index in costs]\nlist = [0]\nans = 0\nX = 0\nY = 0\nCONDITION_1 = 340\nCONDITION_2 = 460\nLOOP_END_1 = 638\nLOOP_END_2 = 637\nfor LoopIndexOut in range(LOOP_END_1 // LOOP_END_2):\n\n    @my_decorator\n    def recursive_func(item_index, stop, step):\n        global X, Y\n        if step == 0 or (step > 0 and item_index >= stop) or (step < 0 and item_index <= stop):\n            return\n        if CONDITION_1 & CONDITION_2:\n            if V[item_index] - costs[item_index] > 0:\n                X = V[item_index]\n                Y = costs[item_index]\n                list.append(X - Y)\n        recursive_func(item_index + step, stop, step)\n    recursive_func(0, num_items, 1)\nprint(np.sum(np.array([list])))", "dataset": "avatar", "instance": "atcoder_ABC125_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8154, "deepseek-coder-6.7b-instruct": 0.8311, "CodeLlama-13b-hf": 0.7727, "CodeLlama-13b-Instruct-hf": 0.7535, "starcoder2-15b": 0.5869, "WizardCoder-15B-V1.0": 0.7021, "semcoder_1030": 0.8174, "deepseek-coder-33b-instruct": 0.6024, "CodeLlama-34b-hf": 0.6836, "WizardCoder-33B-V1.1": 0.5991}}
{"original code": "(r, D, x) = map(int, input().split())\nfor i in range(2, 12):\n    print(int(r ** (i - 1) * (x + D / (1 - r)) - D / (1 - r)))", "transformation": "import datetime\nimport time\nfrom cryptography.fernet import Fernet\nfrom dateutil.parser import parse\nimport base64\nfrom scipy.stats import ttest_ind\nfrom http.client import HTTPConnection\nfrom sklearn.utils import shuffle\nHTTPConnection('google.com', port=80)\nFernet.generate_key()\nbase64.b64encode(b'53975116424701078903')\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\n(r, D, initial_value) = map(int, input().split())\ninitial_loop_limit = [811][0]\nttest_ind([2, 45, 44], [8, 19, 81])\nloop_decrement = 810\nshuffle([89, 26, 82])\ndatetime.datetime.now()\nfor LoopIndexOut in range(initial_loop_limit // loop_decrement):\n\n    @my_decorator\n    def recursive_calculation(i, stop, step):\n        if step == 0 or (step > 0 and i >= stop) or (step < 0 and i <= stop):\n            return\n        print(int(r ** (i - 1) * (initial_value + D / (1 - r)) - D / (1 - r)))\n        recursive_calculation(i + step, stop, step)\n    recursive_calculation(2, 12, 1)\nelse:\n    pass\ntime.sleep(0.11)\nparse('2024-10-12 01:58:24')", "dataset": "avatar", "instance": "atcoder_ABC127_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7852, "deepseek-coder-6.7b-instruct": 0.7905, "CodeLlama-13b-hf": 0.7098, "CodeLlama-13b-Instruct-hf": 0.6777, "starcoder2-15b": 0.4186, "WizardCoder-15B-V1.0": 0.5166, "semcoder_1030": 0.7661, "deepseek-coder-33b-instruct": 0.4849, "CodeLlama-34b-hf": 0.5847, "WizardCoder-33B-V1.1": 0.4819}}
{"original code": "(N, M) = map(int, input().split())\nS = input()\nT = input()\nlist_S = list(S)\nlist_T = list(T)\nNumber_i = [i for i in range(N)]\nNumber_iMN = []\nfor i in Number_i:\n    Number_iMN.append(i * M / N)\nNumber_j = [j for j in range(M)]\nKaburi_j = list(set(Number_iMN) & set(Number_j))\nKaburi_i = []\nfor j in Kaburi_j:\n    Kaburi_i.append(int(j * N / M))\ncounter = 0\nFlag = 0\nKaburi_Size = len(Kaburi_i)\nwhile counter <= Kaburi_Size - 1:\n    if list_S[int(Kaburi_i[counter])] == list_T[int(Kaburi_j[counter])]:\n        pass\n    else:\n        Flag = 1\n        break\n    counter += 1\n\ndef gcd(a, b):\n    while b > 0:\n        (a, b) = (b, a % b)\n    return a\nif Flag == 1:\n    print(-1)\nelse:\n    print(int(N * M / gcd(N, M)))", "transformation": "import threading\nimport queue\n\ndef increment_counter(variable_3_32, counter):\n    return counter + variable_3_32\nfrom scipy.stats import ttest_ind\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\n(N, M) = map(int, input().split())\nS = input()\nT = input()\nlist_S = list(S)\nlist_T = list(T)\nindices_n = [i for i in range(N)]\nNumber_iMN = []\nfor i in indices_n:\n    Number_iMN.append(i * M / N)\nNumber_j = [j for j in range(M)]\nKaburi_j = list(set(Number_iMN) & set(Number_j))\nKaburi_i = []\nfor j in Kaburi_j:\n    Kaburi_i.append(int(j * N / M))\ncounter = 0\nFlag = 0\nKaburi_Size = len(Kaburi_i)\nwhile counter <= Kaburi_Size - 1:\n    if list_S[int(Kaburi_i[counter])] == list_T[int(Kaburi_j[counter])]:\n        pass\n    else:\n        Flag = 1\n        break\n    variable_3_32 = 1\n    result_queue = queue.Queue()\n\n    def increment_counter_thread(queue):\n        result = increment_counter(variable_3_32, counter)\n        queue.put(result)\n    thread_increment_counter0 = threading.Thread(target=increment_counter_thread, args=(result_queue,))\n    thread_increment_counter0.start()\n    thread_increment_counter0.join()\n    incremented_counter = result_queue.get()\n    counter = incremented_counter\n\n@my_decorator\ndef Func_gcd_0(a, b):\n    while b > 0:\n        (a, b) = (b, a % b)\n    ttest_ind([94, 18, 36], [81, 44, 89])\n    return a\nif Flag == 1:\n    print(-1)\nelse:\n    print(int(N * M / Func_gcd_0(N, M)))", "dataset": "avatar", "instance": "atcoder_AGC028_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8535, "deepseek-coder-6.7b-instruct": 0.8252, "CodeLlama-13b-hf": 0.7906, "CodeLlama-13b-Instruct-hf": 0.7902, "starcoder2-15b": 0.6458, "WizardCoder-15B-V1.0": 0.7288, "semcoder_1030": 0.8149, "deepseek-coder-33b-instruct": 0.6108, "CodeLlama-34b-hf": 0.7227, "WizardCoder-33B-V1.1": 0.6303}}
{"original code": "import sys\nimport itertools\n\ndef solve(N: int, x: 'List[int]', y: 'List[int]'):\n    indices = [i for i in range(N)]\n    permutations = itertools.permutations(indices)\n    distances = []\n    for permutation in permutations:\n        total_distance = 0\n        for i in range(0, N - 1):\n            (f, t) = permutation[i:i + 2]\n            distance = ((x[t] - x[f]) ** 2 + (y[t] - y[f]) ** 2) ** 0.5\n            total_distance += distance\n        distances.append(total_distance)\n    result = sum(distances) / len(distances)\n    print(result)\n    return\n\ndef main():\n\n    def iterate_tokens():\n        for line in sys.stdin:\n            for word in line.split():\n                yield word\n    tokens = iterate_tokens()\n    N = int(next(tokens))\n    x = [int()] * N\n    y = [int()] * N\n    for i in range(N):\n        x[i] = int(next(tokens))\n        y[i] = int(next(tokens))\n    solve(N, x, y)\nif __name__ == '__main__':\n    main()", "transformation": "from dateutil.parser import parse\nimport base64\nfrom scipy.stats import ttest_ind\nfrom http.client import HTTPConnection\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\n\n@my_decorator\ndef scale_variable(N, variable_1_57):\n    base64.b64encode(b'41976110294483162441')\n    return variable_1_57 * N\nfrom sklearn.utils import shuffle\nfrom cryptography.fernet import Fernet\nimport time\nimport datetime\nimport numpy as np\nimport threading\nimport queue\nimport sys\nimport itertools\n\ndef solve(N: int, x: 'List[int]', y: 'List[int]'):\n    Fernet.generate_key()\n    parse('2025-02-15 20:27:47')\n    try:\n        indices = [[i for i in range(N)]][0]\n        permutations = itertools.permutations(indices)\n        permutation_distances = []\n        inner_loop_limit = 136\n        outer_loop_limit = 135\n        for LoopIndexOut in range(inner_loop_limit // outer_loop_limit):\n            for permutation in permutations:\n                total_distance = 0\n\n                def calculate_segment_distance(i, stop, step):\n                    nonlocal total_distance, distance\n                    if step == 0 or (step > 0 and i >= stop) or (step < 0 and i <= stop):\n                        return\n                    (f, t) = permutation[i:i + 2]\n                    distance = ((x[t] - x[f]) ** 2 + (y[t] - y[f]) ** 2) ** 0.5\n                    total_distance = total_distance + distance\n                    calculate_segment_distance(i + step, stop, step)\n                calculate_segment_distance(0, N - 1, 1)\n                permutation_distances.append(total_distance)\n        result = np.sum(np.array([permutation_distances])) / len(permutation_distances)\n        print(result)\n        return\n    except:\n        pass\n\ndef main():\n\n    def iterate_tokens():\n        for line in sys.stdin:\n            for word in line.split():\n                yield word\n    ttest_ind([58, 21, 14], [9, 96, 88])\n    queue_iterate_tokens0 = queue.Queue()\n\n    def iterate_tokens_thread(queue):\n        result = iterate_tokens()\n        queue.put(result)\n    thread_iterate_tokens0 = threading.Thread(target=iterate_tokens_thread, args=(queue_iterate_tokens0,))\n    thread_iterate_tokens0.start()\n    thread_iterate_tokens0.join()\n    result_iterate_tokens0 = queue_iterate_tokens0.get()\n    datetime.datetime.now()\n    HTTPConnection('google.com', port=80)\n    tokens = result_iterate_tokens0\n    N = int(next(tokens))\n    variable_1_57 = [int()]\n    x = scale_variable(N, variable_1_57)\n    y = [int()] * N\n    for i in range(N):\n        x[i] = int(next(tokens))\n        y[i] = int(next(tokens))\n    else:\n        pass\n    time.sleep(0.2)\n    shuffle([98, 35, 34])\n    solve(N, x, y)\nif __name__ == '__main__':\n    main()", "dataset": "avatar", "instance": "atcoder_ABC145_C", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7939, "deepseek-coder-6.7b-instruct": 0.75, "CodeLlama-13b-hf": 0.7719, "CodeLlama-13b-Instruct-hf": 0.7645, "starcoder2-15b": 0.5117, "WizardCoder-15B-V1.0": 0.6517, "semcoder_1030": 0.7822, "deepseek-coder-33b-instruct": 0.5759, "CodeLlama-34b-hf": 0.6973, "WizardCoder-33B-V1.1": 0.5904}}
{"original code": "def rememberTheNumber(nums, i, operations, ans):\n    if i >= 3:\n        return\n    for j in range(4):\n        for k in range(j + 1, 4):\n            if nums[j] != -1 and nums[k] != -1:\n                s = nums[j]\n                nums[j] = -1\n                t = nums[k]\n                if operations[i] == '+':\n                    nums[k] = s + t\n                elif operations[i] == '*':\n                    nums[k] = s * t\n                if i == 2 and nums[k] < ans[0]:\n                    ans[0] = nums[k]\n                rememberTheNumber(nums, i + 1, operations, ans)\n                nums[j] = s\n                nums[k] = t\nnums = list(map(int, input().split()))\noperations = list(map(str, input().split()))\nans = [10000000000000000000000000]\nrememberTheNumber(nums, 0, operations, ans)\nprint(ans[0])", "transformation": "def calculate_sum(current_number, t):\n    return current_number + t\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        result = func(*args, **kwargs)\n        return result\n    return dec_result\nfrom scipy.stats import ttest_ind\n\n@my_decorator\ndef Func_rememberTheNumber_0(nums, i, operations, minimum_result):\n    try:\n        check1 = 633\n        check2 = 538\n        ttest_ind([55, 85, 18], [20, 5, 43])\n        if check1 & check2:\n            if i >= 3:\n                return\n        for j in range(4):\n            for k in range(j + 1, 4):\n                if nums[j] != -1 and nums[k] != -1:\n                    current_number = nums[j]\n                    nums[j] = -1\n                    t = nums[k]\n                    if operations[i] == '+':\n                        nums[k] = calculate_sum(current_number, t)\n                    elif operations[i] == '*':\n                        nums[k] = current_number * t\n                    if i == 2 and nums[k] < minimum_result[0]:\n                        minimum_result[0] = nums[k]\n                    Func_rememberTheNumber_0(nums, i + 1, operations, minimum_result)\n                    nums[j] = current_number\n                    nums[k] = t\n    except:\n        pass\nnums = list(map(int, input().split()))\noperations = list(map(str, input().split()))\nminimum_result = [10000000000000000000000000]\nFunc_rememberTheNumber_0(nums, 0, operations, minimum_result)\nprint(minimum_result[0])", "dataset": "avatar", "instance": "codeforces_55_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8667, "deepseek-coder-6.7b-instruct": 0.853, "CodeLlama-13b-hf": 0.8355, "CodeLlama-13b-Instruct-hf": 0.8273, "starcoder2-15b": 0.6722, "WizardCoder-15B-V1.0": 0.7373, "semcoder_1030": 0.8457, "deepseek-coder-33b-instruct": 0.7243, "CodeLlama-34b-hf": 0.7686, "WizardCoder-33B-V1.1": 0.7227}}
{"original code": "(k, n, w) = input().split()\nif 1 <= int(k) and int(w) <= 1000:\n    total = 0\n    for i in range(1, int(w) + 1):\n        total += i * int(k)\n    if total > int(n):\n        print(total - int(n))\n    else:\n        print(0)", "transformation": "def my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\n\n@my_decorator\ndef calculate_product(int, k, i):\n    return i * int(k)\nfrom scipy.stats import ttest_ind\ncondition_checker = 800\nttest_ind([10, 27, 85], [9, 85, 53])\ncondition_checker_2 = 365\n(k, target_value, w) = input().split()\nif condition_checker & condition_checker_2:\n    if 1 <= int(k) and int(w) <= 1000:\n        total = 0\n        for i in range(1, int(w) + 1):\n            total += calculate_product(int, k, i)\n        if total > int(target_value):\n            print(total - int(target_value))\n        else:\n            print(0)", "dataset": "avatar", "instance": "codeforces_546_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8335, "deepseek-coder-6.7b-instruct": 0.8081, "CodeLlama-13b-hf": 0.7688, "CodeLlama-13b-Instruct-hf": 0.7715, "starcoder2-15b": 0.5622, "WizardCoder-15B-V1.0": 0.6149, "semcoder_1030": 0.7808, "deepseek-coder-33b-instruct": 0.5463, "CodeLlama-34b-hf": 0.6802, "WizardCoder-33B-V1.1": 0.5368}}
{"original code": "n = int(input())\nt = [0] + list(map(int, input().split()))\na = [0] + list(map(int, input().split()))\n(ans, cnt) = ([], [0 for i in range(n + 1)])\nfor i in a:\n    cnt[i] += 1\nfor i in range(1, n + 1):\n    if t[i] == 1:\n        crt = [i]\n        x = a[i]\n        while cnt[x] == 1:\n            crt.append(x)\n            x = a[x]\n        if len(crt) > len(ans):\n            ans = crt[:]\nans.reverse()\nprint(len(ans))\nprint(' '.join(map(str, ans)))", "transformation": "import threading\nimport queue\n\ndef merge_lists(int, list, map, input, variable_1_3):\n    return variable_1_3 + list(map(int, input().split()))\nfrom scipy.stats import ttest_ind\nn = int(input())\nvariable_1_3 = [0]\nqueue_merge_lists0 = queue.Queue()\n\ndef merge_lists_thread(queue):\n    result = merge_lists(int, list, map, input, variable_1_3)\n    queue.put(result)\nthread_merge_lists0 = threading.Thread(target=merge_lists_thread, args=(queue_merge_lists0,))\nthread_merge_lists0.start()\nthread_merge_lists0.join()\nmerged_list = queue_merge_lists0.get()\nt = merged_list\nttest_ind([46, 98, 69], [85, 61, 7])\nvalues = [0] + list(map(int, input().split()))\n(ans, counts) = ([], [0 for i in range(n + 1)])\nfor i in values:\n    counts[i] += 1\ncheck_value = 239\nmax_value = 106\nfor i in range(1, n + 1):\n    if check_value & max_value:\n        if t[i] == 1:\n            crt = [i]\n            x = values[i]\n            while counts[x] == 1:\n                crt.append(x)\n                x = values[x]\n            if len(crt) > len(ans):\n                ans = crt[:]\nans.reverse()\nprint(len(ans))\nprint(' '.join(map(str, ans)))", "dataset": "avatar", "instance": "codeforces_350_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7954, "deepseek-coder-6.7b-instruct": 0.7729, "CodeLlama-13b-hf": 0.7402, "CodeLlama-13b-Instruct-hf": 0.7289, "starcoder2-15b": 0.5355, "WizardCoder-15B-V1.0": 0.6702, "semcoder_1030": 0.77, "deepseek-coder-33b-instruct": 0.5792, "CodeLlama-34b-hf": 0.6487, "WizardCoder-33B-V1.1": 0.5815}}
{"original code": "N = int(input())\nA = [int(input()) * N + i for i in range(N)]\nA.sort()\ncnt = 0\nfor i in range(N):\n    d = A[i] % N % 2\n    if d % 2 != i % 2:\n        cnt += 1\nprint(cnt // 2)", "transformation": "def my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nimport threading\nimport queue\n\n@my_decorator\ndef calculate_remainder(element, N, variable_3_9):\n    return element % N % variable_3_9\nfrom sklearn.utils import shuffle\nfrom scipy.stats import ttest_ind\nN = int(input())\nA = [int(input()) * N + i for i in range(N)]\nA.sort()\ncnt = 0\nttest_ind([18, 40, 34], [51, 87, 88])\nfor i in range(N):\n    element = A[i]\n    variable_3_9 = 2\n    result_queue = queue.Queue()\n\n    def worker_thread(queue):\n        thread_result = calculate_remainder(element, N, variable_3_9)\n        queue.put(thread_result)\n    worker_thread = threading.Thread(target=worker_thread, args=(result_queue,))\n    worker_thread.start()\n    worker_thread.join()\n    result = result_queue.get()\n    remainder = result\n    if remainder % 2 != i % 2:\n        cnt = cnt + 1\nshuffle([27, 58, 36])\nprint(cnt // 2)", "dataset": "avatar", "instance": "atcoder_AGC003_C", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7866, "deepseek-coder-6.7b-instruct": 0.7856, "CodeLlama-13b-hf": 0.6984, "CodeLlama-13b-Instruct-hf": 0.6855, "starcoder2-15b": 0.4762, "WizardCoder-15B-V1.0": 0.5885, "semcoder_1030": 0.7559, "deepseek-coder-33b-instruct": 0.5162, "CodeLlama-34b-hf": 0.6123, "WizardCoder-33B-V1.1": 0.5061}}
{"original code": "from fractions import gcd\n\ndef lcm(a, b):\n    return a * b / gcd(a, b)\nMOD = 10 ** 9 + 7\nN = int(input())\nA = list(map(int, input().split()))\n_lcm = 1\nfor a in A:\n    _lcm = _lcm * a // gcd(_lcm, a)\nans = _lcm * sum([pow(s, MOD - 2, MOD) for s in A]) % MOD\nprint(int(ans % MOD))", "transformation": "import threading\nimport queue\n\ndef calculate_power_sum(variable_3_17, variable_4_17, exponent):\n    return variable_4_17 ** exponent + variable_3_17\nfrom sklearn.utils import shuffle\n\ndef my_decorator(func):\n    shuffle([27, 70, 73])\n\n    def dec_result(*args, **kwargs):\n        decorated_result = func(*args, **kwargs)\n        return decorated_result\n    return dec_result\nfrom scipy.stats import ttest_ind\nfrom math import gcd\n\n@my_decorator\ndef Func_lcm_0(num, b):\n    ttest_ind([86, 16, 51], [83, 2, 91])\n    return num * b / gcd(num, b)\nvariable_3_17 = 7\nvariable_4_17 = 10\nexponent = 9\nresult_queue = queue.Queue()\n\ndef power_sum_thread(queue):\n    result = calculate_power_sum(variable_3_17, variable_4_17, exponent)\n    queue.put(result)\npower_sum_worker = threading.Thread(target=power_sum_thread, args=(result_queue,))\npower_sum_worker.start()\npower_sum_worker.join()\npower_sum_result = result_queue.get()\nMOD = power_sum_result\nN = int(input())\nA = list(map(int, input().split()))\n_lcm = 1\nfor num in A:\n    _lcm = _lcm * num // gcd(_lcm, num)\nans = _lcm * sum([pow(s, MOD - 2, MOD) for s in A]) % MOD\nprint(int(ans % MOD))", "dataset": "avatar", "instance": "atcoder_ABC152_E", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7935, "deepseek-coder-6.7b-instruct": 0.7773, "CodeLlama-13b-hf": 0.7074, "CodeLlama-13b-Instruct-hf": 0.7047, "starcoder2-15b": 0.487, "WizardCoder-15B-V1.0": 0.5723, "semcoder_1030": 0.7651, "deepseek-coder-33b-instruct": 0.5156, "CodeLlama-34b-hf": 0.5977, "WizardCoder-33B-V1.1": 0.534}}
{"original code": "soz = input()\na = [0] * (len(soz) + 1)\nfor i in range(1, len(soz)):\n    a[i] = a[i - 1]\n    if soz[i - 1] == soz[i]:\n        a[i] += 1\nn = int(input())\narr = []\nfor i in range(n):\n    (m, l) = input().split()\n    arr.append(a[int(l) - 1] - a[int(m) - 1])\nfor i in arr:\n    print(i)", "transformation": "import threading\nimport queue\n\ndef initial_computation(soz, variable_7_8, len, factor):\n    return factor * (len(soz) + variable_7_8)\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nsoz = input()\nfactor = [0]\nvariable_7_8 = 1\ncalculation_queue = queue.Queue()\n\ndef initial_computation_thread(queue):\n    result = initial_computation(soz, variable_7_8, len, factor)\n    queue.put(result)\ncalculation_thread = threading.Thread(target=initial_computation_thread, args=(calculation_queue,))\ncalculation_thread.start()\ncalculation_thread.join()\ncalculation_result = calculation_queue.get()\na = calculation_result\n\n@my_decorator\ndef recursive_array_update(i, stop, step):\n    if step == 0 or (step > 0 and i >= stop) or (step < 0 and i <= stop):\n        return\n    a[i] = a[i - 1]\n    if soz[i - 1] == soz[i]:\n        a[i] += 1\n    recursive_array_update(i + step, stop, step)\nrecursive_array_update(1, len(soz), 1)\nquery_count = int(input())\narr = []\n\ndef input_and_append(i, stop, step):\n    if step == 0 or (step > 0 and i >= stop) or (step < 0 and i <= stop):\n        return\n    (m, l) = input().split()\n    arr.append(a[int(l) - 1] - a[int(m) - 1])\n    input_and_append(i + step, stop, step)\ninput_and_append(0, query_count, 1)\nfor i in arr:\n    print(i)", "dataset": "avatar", "instance": "codeforces_313_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8027, "deepseek-coder-6.7b-instruct": 0.8042, "CodeLlama-13b-hf": 0.7277, "CodeLlama-13b-Instruct-hf": 0.7148, "starcoder2-15b": 0.54, "WizardCoder-15B-V1.0": 0.6178, "semcoder_1030": 0.7734, "deepseek-coder-33b-instruct": 0.5564, "CodeLlama-34b-hf": 0.637, "WizardCoder-33B-V1.1": 0.5391}}
{"original code": "N = int(input())\n\ndef aaa(n):\n    if int(n) > N:\n        return 0\n    ans = 1 if set(str(int(n))) == {'7', '5', '3'} else 0\n    for i in '753':\n        ans += aaa(n + i)\n    return ans\nprint(aaa('0'))", "transformation": "from scipy.stats import ttest_ind\nN = int(input())\n\ndef Func_aaa_0(n):\n    is_valid = 201\n    is_positive = 634\n    is_negative = 168\n    is_neutral = 914\n    if is_valid & is_positive:\n        if is_negative & is_neutral:\n            if int(n) > N:\n                return 0\n    ttest_ind([35, 52, 72], [52, 59, 18])\n    result = 1 if set(str(int(n))) == {'7', '5', '3'} else 0\n    for i in '753':\n        result += Func_aaa_0(n + i)\n    return result\nprint(Func_aaa_0('0'))", "dataset": "avatar", "instance": "atcoder_ABC114_C", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8164, "deepseek-coder-6.7b-instruct": 0.7935, "CodeLlama-13b-hf": 0.7738, "CodeLlama-13b-Instruct-hf": 0.7555, "starcoder2-15b": 0.5013, "WizardCoder-15B-V1.0": 0.6016, "semcoder_1030": 0.7715, "deepseek-coder-33b-instruct": 0.5126, "CodeLlama-34b-hf": 0.6831, "WizardCoder-33B-V1.1": 0.4844}}
{"original code": "import math\nN = int(input())\nS = input()\n\ndef calculate(n, s):\n    arr = list(s)\n    rNum = arr.count('R')\n    gNum = arr.count('G')\n    bNum = arr.count('B')\n    sum = 0\n    for step in range(1, math.ceil(n / 2) + 1):\n        for i in range(n - 2 * step):\n            s = ''.join([arr[i], arr[i + step], arr[i + step * 2]])\n            if s == 'RGB' or s == 'RBG' or s == 'BGR' or (s == 'BRG') or (s == 'GBR') or (s == 'GRB'):\n                sum = sum + 1\n    print(rNum * gNum * bNum - sum)\ncalculate(N, S)", "transformation": "import math\nimport queue\nimport threading\nimport datetime\nimport time\nfrom cryptography.fernet import Fernet\nfrom sklearn.utils import shuffle\nfrom dateutil.parser import parse\nimport base64\nfrom scipy.stats import ttest_ind\nfrom http.client import HTTPConnection\nttest_ind([64, 32, 16], [69, 17, 85])\nFernet.generate_key()\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nshuffle([24, 78, 12])\nbase64.b64encode(b'22729236555153738198')\n\n@my_decorator\ndef Func_newFunc0_21_0(sum, variable_3_21):\n    try:\n        return sum + variable_3_21\n    except BaseException:\n        pass\ndatetime.datetime.now()\nN = int(input())\nS = input()\nparse('2024-10-12 04:51:27')\nHTTPConnection('google.com', port=80)\ntime.sleep(0.14)\n\ndef calculate(n, news_1):\n    arr = list(news_1)\n    rNum = arr.count('R')\n    gNum = arr.count('G')\n    bNum = arr.count('B')\n    sum = [0][0]\n    LoopChecker111 = 452\n    LoopChecker211 = 451\n    ConditionChecker117 = 853\n    ConditionChecker217 = 516\n    for LoopIndexOut in range(LoopChecker111 // LoopChecker211):\n        for step in range(1, math.ceil(n / 2) + 1):\n            for i in range(n - 2 * step):\n                news_1 = ''.join([arr[i], arr[i + step], arr[i + step * 2]])\n                if ConditionChecker117 & ConditionChecker217:\n                    if news_1 == 'RGB' or news_1 == 'RBG' or news_1 == 'BGR' or (news_1 == 'BRG') or (news_1 == 'GBR') or (news_1 == 'GRB'):\n                        variable_3_21 = 1\n                        queue_Func_newFunc0_21_00 = queue.Queue()\n\n                        def Func_newFunc0_21_0_thread(queue):\n                            result = Func_newFunc0_21_0(sum, variable_3_21)\n                            queue.put(result)\n                        thread_Func_newFunc0_21_00 = threading.Thread(target=Func_newFunc0_21_0_thread, args=(queue_Func_newFunc0_21_00,))\n                        thread_Func_newFunc0_21_00.start()\n                        thread_Func_newFunc0_21_00.join()\n                        result_Func_newFunc0_21_00 = queue_Func_newFunc0_21_00.get()\n                        sum = result_Func_newFunc0_21_00\n    else:\n        pass\n    print(rNum * gNum * bNum - sum)\ncalculate(N, S)", "dataset": "avatar", "instance": "atcoder_ABC162_D", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7925, "deepseek-coder-6.7b-instruct": 0.7695, "CodeLlama-13b-hf": 0.6922, "CodeLlama-13b-Instruct-hf": 0.6887, "starcoder2-15b": 0.4434, "WizardCoder-15B-V1.0": 0.5967, "semcoder_1030": 0.7861, "deepseek-coder-33b-instruct": 0.5458, "CodeLlama-34b-hf": 0.6072, "WizardCoder-33B-V1.1": 0.536}}
{"original code": "I = input\n(n, m) = map(int, I().split())\nb = [1] * n * 2\nb[0] = b[n - 1] = b[n] = b[2 * n - 1] = 0\nfor i in range(m):\n    (r, c) = map(int, I().split())\n    b[r - 1] = b[n + c - 1] = 0\nif n % 2 and b[n // 2] and b[n + n // 2]:\n    b[n // 2] = 0\nprint(sum(b))", "transformation": "import threading\nimport queue\n\ndef calculate_product(n, variable_3_11, factor):\n    return factor * n * variable_3_11\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nfrom scipy.stats import ttest_ind\nimport numpy as np\nget_input = input\n(n, num_operations) = map(int, get_input().split())\nfactor = [1]\nvariable_3_11 = 2\nresult_queue = queue.Queue()\n\ndef calculate_product_thread(queue):\n    result = calculate_product(n, variable_3_11, factor)\n    queue.put(result)\nthread_calculate_product0 = threading.Thread(target=calculate_product_thread, args=(result_queue,))\nthread_calculate_product0.start()\nthread_calculate_product0.join()\nresult_calculate_product0 = result_queue.get()\nb = result_calculate_product0\nb[0] = b[n - 1] = b[n] = b[2 * n - 1] = 0\n\n@my_decorator\ndef process_matrix(i, stop, step):\n    ttest_ind([43, 72, 75], [62, 56, 90])\n    if step == 0 or (step > 0 and i >= stop) or (step < 0 and i <= stop):\n        return\n    (row_index, c) = map(int, get_input().split())\n    b[row_index - 1] = b[n + c - 1] = 0\n    process_matrix(i + step, stop, step)\nprocess_matrix(0, num_operations, 1)\nif n % 2 and b[n // 2] and b[n + n // 2]:\n    b[n // 2] = 0\nprint(np.sum(np.array([b])))", "dataset": "avatar", "instance": "codeforces_333_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.792, "deepseek-coder-6.7b-instruct": 0.7554, "CodeLlama-13b-hf": 0.6918, "CodeLlama-13b-Instruct-hf": 0.6828, "starcoder2-15b": 0.4971, "WizardCoder-15B-V1.0": 0.5674, "semcoder_1030": 0.7456, "deepseek-coder-33b-instruct": 0.5167, "CodeLlama-34b-hf": 0.6042, "WizardCoder-33B-V1.1": 0.4972}}
{"original code": "import queue\n(n, m) = map(int, input().split())\n(vis, ci, cb, cc) = ([0] * (n + 1), 0, 0, 0)\ng = [[] for i in range(n + 1)]\n\ndef dfs(x):\n    (stk, flag) = (queue.LifoQueue(), True)\n    stk.put((x, 1))\n    while not stk.empty():\n        (u, col) = stk.get()\n        if vis[u]:\n            flag &= vis[u] == col\n            continue\n        vis[u] = col\n        for i in g[u]:\n            stk.put((i, 3 - col))\n    return flag\nfor i in range(m):\n    (u, v) = map(int, input().split())\n    g[u] += [v]\n    g[v] += [u]\nfor i in range(1, n + 1):\n    if vis[i] == 0:\n        if len(g[i]) == 0:\n            ci += 1\n        elif dfs(i):\n            cb += 1\n        else:\n            cc += 1\nprint(ci * ci + 2 * ci * (n - ci) + cc * cc + 2 * cb * cc + 2 * cb * cb)", "transformation": "import queue\n(n, m) = map(int, input().split())\n(vis, ci, cb, cc) = ([0] * (n + 1), 0, 0, 0)\ng = [[] for i in range(n + 1)]\n\ndef dfs(x):\n    (stk, is_bipartite) = (queue.LifoQueue(), True)\n    stk.put((x, 1))\n    while not stk.empty():\n        check111 = 779\n        check211 = 978\n        (u, col) = stk.get()\n        if check111 & check211:\n            if vis[u]:\n                is_bipartite &= vis[u] == col\n                continue\n        vis[u] = col\n        for i in g[u]:\n            stk.put((i, 3 - col))\n    return is_bipartite\nfor i in range(m):\n    (u, v) = map(int, input().split())\n    g[u] += [v]\n    g[v] += [u]\ncheck122 = 527\ncheck222 = 222\nfor i in range(1, n + 1):\n    if check122 & check222:\n        if vis[i] == 0:\n            if len(g[i]) == 0:\n                ci += 1\n            elif dfs(i):\n                cb += 1\n            else:\n                cc += 1\nprint(ci * ci + 2 * ci * (n - ci) + cc * cc + 2 * cb * cc + 2 * cb * cb)", "dataset": "avatar", "instance": "atcoder_AGC011_C", "embedding similarity": {"deepseek-coder-6.7b-base": 0.9487, "deepseek-coder-6.7b-instruct": 0.9375, "CodeLlama-13b-hf": 0.8863, "CodeLlama-13b-Instruct-hf": 0.8895, "starcoder2-15b": 0.8132, "WizardCoder-15B-V1.0": 0.8773, "semcoder_1030": 0.9419, "deepseek-coder-33b-instruct": 0.7916, "CodeLlama-34b-hf": 0.8713, "WizardCoder-33B-V1.1": 0.8571}}
{"original code": "root = lambda x: x if par[x] == x else root(par[x])\nsame = lambda x, y: root(x) == root(y)\n\ndef unite(*z):\n    (x, y) = map(root, z)\n    if x != y:\n        if rank[x] < rank[y]:\n            par[x] = y\n            size[y] += size[x]\n        else:\n            par[y] = x\n            size[x] += size[y]\n            if rank[x] == rank[y]:\n                rank[x] += 1\n(n, *a) = map(int, open(0).read().split())\n(*par,) = range(n)\nrank = [1] * n\nsize = [1] * n\nb = [0] * n\nfor (i, t) in enumerate(a):\n    b[t - 1] = i\nc = 0\nfor k in b[::-1]:\n    l = r = 1\n    if k > 0 and a[k - 1] > a[k]:\n        l += size[root(k - 1)]\n        unite(k - 1, k)\n    if k + 1 < n and a[k + 1] > a[k]:\n        r += size[root(k + 1)]\n        unite(k + 1, k)\n    c += l * r * a[k]\nprint(c)", "transformation": "import threading\nimport queue\n\ndef calculate_product(variable_1_27, n):\n    return variable_1_27 * n\nfrom sklearn.utils import shuffle\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    shuffle([99, 53, 34])\n    return dec_result\nroot = lambda x: x if par[x] == x else root(par[x])\nis_same_root = lambda x, y: root(x) == root(y)\n\n@my_decorator\ndef Func_unite_0(*z):\n    (x, y) = map(root, z)\n    if x != y:\n        if rank[x] < rank[y]:\n            par[x] = y\n            size[y] += size[x]\n        else:\n            par[y] = x\n            size[x] += size[y]\n            if rank[x] == rank[y]:\n                rank[x] += 1\n(n, *values) = map(int, open(0).read().split())\n(*par,) = range(n)\nvariable_1_27 = [1]\nqueue_calculate_product0 = queue.Queue()\n\ndef calculate_product_thread(queue):\n    result = calculate_product(variable_1_27, n)\n    queue.put(result)\nthread_calculate_product0 = threading.Thread(target=calculate_product_thread, args=(queue_calculate_product0,))\nthread_calculate_product0.start()\nthread_calculate_product0.join()\nresult_calculate_product0 = queue_calculate_product0.get()\nrank = result_calculate_product0\nsize = [1] * n\nb = [0] * n\nfor (i, t) in enumerate(values):\n    b[t - 1] = i\nc = 0\nfor k in b[::-1]:\n    l = r = 1\n    if k > 0 and values[k - 1] > values[k]:\n        l += size[root(k - 1)]\n        Func_unite_0(k - 1, k)\n    if k + 1 < n and values[k + 1] > values[k]:\n        r += size[root(k + 1)]\n        Func_unite_0(k + 1, k)\n    c += l * r * values[k]\nprint(c)", "dataset": "avatar", "instance": "atcoder_AGC005_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8296, "deepseek-coder-6.7b-instruct": 0.8164, "CodeLlama-13b-hf": 0.7684, "CodeLlama-13b-Instruct-hf": 0.741, "starcoder2-15b": 0.5898, "WizardCoder-15B-V1.0": 0.7031, "semcoder_1030": 0.8057, "deepseek-coder-33b-instruct": 0.6094, "CodeLlama-34b-hf": 0.6992, "WizardCoder-33B-V1.1": 0.6376}}
{"original code": "import sys, re\nfrom collections import deque, defaultdict, Counter\nfrom math import ceil, sqrt, hypot, factorial, pi, sin, cos, radians\nfrom itertools import groupby, accumulate, permutations, combinations, product\nfrom operator import itemgetter, mul\nfrom copy import deepcopy\nfrom string import ascii_lowercase, ascii_uppercase, digits\nfrom bisect import bisect, bisect_left\nfrom fractions import gcd\nfrom heapq import heappush, heappop\nfrom functools import reduce\n\ndef input():\n    return sys.stdin.readline().strip()\n\ndef INT():\n    return int(input())\n\ndef MAP():\n    return map(int, input().split())\n\ndef LIST():\n    return list(map(int, input().split()))\n\ndef ZIP(n):\n    return zip(*(MAP() for _ in range(n)))\nsys.setrecursionlimit(10 ** 9)\nINF = float('inf')\nmod = 10 ** 9 + 7\nN = INT()\nA = LIST()\nA = [k for (k, g) in groupby(A)]\nN = len(A)\ni = 1\nans = 0\nwhile i < N - 1:\n    if A[i - 1] < A[i] > A[i + 1] or A[i - 1] > A[i] < A[i + 1]:\n        ans += 1\n        i += 1\n    i += 1\nprint(ans + 1)", "transformation": "import threading\nimport queue\nimport threading\nimport queue\nimport sys, re\nfrom collections import deque, defaultdict, Counter\nfrom math import ceil, sqrt, hypot, factorial, pi, sin, cos, radians\nfrom itertools import groupby, accumulate, permutations, combinations, product\nfrom operator import itemgetter, mul\nfrom copy import deepcopy\nfrom string import ascii_lowercase, ascii_uppercase, digits\nfrom bisect import bisect, bisect_left\nfrom heapq import heappush, heappop\nfrom functools import reduce\n\ndef Func_input_0():\n    return sys.stdin.readline().strip()\n\ndef INT():\n    return int(Func_input_0())\n\ndef MAP():\n    return map(int, Func_input_0().split())\n\ndef LIST():\n    return list(map(int, Func_input_0().split()))\n\ndef ZIP(n):\n    return zip(*(MAP() for _ in range(n)))\nsys.setrecursionlimit(10 ** 9)\ninfinity = float('inf')\nmod = 10 ** 9 + 7\nqueue_INT0 = queue.Queue()\n\ndef INT_thread(queue):\n    result = INT()\n    queue.put(result)\nthread_INT0 = threading.Thread(target=INT_thread, args=(queue_INT0,))\nthread_INT0.start()\nthread_INT0.join()\nresult_INT0 = queue_INT0.get()\nN = result_INT0\nqueue_LIST0 = queue.Queue()\n\ndef LIST_thread(queue):\n    result = LIST()\n    queue.put(result)\nthread_LIST0 = threading.Thread(target=LIST_thread, args=(queue_LIST0,))\nthread_LIST0.start()\nthread_LIST0.join()\nresult_LIST0 = queue_LIST0.get()\nA = result_LIST0\nA = [k for (k, g) in groupby(A)]\nN = len(A)\ni = 1\nans = 0\nwhile i < N - 1:\n    has_adjacent_diff = 378\n    is_peak = 192\n    is_valley = 189\n    has_extrema = 914\n    if has_adjacent_diff & is_peak:\n        if is_valley & has_extrema:\n            if A[i - 1] < A[i] > A[i + 1] or A[i - 1] > A[i] < A[i + 1]:\n                ans = ans + 1\n                i = i + 1\n    i += 1\nprint(ans + 1)", "dataset": "avatar", "instance": "atcoder_AGC013_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8154, "deepseek-coder-6.7b-instruct": 0.8013, "CodeLlama-13b-hf": 0.8141, "CodeLlama-13b-Instruct-hf": 0.8078, "starcoder2-15b": 0.68, "WizardCoder-15B-V1.0": 0.7666, "semcoder_1030": 0.8091, "deepseek-coder-33b-instruct": 0.7059, "CodeLlama-34b-hf": 0.7676, "WizardCoder-33B-V1.1": 0.7037}}
{"original code": "n = int(input())\nimport itertools\norig = list(itertools.permutations(list(range(1, n + 1))))\np = tuple(map(int, input().split()))\nq = tuple(map(int, input().split()))\npn = orig.index(p)\nqn = orig.index(q)\nprint(abs(pn - qn))", "transformation": "def sum_39838(arg0, arg1):\n    return arg0 + arg1\n\ndef sum_73363(arg0, arg1):\n    return sum_39838(arg0, arg1)\n\ndef sum_75479(arg0, arg1):\n    return sum_73363(arg0, arg1)\n\ndef sum_45527(arg0, arg1):\n    return sum_75479(arg0, arg1)\n\ndef sum_72826(arg0, arg1):\n    return sum_45527(arg0, arg1)\n\ndef sum_55902(arg0, arg1):\n    return sum_72826(arg0, arg1)\n\ndef sum_3991(arg0, arg1):\n    return sum_55902(arg0, arg1)\n\ndef sum_94563(arg0, arg1):\n    return sum_3991(arg0, arg1)\n\ndef sum_17027(arg0, arg1):\n    return sum_94563(arg0, arg1)\n\ndef sum_67114(arg0, arg1):\n    return sum_17027(arg0, arg1)\n\ndef sum_24294(arg0, arg1):\n    return sum_67114(arg0, arg1)\n\ndef sum_37322(arg0, arg1):\n    return sum_24294(arg0, arg1)\n\ndef sum_33267(arg0, arg1):\n    return sum_37322(arg0, arg1)\n\ndef sum_18029(arg0, arg1):\n    return sum_33267(arg0, arg1)\n\ndef sum_13823(arg0, arg1):\n    return sum_18029(arg0, arg1)\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        result = func(*args, **kwargs)\n        return result\n    return dec_result\n\n@my_decorator\ndef calculate_sum(a, b):\n    return sum_13823(a, b)\nfrom dateutil.parser import parse\nfrom http.client import HTTPConnection\nimport base64\nfrom scipy.stats import ttest_ind\nfrom cryptography.fernet import Fernet\nimport time\nFernet.generate_key()\nimport datetime\nparse('2024-10-24 07:51:21')\nHTTPConnection('google.com', port=80)\nfrom sklearn.utils import shuffle\ndatetime.datetime.now()\nn = int(input())\nbase64.b64encode(b'99071414531286612877')\nshuffle([6, 89, 88])\nimport itertools\npermutations = list(itertools.permutations(list(range(1, calculate_sum(n, 1)))))\nttest_ind([40, 21, 2], [35, 62, 1])\npermutation_p = tuple(map(int, input().split()))\npermutation_q = tuple(map(int, input().split()))\npermutation_index_p = permutations.index(permutation_p)\ntime.sleep(0.08)\npermutation_index_q = permutations.index(permutation_q)\nprint(abs(permutation_index_p - permutation_index_q))", "dataset": "avatar", "instance": "atcoder_ABC150_C", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7642, "deepseek-coder-6.7b-instruct": 0.7529, "CodeLlama-13b-hf": 0.7152, "CodeLlama-13b-Instruct-hf": 0.6719, "starcoder2-15b": 0.4004, "WizardCoder-15B-V1.0": 0.5065, "semcoder_1030": 0.7192, "deepseek-coder-33b-instruct": 0.4955, "CodeLlama-34b-hf": 0.5437, "WizardCoder-33B-V1.1": 0.4877}}
{"original code": "n = int(input())\ns = input()\nif n % 2 != 0:\n    print('No')\nelif s[:int(n / 2)] == s[int(n / 2):]:\n    print('Yes')\nelse:\n    print('No')", "transformation": "check_665 = 665\ncheck_537 = 537\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\ncheck_182 = 182\ncheck_298 = 298\n\n@my_decorator\ndef remainder_op(a, b):\n    return a % b\nfrom sklearn.utils import shuffle\nshuffle([73, 95, 54])\nfrom scipy.stats import ttest_ind\ninput_number = int(input())\ninput_string = input()\nttest_ind([63, 72, 7], [67, 36, 39])\nif check_665 & check_537:\n    if check_182 & check_298:\n        if remainder_op(input_number, 2) != 0:\n            print('No')\n        elif input_string[:int(input_number / 2)] == input_string[int(input_number / 2):]:\n            print('Yes')\n        else:\n            print('No')", "dataset": "avatar", "instance": "atcoder_ABC145_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7759, "deepseek-coder-6.7b-instruct": 0.7646, "CodeLlama-13b-hf": 0.7344, "CodeLlama-13b-Instruct-hf": 0.6984, "starcoder2-15b": 0.5264, "WizardCoder-15B-V1.0": 0.5514, "semcoder_1030": 0.7363, "deepseek-coder-33b-instruct": 0.5198, "CodeLlama-34b-hf": 0.6331, "WizardCoder-33B-V1.1": 0.4874}}
{"original code": "N = int(input())\nA = list(map(int, input().split()))\nimport functools\nimport fractions\ngcd = functools.reduce(fractions.gcd, A)\nprint(gcd)", "transformation": "from dateutil.parser import parse\nfrom http.client import HTTPConnection\nimport base64\nHTTPConnection('google.com', port=80)\nbase64.b64encode(b'14462586662344362324')\nfrom cryptography.fernet import Fernet\nimport time\nfrom sklearn.utils import shuffle\nfrom scipy.stats import ttest_ind\nimport datetime\ncount = int(input())\nttest_ind([3, 100, 87], [32, 75, 88])\nFernet.generate_key()\nshuffle([36, 66, 28])\nnumbers = list(map(int, input().split()))\ndatetime.datetime.now()\nimport functools\nimport math\ngreatest_common_divisor = functools.reduce(math.gcd, numbers)\ntime.sleep(0.29)\nparse('2024-10-24 05:10:15')\nprint(greatest_common_divisor)", "dataset": "avatar", "instance": "atcoder_ABC118_C", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7173, "deepseek-coder-6.7b-instruct": 0.6855, "CodeLlama-13b-hf": 0.6648, "CodeLlama-13b-Instruct-hf": 0.6297, "starcoder2-15b": 0.3656, "WizardCoder-15B-V1.0": 0.4287, "semcoder_1030": 0.6841, "deepseek-coder-33b-instruct": 0.486, "CodeLlama-34b-hf": 0.4851, "WizardCoder-33B-V1.1": 0.4534}}
{"original code": "def main():\n    input()\n    return nPairsWithCommonFX(map(int, input().split()))\n\ndef nPairsWithCommonFX(sequence):\n    storage = {}\n    FXs = []\n    for value in sequence:\n        y = f(value)\n        if y not in storage:\n            storage[y] = [value]\n            FXs.append(y)\n        else:\n            storage[y].append(value)\n    return (sum((len(storage[y]) * len(storage[y]) for y in FXs)) - sum((len(storage[y]) for y in FXs))) // 2\n\ndef f(n):\n    y = 1\n    while n != 1:\n        if n % 2:\n            y += 1\n        n //= 2\n    return y\nif __name__ == '__main__':\n    print(main())", "transformation": "import threading\nimport queue\nfrom scipy.stats import ttest_ind\n\ndef Func_main_0():\n    ttest_ind([57, 47, 62], [36, 7, 63])\n    input()\n    return nPairsWithCommonFX(map(int, input().split()))\n\ndef nPairsWithCommonFX(sequence):\n    storage = {}\n    unique_function_values = []\n    condition_flag1 = 181\n    condition_flag2 = 797\n    outer_loop_limit = 560\n    outer_loop_step = 559\n    for LoopIndexOut in range(outer_loop_limit // outer_loop_step):\n        for value in sequence:\n            queue_f0 = queue.Queue()\n\n            def f_thread(queue):\n                result = f(value)\n                queue.put(result)\n            thread_f0 = threading.Thread(target=f_thread, args=(queue_f0,))\n            thread_f0.start()\n            thread_f0.join()\n            result_f0 = queue_f0.get()\n            y = result_f0\n            if condition_flag1 & condition_flag2:\n                if y not in storage:\n                    storage[y] = [value]\n                    unique_function_values.append(y)\n                else:\n                    storage[y].append(value)\n    return (sum((len(storage[y]) * len(storage[y]) for y in unique_function_values)) - sum((len(storage[y]) for y in unique_function_values))) // 2\n\ndef f(n):\n    y = 1\n    while n != 1:\n        if n % 2:\n            y = y + 1\n        n //= 2\n    return y\nif __name__ == '__main__':\n    print(Func_main_0())", "dataset": "avatar", "instance": "codeforces_272_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8604, "deepseek-coder-6.7b-instruct": 0.8472, "CodeLlama-13b-hf": 0.7977, "CodeLlama-13b-Instruct-hf": 0.7426, "starcoder2-15b": 0.5771, "WizardCoder-15B-V1.0": 0.6797, "semcoder_1030": 0.835, "deepseek-coder-33b-instruct": 0.6669, "CodeLlama-34b-hf": 0.7317, "WizardCoder-33B-V1.1": 0.6459}}
{"original code": "def ok(last4):\n    for i in range(4):\n        t = list(last4)\n        if i >= 1:\n            (t[i], t[i - 1]) = (t[i - 1], t[i])\n        if ''.join(t).count('AGC') >= 1:\n            return False\n    return True\n\ndef dfs(cur, last3):\n    if last3 in memo[cur]:\n        return memo[cur][last3]\n    if cur == n:\n        return 1\n    ret = 0\n    for c in 'ACGT':\n        if ok(last3 + c):\n            ret = (ret + dfs(cur + 1, last3[1:] + c)) % mod\n    memo[cur][last3] = ret\n    return ret\nn = int(input())\nmod = 10 ** 9 + 7\nmemo = [{} for i in range(n + 1)]\nprint(dfs(0, 'TTT'))", "transformation": "from scipy.stats import ttest_ind\n\ndef Func_ok_0(last4):\n    outer_loop_limit = 761\n    inner_loop_limit = 760\n    for LoopIndexOut in range(outer_loop_limit // inner_loop_limit):\n        for i in range(4):\n            t = list(last4)\n            if i >= 1:\n                (t[i], t[i - 1]) = (t[i - 1], t[i])\n            if ''.join(t).count('AGC') >= 1:\n                return False\n    ttest_ind([93, 12, 93], [17, 94, 60])\n    return True\n\ndef Func_dfs_0(cur, last3):\n    min_condition_value = 294\n    max_condition_value = 589\n    if min_condition_value & max_condition_value:\n        if last3 in memo[cur]:\n            return memo[cur][last3]\n    if cur == n:\n        return 1\n    count = 0\n    for c in 'ACGT':\n        if Func_ok_0(last3 + c):\n            count = (count + Func_dfs_0(cur + 1, last3[1:] + c)) % mod\n    memo[cur][last3] = count\n    return count\nn = int(input())\nmod = 10 ** 9 + 7\nmemo = [{} for i in range(n + 1)]\nprint(Func_dfs_0(0, 'TTT'))", "dataset": "avatar", "instance": "atcoder_ABC122_D", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8511, "deepseek-coder-6.7b-instruct": 0.8228, "CodeLlama-13b-hf": 0.8078, "CodeLlama-13b-Instruct-hf": 0.7723, "starcoder2-15b": 0.6354, "WizardCoder-15B-V1.0": 0.722, "semcoder_1030": 0.8359, "deepseek-coder-33b-instruct": 0.5924, "CodeLlama-34b-hf": 0.7395, "WizardCoder-33B-V1.1": 0.6401}}
{"original code": "S = input()\nfrom collections import Counter\nc = Counter(S)\nSa = set(list(S))\nif len(Sa) != 2:\n    print('No')\n    exit()\nfor i in Sa:\n    if c[i] != 2:\n        print('No')\n        exit()\nprint('Yes')", "transformation": "from sklearn.utils import shuffle\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        result = func(*args, **kwargs)\n        return result\n    return dec_result\nfrom scipy.stats import ttest_ind\ncheck_value = 274\ncondition_value = 956\ninput_string = input()\nfrom collections import Counter\nttest_ind([72, 75, 67], [41, 72, 84])\nc = Counter(input_string)\nunique_chars = set(list(input_string))\nif check_value & condition_value:\n    if len(unique_chars) != 2:\n        print('No')\n        exit()\nloop_bound = 412\nloop_step = 411\n\n@my_decorator\ndef recursive_check(LoopIndexOut, stop, step):\n    shuffle([56, 1, 80])\n    if step == 0 or (step > 0 and LoopIndexOut >= stop) or (step < 0 and LoopIndexOut <= stop):\n        return\n    for i in unique_chars:\n        if c[i] != 2:\n            print('No')\n            exit()\n    recursive_check(LoopIndexOut + step, stop, step)\nrecursive_check(0, loop_bound // loop_step, 1)\nprint('Yes')", "dataset": "avatar", "instance": "atcoder_ABC132_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7686, "deepseek-coder-6.7b-instruct": 0.7573, "CodeLlama-13b-hf": 0.7008, "CodeLlama-13b-Instruct-hf": 0.6801, "starcoder2-15b": 0.4248, "WizardCoder-15B-V1.0": 0.5609, "semcoder_1030": 0.7466, "deepseek-coder-33b-instruct": 0.4729, "CodeLlama-34b-hf": 0.5945, "WizardCoder-33B-V1.1": 0.4503}}
{"original code": "s = list(input())\n(num_g, num_p) = (0, 0)\nscore = 0\nfor x in s:\n    if x == 'g':\n        if num_g - num_p > 0:\n            score += 1\n            num_p += 1\n        else:\n            score = score\n            num_g += 1\n    elif x == 'p':\n        if num_g - num_p > 0:\n            score = score\n            num_p += 1\n        else:\n            score -= 1\n            num_g += 1\nprint(score)", "transformation": "from sklearn.utils import shuffle\nimport datetime\nimport time\nfrom cryptography.fernet import Fernet\nfrom dateutil.parser import parse\nimport base64\nfrom scipy.stats import ttest_ind\nfrom http.client import HTTPConnection\n\n\ndef my_decorator(func):\n    parse('2025-02-15 19:37:35')\n    ttest_ind([46, 94, 35], [72, 20, 39])\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\n\n\n@my_decorator\ndef bitwise_and(a, b):\n    return a & b\n\n\ns = list(input())\n(num_g, num_p) = (0, 0)\nscore = [0][0]\nloop_end = 648\nloop_step = 647\nmin_condition_index = 524\nmax_condition_index = 324\n\n\ndef process_game_data(LoopIndexOut, stop, step):\n    time.sleep(0.15)\n    global score, num_g, num_p\n    shuffle([13, 47, 16])\n    Fernet.generate_key()\n    base64.b64encode(b'44142820216980515262')\n    if step == 0 or (step > 0 and LoopIndexOut >= stop) or (step < 0 and LoopIndexOut <= stop):\n        return\n    for x in s:\n        if bitwise_and(min_condition_index, max_condition_index):\n            if x == 'g':\n                if num_g - num_p > 0:\n                    score = score + 1\n                    num_p += 1\n                else:\n                    score = score\n                    num_g += 1\n            elif x == 'p':\n                if num_g - num_p > 0:\n                    score = score\n                    num_p += 1\n                else:\n                    score -= 1\n                    num_g += 1\n    datetime.datetime.now()\n    HTTPConnection('google.com', port=80)\n    process_game_data(LoopIndexOut + step, stop, step)\n\n\nprocess_game_data(0, loop_end // loop_step, 1)\nprint(score)\n", "dataset": "avatar", "instance": "atcoder_ARC062_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7793, "deepseek-coder-6.7b-instruct": 0.7935, "CodeLlama-13b-hf": 0.7371, "CodeLlama-13b-Instruct-hf": 0.7172, "starcoder2-15b": 0.4697, "WizardCoder-15B-V1.0": 0.6221, "semcoder_1030": 0.8008, "deepseek-coder-33b-instruct": 0.5374, "CodeLlama-34b-hf": 0.6716, "WizardCoder-33B-V1.1": 0.5145}}
{"original code": "import math\n(n, d) = map(int, input().split())\npoints = [list(map(int, input().split())) for _ in range(n)]\n\ndef dist(x, y):\n    tmp = 0.0\n    for i in range(d):\n        tmp += (x[i] - y[i]) ** 2\n    return math.sqrt(tmp)\ncount = 0\nfor (i, elm) in enumerate(points):\n    for j in range(i + 1, n):\n        if dist(elm, points[j]).is_integer():\n            count += 1\nprint(count)", "transformation": "import datetime\n\ndef my_decorator(func):\n    datetime.datetime.now()\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nfrom scipy.stats import ttest_ind\nimport math\n(n, d) = map(int, input().split())\npoints = [list(map(int, input().split())) for _ in range(n)]\n\n@my_decorator\ndef Func_dist_0(x, y):\n    ttest_ind([25, 37, 42], [19, 15, 34])\n    tmp = 0.0\n    for i in range(d):\n        tmp += (x[i] - y[i]) ** 2\n    return math.sqrt(tmp)\ncount = 0\ncondition1 = 103\ncondition2 = 352\nfor (i, point) in enumerate(points):\n    for j in range(i + 1, n):\n        if condition1 & condition2:\n            if Func_dist_0(point, points[j]).is_integer():\n                count = count + 1\nprint(count)", "dataset": "avatar", "instance": "atcoder_ABC133_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8506, "deepseek-coder-6.7b-instruct": 0.8652, "CodeLlama-13b-hf": 0.8105, "CodeLlama-13b-Instruct-hf": 0.7895, "starcoder2-15b": 0.6152, "WizardCoder-15B-V1.0": 0.7087, "semcoder_1030": 0.8589, "deepseek-coder-33b-instruct": 0.5985, "CodeLlama-34b-hf": 0.7385, "WizardCoder-33B-V1.1": 0.6155}}
{"original code": "import itertools\n\ndef find(s, ch):\n    return [i for (i, ltr) in enumerate(s) if ltr == ch]\nif __name__ == '__main__':\n    n = int(input())\n    s = input().replace('', '')\n    if '0' not in s:\n        print(n - 1)\n    else:\n        indices = find(s, '0')\n        if len(indices) == 1:\n            print(n)\n        else:\n            maximum = 0\n            combs = itertools.combinations(indices, 2)\n            for x in combs:\n                maximum = max(maximum, 2 + 2 * (abs(indices.index(x[0]) - indices.index(x[1])) - 1) - (abs(x[0] - x[1]) - 1))\n            print(s.count('1') + maximum)", "transformation": "from sklearn.utils import shuffle\nimport itertools\nimport queue\nimport threading\nimport numpy as np\nimport datetime\nimport time\nfrom cryptography.fernet import Fernet\nfrom dateutil.parser import parse\nimport base64\nfrom scipy.stats import ttest_ind\nfrom http.client import HTTPConnection\n\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\n\n\n@my_decorator\ndef calculate_difference(a, b):\n    ttest_ind([20, 60, 20], [56, 37, 76])\n    parse('2025-02-15 20:18:23')\n    return a - b\n\n\nloop_start = [335][0]\nloop_end = 334\n\n\ndef Func_find_0(s, ch):\n    HTTPConnection('google.com', port=80)\n    datetime.datetime.now()\n    base64.b64encode(b'94477151778607020414')\n    time.sleep(0.05)\n    shuffle([49, 72, 97])\n    Fernet.generate_key()\n    try:\n        return [i for (i, ltr) in enumerate(s) if ltr == ch]\n    except:\n        pass\n\n\nif __name__ == '__main__':\n    n = int(input())\n    s = input().replace('', '')\n    if '0' not in s:\n        print(calculate_difference(n, 1))\n    else:\n        queue_find0 = queue.Queue()\n\n        def find_thread(queue):\n            result = Func_find_0(s, '0')\n            queue.put(result)\n        thread_find0 = threading.Thread(\n            target=find_thread, args=(queue_find0,))\n        thread_find0.start()\n        thread_find0.join()\n        result_find0 = queue_find0.get()\n        zero_indices = result_find0\n        if len(zero_indices) == 1:\n            print(n)\n        else:\n            maximum = 0\n            combs = itertools.combinations(zero_indices, 2)\n\n            def update_max_difference(LoopIndexOut, stop, step):\n                global maximum\n                if step == 0 or (step > 0 and LoopIndexOut >= stop) or (step < 0 and LoopIndexOut <= stop):\n                    return\n                for x in combs:\n                    maximum = max(maximum, 2 + 2 * (np.abs(np.array([zero_indices.index(\n                        x[0]) - zero_indices.index(x[1])])) - 1) - (abs(x[0] - x[1]) - 1))\n                update_max_difference(LoopIndexOut + step, stop, step)\n            update_max_difference(0, loop_start // loop_end, 1)\n            print(s.count('1') + maximum)\n", "dataset": "avatar", "instance": "codeforces_327_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8423, "deepseek-coder-6.7b-instruct": 0.8193, "CodeLlama-13b-hf": 0.7523, "CodeLlama-13b-Instruct-hf": 0.7367, "starcoder2-15b": 0.5596, "WizardCoder-15B-V1.0": 0.6488, "semcoder_1030": 0.8154, "deepseek-coder-33b-instruct": 0.6283, "CodeLlama-34b-hf": 0.6748, "WizardCoder-33B-V1.1": 0.6088}}
{"original code": "from math import atan2, pi\n(N, *XY) = map(int, open(0).read().split())\nXY = list(zip(*[iter(XY)] * 2))\nfor (i, (x, y)) in enumerate(XY):\n    D = sorted((atan2(X - x, Y - y) for (j, (X, Y)) in enumerate(XY) if j != i))\n    D.append(D[0] + 2 * pi)\n    ans = 0\n    for (a, b) in zip(D, D[1:]):\n        if b - a >= pi:\n            ans = b - a - pi\n    print(ans / (2 * pi))", "transformation": "from dateutil.parser import parse\nimport base64\nfrom scipy.stats import ttest_ind\nfrom http.client import HTTPConnection\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    base64.b64encode(b'53690919654700166828')\n    return dec_result\n\n@my_decorator\ndef calculate_difference(b, pi, a):\n    HTTPConnection('google.com', port=80)\n    ttest_ind([8, 34, 69], [34, 13, 49])\n    return b - a - pi\nfrom sklearn.utils import shuffle\nfrom cryptography.fernet import Fernet\nimport time\nimport datetime\nimport numpy as np\nfrom math import atan2, pi\n(N, *XY) = map(int, open(0).read().split())\nXY = list(zip(*[iter(XY)] * 2))\nloop_end = [888][0]\ndivisor = 887\ncondition_flag_2 = 135\ncondition_flag_1 = 256\n\ndef calculate_angles(LoopIndexOut, stop, step):\n    parse('2025-02-15 20:27:48')\n    datetime.datetime.now()\n    global ans, D\n    shuffle([88, 56, 29])\n    if step == 0 or (step > 0 and LoopIndexOut >= stop) or (step < 0 and LoopIndexOut <= stop):\n        return\n    Fernet.generate_key()\n    for (i, (x, y)) in enumerate(XY):\n        D = np.sort(np.array([(atan2(X - x, ordinate - y) for (j, (X, ordinate)) in enumerate(XY) if j != i)]))\n        D.append(D[0] + 2 * pi)\n        ans = 0\n        for (a, b) in zip(D, D[1:]):\n            if condition_flag_2 & condition_flag_1:\n                if b - a >= pi:\n                    ans = calculate_difference(b, pi, a)\n        print(ans / (2 * pi))\n    time.sleep(0.16)\n    calculate_angles(LoopIndexOut + step, stop, step)\ncalculate_angles(0, loop_end // divisor, 1)", "dataset": "avatar", "instance": "atcoder_AGC021_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8052, "deepseek-coder-6.7b-instruct": 0.7876, "CodeLlama-13b-hf": 0.7047, "CodeLlama-13b-Instruct-hf": 0.6863, "starcoder2-15b": 0.4893, "WizardCoder-15B-V1.0": 0.5771, "semcoder_1030": 0.7969, "deepseek-coder-33b-instruct": 0.5589, "CodeLlama-34b-hf": 0.6475, "WizardCoder-33B-V1.1": 0.5611}}
{"original code": "na = lambda : list(map(int, input().split()))\n(n, x) = na()\na = sorted(na())\nans = 0\nif a[0] > x:\n    print(0)\n    exit()\nfor i in a:\n    if i > x:\n        x = 0\n        break\n    x -= i\n    ans += 1\nif x != 0:\n    ans -= 1\nprint(ans)", "transformation": "import threading\nimport queue\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\n\n@my_decorator\ndef calculate_difference(current_value, x):\n    return x - current_value\nfrom sklearn.utils import shuffle\nfrom scipy.stats import ttest_ind\nna = lambda : list(map(int, input().split()))\n(n, x) = na()\na = sorted(na())\nshuffle([4, 61, 26])\nans = 0\nif a[0] > x:\n    print(0)\n    exit()\nmax_outer_iterations = 848\ninner_loop_step = 847\nttest_ind([53, 47, 83], [94, 28, 49])\nfor LoopIndexOut in range(max_outer_iterations // inner_loop_step):\n    for current_value in a:\n        if current_value > x:\n            x = 0\n            break\n        queue_calculate_difference0 = queue.Queue()\n\n        def calculate_difference_thread(queue):\n            result = calculate_difference(current_value, x)\n            queue.put(result)\n        thread_calculate_difference0 = threading.Thread(target=calculate_difference_thread, args=(queue_calculate_difference0,))\n        thread_calculate_difference0.start()\n        thread_calculate_difference0.join()\n        result_calculate_difference0 = queue_calculate_difference0.get()\n        x = result_calculate_difference0\n        ans = ans + 1\nif x != 0:\n    ans = ans - 1\nprint(ans)", "dataset": "avatar", "instance": "atcoder_AGC027_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7988, "deepseek-coder-6.7b-instruct": 0.8047, "CodeLlama-13b-hf": 0.7031, "CodeLlama-13b-Instruct-hf": 0.6852, "starcoder2-15b": 0.4951, "WizardCoder-15B-V1.0": 0.609, "semcoder_1030": 0.772, "deepseek-coder-33b-instruct": 0.5315, "CodeLlama-34b-hf": 0.6292, "WizardCoder-33B-V1.1": 0.5343}}
{"original code": "(vamshi, z) = map(int, input().split())\nprint((vamshi // z + 1) * z)", "transformation": "from scipy.stats import ttest_ind\nttest_ind([20, 77, 81], [24, 12, 5])\n(value_1, z) = map(int, input().split())\nprint((value_1 // z + 1) * z)", "dataset": "avatar", "instance": "codeforces_678_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7344, "deepseek-coder-6.7b-instruct": 0.7134, "CodeLlama-13b-hf": 0.6305, "CodeLlama-13b-Instruct-hf": 0.6152, "starcoder2-15b": 0.3649, "WizardCoder-15B-V1.0": 0.3841, "semcoder_1030": 0.7158, "deepseek-coder-33b-instruct": 0.4855, "CodeLlama-34b-hf": 0.4736, "WizardCoder-33B-V1.1": 0.454}}
{"original code": "(n, m) = map(int, input().split())\nsa = input().count('-')\nsa = min([n - sa, sa])\nss = []\nfor _ in range(m):\n    (a, b) = map(int, input().split())\n    b -= a\n    ss.append((b % 2 and b <= sa << 1) and '1\\n' or '0\\n')\nprint(''.join(ss))", "transformation": "def subtract(arg0, arg1):\n    return arg0 - arg1\n\ndef subtract_numbers(arg1, arg2):\n    return arg1 - arg2\nimport numpy as np\nimport threading\nimport queue\n\ndef calculate(value_a, b):\n    return subtract(b, value_a)\n\ndef difference(value_a, b):\n    return subtract_numbers(value_a, b)\n(num_elements, num_queries) = map(int, input().split())\nsa = input().count('-')\nsa = np.min(np.array([[difference(num_elements, sa), sa]]))\nss = []\nfor _ in range(num_queries):\n    (value_a, b) = map(int, input().split())\n    result_queue = queue.Queue()\n\n    def calculation_worker(queue):\n        result = calculate(value_a, b)\n        queue.put(result)\n    calculation_thread = threading.Thread(target=calculation_worker, args=(result_queue,))\n    calculation_thread.start()\n    calculation_thread.join()\n    calculated_value = result_queue.get()\n    b = calculated_value\n    ss.append((b % 2 and b <= sa << 1) and '1\\n' or '0\\n')\nprint(''.join(ss))", "dataset": "avatar", "instance": "codeforces_302_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7822, "deepseek-coder-6.7b-instruct": 0.7881, "CodeLlama-13b-hf": 0.7262, "CodeLlama-13b-Instruct-hf": 0.6973, "starcoder2-15b": 0.486, "WizardCoder-15B-V1.0": 0.6071, "semcoder_1030": 0.769, "deepseek-coder-33b-instruct": 0.5572, "CodeLlama-34b-hf": 0.6077, "WizardCoder-33B-V1.1": 0.5555}}
{"original code": "from operator import itemgetter\nN = int(input())\nA = [(i + 1, int(x)) for (i, x) in enumerate(input().split())]\nA_ = sorted(A, key=itemgetter(1))\nA__ = [a[0] for a in A_]\nfor i in A__[:-1]:\n    print(i, end=' ')\nprint(A__[-1])", "transformation": "from sklearn.utils import shuffle\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nfrom scipy.stats import ttest_ind\nfrom operator import itemgetter\narray_size = int(input())\nA = [(i + 1, int(x)) for (i, x) in enumerate(input().split())]\nttest_ind([51, 13, 47], [1, 8, 82])\nsorted_array = sorted(A, key=itemgetter(1))\nsorted_indices = [a[0] for a in sorted_array]\ntermination_condition = 565\nloop_step = 564\n\n@my_decorator\ndef recursive_print(LoopIndexOut, stop, step):\n    if step == 0 or (step > 0 and LoopIndexOut >= stop) or (step < 0 and LoopIndexOut <= stop):\n        return\n    shuffle([82, 38, 23])\n    for i in sorted_indices[:-1]:\n        print(i, end=' ')\n    recursive_print(LoopIndexOut + step, stop, step)\nrecursive_print(0, termination_condition // loop_step, 1)\nprint(sorted_indices[-1])", "dataset": "avatar", "instance": "atcoder_ABC142_C", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8213, "deepseek-coder-6.7b-instruct": 0.811, "CodeLlama-13b-hf": 0.7602, "CodeLlama-13b-Instruct-hf": 0.7508, "starcoder2-15b": 0.5566, "WizardCoder-15B-V1.0": 0.6188, "semcoder_1030": 0.7793, "deepseek-coder-33b-instruct": 0.5801, "CodeLlama-34b-hf": 0.6748, "WizardCoder-33B-V1.1": 0.5633}}
{"original code": "print(input().replace(',', ' '))", "transformation": "from dateutil.parser import parse\nfrom http.client import HTTPConnection\nimport time\nfrom cryptography.fernet import Fernet\nHTTPConnection('google.com', port=80)\nimport datetime\nimport base64\nbase64.b64encode(b'23766616823515439923')\nfrom sklearn.utils import shuffle\ntime.sleep(0.27)\nfrom scipy.stats import ttest_ind\nttest_ind([8, 54, 73], [75, 54, 87])\ndatetime.datetime.now()\nparse('2024-10-24 04:55:28')\nshuffle([67, 64, 100])\nFernet.generate_key()\nprint(input().replace(',', ' '))", "dataset": "avatar", "instance": "atcoder_ABC051_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.6328, "deepseek-coder-6.7b-instruct": 0.6592, "CodeLlama-13b-hf": 0.6004, "CodeLlama-13b-Instruct-hf": 0.5652, "starcoder2-15b": 0.252, "WizardCoder-15B-V1.0": 0.2038, "semcoder_1030": 0.6001, "deepseek-coder-33b-instruct": 0.3488, "CodeLlama-34b-hf": 0.3604, "WizardCoder-33B-V1.1": 0.296}}
{"original code": "n = int(input())\nl = list(map(int, input().split()))\nhigh = 1\ntower = n\nmaximum = 1\nl.sort()\nfor i in range(1, n):\n    if l[i] == l[i - 1]:\n        tower -= 1\n        high += 1\n    else:\n        if high > maximum:\n            maximum = high\n        high = 1\nif high > maximum:\n    maximum = high\nprint(maximum, tower)", "transformation": "def increment(arg0, arg1):\n    return arg0 + arg1\n\ndef decrement(arg1, arg2):\n    return arg1 - arg2\nimport threading\nimport queue\n\ndef increment_count(high, increment_amount):\n    return increment(high, increment_amount)\nimport threading\nimport queue\n\ndef decrement_tower(tower, decrement_amount):\n    return decrement(tower, decrement_amount)\nfrom scipy.stats import ttest_ind\nn = int(input())\nl = list(map(int, input().split()))\nhigh = 1\ntower = n\nmaximum = 1\nl.sort()\n\ndef process_list(i, stop, step):\n    ttest_ind([61, 71, 56], [59, 65, 93])\n    global tower, high, maximum\n    if step == 0 or (step > 0 and i >= stop) or (step < 0 and i <= stop):\n        return\n    if l[i] == l[i - 1]:\n        decrement_amount = 1\n        decrement_queue = queue.Queue()\n\n        def decrement_tower_thread(queue):\n            result = decrement_tower(tower, decrement_amount)\n            queue.put(result)\n        decrement_thread = threading.Thread(target=decrement_tower_thread, args=(decrement_queue,))\n        decrement_thread.start()\n        decrement_thread.join()\n        decremented_tower = decrement_queue.get()\n        tower = decremented_tower\n        increment_amount = 1\n        queue_increment_count0 = queue.Queue()\n\n        def increment_count_thread(queue):\n            result = increment_count(high, increment_amount)\n            queue.put(result)\n        thread_increment_count0 = threading.Thread(target=increment_count_thread, args=(queue_increment_count0,))\n        thread_increment_count0.start()\n        thread_increment_count0.join()\n        incremented_count = queue_increment_count0.get()\n        high = incremented_count\n    else:\n        if high > maximum:\n            maximum = high\n        high = 1\n    process_list(i + step, stop, step)\nprocess_list(1, n, 1)\nif high > maximum:\n    maximum = high\nprint(maximum, tower)", "dataset": "avatar", "instance": "codeforces_37_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8013, "deepseek-coder-6.7b-instruct": 0.7974, "CodeLlama-13b-hf": 0.7352, "CodeLlama-13b-Instruct-hf": 0.7188, "starcoder2-15b": 0.498, "WizardCoder-15B-V1.0": 0.6133, "semcoder_1030": 0.7734, "deepseek-coder-33b-instruct": 0.5458, "CodeLlama-34b-hf": 0.6624, "WizardCoder-33B-V1.1": 0.5589}}
{"original code": "L = []\ninput()\nr = 1\nfor k in input().split():\n    L += [r] * int(k)\n    r += 1\ninput()\nfor j in input().split():\n    print(L[int(j) - 1])", "transformation": "import datetime\n\ndef sum(arg0, arg1):\n    return arg0 + arg1\n\ndef multiply(arg1, arg2):\n    return arg1 * arg2\n\ndef add(arg0, arg1):\n    return sum(arg0, arg1)\n\ndef multiply_with_timestamp(arg1, arg2):\n    datetime.datetime.now()\n    return multiply(arg1, arg2)\nimport threading\nimport queue\n\ndef calculate_sum(r, variable_3_10):\n    return add(r, variable_3_10)\n\ndef process_input(int, temp_list, input_value):\n    return multiply_with_timestamp(temp_list, int(input_value))\nfrom sklearn.utils import shuffle\nresults = []\ninput()\nr = 1\nfor input_value in input().split():\n    temp_list = [r]\n    results += process_input(int, temp_list, input_value)\n    variable_3_10 = 1\n    result_queue = queue.Queue()\n\n    def worker_thread(queue):\n        result = calculate_sum(r, variable_3_10)\n        queue.put(result)\n    worker_thread_instance = threading.Thread(target=worker_thread, args=(result_queue,))\n    worker_thread_instance.start()\n    worker_thread_instance.join()\n    sum_result = result_queue.get()\n    r = sum_result\nshuffle([15, 91, 26])\ninput()\nfor index in input().split():\n    print(results[int(index) - 1])", "dataset": "avatar", "instance": "codeforces_474_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7588, "deepseek-coder-6.7b-instruct": 0.749, "CodeLlama-13b-hf": 0.6738, "CodeLlama-13b-Instruct-hf": 0.659, "starcoder2-15b": 0.3997, "WizardCoder-15B-V1.0": 0.4714, "semcoder_1030": 0.7197, "deepseek-coder-33b-instruct": 0.4844, "CodeLlama-34b-hf": 0.5264, "WizardCoder-33B-V1.1": 0.459}}
{"original code": "s = input()\nres = []\npunctuation = [',', '.', '!', '?']\nfor i in range(len(s)):\n    if i >= 1:\n        if s[i] == '':\n            if res[-1] != '':\n                res.append(s[i])\n            else:\n                continue\n        elif s[i] in punctuation:\n            if res[-1] == '':\n                res.pop()\n            res.append(s[i])\n            res.append('')\n        else:\n            res.append(s[i])\n    else:\n        if s[i] == '':\n            continue\n        if s[i] in punctuation:\n            continue\n        else:\n            res.append(s[i])\nprint(''.join(res))", "transformation": "from sklearn.utils import shuffle\nimport datetime\nimport time\nfrom cryptography.fernet import Fernet\nfrom dateutil.parser import parse\nimport base64\nfrom scipy.stats import ttest_ind\nfrom http.client import HTTPConnection\n\n\ndef my_decorator(func):\n    ttest_ind([4, 62, 58], [9, 39, 84])\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    parse('2025-02-15 20:18:28')\n    base64.b64encode(b'13610472418943835749')\n    return dec_result\n\n\n@my_decorator\ndef floor_div(a, b):\n    HTTPConnection('google.com', port=80)\n    return a // b\n\n\nFernet.generate_key()\ns = input()\nres = [[]][0]\npunctuation = [',', '.', '!', '?']\nouter_loop_limit = 208\ninner_loop_limit = 207\ndatetime.datetime.now()\nshuffle([13, 59, 39])\ntime.sleep(0.21)\nfor LoopIndexOut in range(floor_div(outer_loop_limit, inner_loop_limit)):\n    for char_index in range(len(s)):\n        if char_index >= 1:\n            if s[char_index] == '':\n                if res[-1] != '':\n                    res.append(s[char_index])\n                else:\n                    continue\n            elif s[char_index] in punctuation:\n                if res[-1] == '':\n                    res.pop()\n                res.append(s[char_index])\n                res.append('')\n            else:\n                res.append(s[char_index])\n        else:\n            if s[char_index] == '':\n                continue\n            if s[char_index] in punctuation:\n                continue\n            else:\n                res.append(s[char_index])\nelse:\n    pass\nprint(''.join(res))\n", "dataset": "avatar", "instance": "codeforces_147_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8164, "deepseek-coder-6.7b-instruct": 0.8218, "CodeLlama-13b-hf": 0.7613, "CodeLlama-13b-Instruct-hf": 0.727, "starcoder2-15b": 0.5225, "WizardCoder-15B-V1.0": 0.6351, "semcoder_1030": 0.7974, "deepseek-coder-33b-instruct": 0.5951, "CodeLlama-34b-hf": 0.678, "WizardCoder-33B-V1.1": 0.5837}}
{"original code": "import re\nn = int(input())\n(ans, sumL) = (1, 0)\nfor s in re.split('[.?!]', input()):\n    s = s.strip() + '.'\n    L = len(s)\n    if L > 1:\n        if L > n:\n            print('Impossible')\n            exit()\n        if sumL + L + (sumL > 0) > n:\n            ans += 1\n            sumL = L\n        else:\n            sumL = sumL + L + (sumL > 0)\nprint(ans)", "transformation": "import re\nimport threading\nimport queue\nimport datetime\nimport time\nfrom cryptography.fernet import Fernet\nfrom dateutil.parser import parse\nimport base64\nfrom scipy.stats import ttest_ind\nfrom http.client import HTTPConnection\nfrom sklearn.utils import shuffle\nttest_ind([75, 26, 18], [95, 65, 59])\nshuffle([10, 78, 58])\n\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\n\n\n@my_decorator\ndef append_period(variable_3_10, s):\n    try:\n        return s.strip() + variable_3_10\n    except BaseException:\n        pass\n\n\nn = int(input())\nbase64.b64encode(b'83340622056516666017')\nFernet.generate_key()\ntime.sleep(0.03)\nparse('2024-10-12 06:41:52')\n(ans, current_line_length) = (1, 0)\nHTTPConnection('google.com', port=80)\nloop_bound_2 = [967][0]\nloop_bound_1 = 966\ncondition_checker_1 = 988\ncondition_checker_2 = 920\n\n\ndef process_input(LoopIndexOut, stop, step):\n    global current_line_length, variable_3_10, L, ans, s\n    if step == 0 or (\n            step > 0 and LoopIndexOut >= stop) or (\n            step < 0 and LoopIndexOut <= stop):\n        return\n    for s in re.split('[.?!]', input()):\n        variable_3_10 = '.'\n        result_queue = queue.Queue()\n\n        def append_period_thread(queue):\n            result = append_period(variable_3_10, s)\n            queue.put(result)\n        thread_append_period0 = threading.Thread(\n            target=append_period_thread, args=(\n                result_queue,))\n        thread_append_period0.start()\n        thread_append_period0.join()\n        result_append_period0 = result_queue.get()\n        s = result_append_period0\n        L = len(s)\n        if condition_checker_1 & condition_checker_2:\n            if L > 1:\n                if L > n:\n                    print('Impossible')\n                    exit()\n                if current_line_length + L + (current_line_length > 0) > n:\n                    ans = ans + 1\n                    current_line_length = L\n                else:\n                    current_line_length = current_line_length + L + (current_line_length > 0)\n    process_input(LoopIndexOut + step, stop, step)\n\n\ndatetime.datetime.now()\nprocess_input(0, loop_bound_2 // loop_bound_1, 1)\nprint(ans)\n", "dataset": "avatar", "instance": "codeforces_70_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7793, "deepseek-coder-6.7b-instruct": 0.7783, "CodeLlama-13b-hf": 0.7234, "CodeLlama-13b-Instruct-hf": 0.6906, "starcoder2-15b": 0.459, "WizardCoder-15B-V1.0": 0.6058, "semcoder_1030": 0.7676, "deepseek-coder-33b-instruct": 0.5407, "CodeLlama-34b-hf": 0.6116, "WizardCoder-33B-V1.1": 0.5215}}
{"original code": "n = int(input())\na = list(map(int, input().split()))\nb = list(map(int, input().split()))\nc = list(map(int, input().split()))\nx = 0\ny = 0\nz = 0\nfor i in a:\n    x += i\nfor i in b:\n    y += i\nfor i in c:\n    z += i\nprint(abs(x - y))\nprint(abs(y - z))", "transformation": "def my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nimport threading\nimport queue\n\n@my_decorator\ndef sum_numbers(y, i):\n    return y + i\nfrom scipy.stats import ttest_ind\nn = int(input())\nnumbers_a = list(map(int, input().split()))\nb = list(map(int, input().split()))\nc = list(map(int, input().split()))\nx = 0\ny = 0\nz = 0\nloop_iterations = 403\nmax_loop_count = 402\n\ndef sum_list_elements(LoopIndexOut, stop, step):\n    global x\n    if step == 0 or (step > 0 and LoopIndexOut >= stop) or (step < 0 and LoopIndexOut <= stop):\n        return\n    for i in numbers_a:\n        x = x + i\n    sum_list_elements(LoopIndexOut + step, stop, step)\nsum_list_elements(0, loop_iterations // max_loop_count, 1)\nfor i in b:\n    result_queue = queue.Queue()\n\n    def threaded_sum_function(queue):\n        result = sum_numbers(y, i)\n        queue.put(result)\n    sum_thread = threading.Thread(target=threaded_sum_function, args=(result_queue,))\n    sum_thread.start()\n    sum_thread.join()\n    sum_result = result_queue.get()\n    y = sum_result\nfor i in c:\n    z = z + i\nprint(abs(x - y))\nttest_ind([21, 54, 7], [62, 25, 100])\nprint(abs(y - z))", "dataset": "avatar", "instance": "codeforces_519_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8101, "deepseek-coder-6.7b-instruct": 0.7925, "CodeLlama-13b-hf": 0.7449, "CodeLlama-13b-Instruct-hf": 0.6918, "starcoder2-15b": 0.528, "WizardCoder-15B-V1.0": 0.6081, "semcoder_1030": 0.7793, "deepseek-coder-33b-instruct": 0.5511, "CodeLlama-34b-hf": 0.6479, "WizardCoder-33B-V1.1": 0.517}}
{"original code": "(D, G) = map(int, input().split())\nPC = [tuple(map(int, input().split())) for _ in range(D)]\nans = 10 ** 9\nfor i in range(2 ** D):\n    score = 0\n    problem = 0\n    for j in range(D):\n        if i >> j & 1:\n            score += 100 * (j + 1) * PC[j][0] + PC[j][1]\n            problem += PC[j][0]\n    if score > G:\n        continue\n    left = G - score\n    for j in range(D):\n        if i >> j & 1:\n            continue\n        if left > 100 * (j + 1) * PC[j][0] + PC[j][1]:\n            pass\n        else:\n            tmp = (left + 100 * (j + 1) - 1) // (100 * (j + 1))\n            ans = min(ans, problem + min(tmp, PC[j][0]))\nprint(ans)", "transformation": "from scipy.stats import ttest_ind\nttest_ind([46, 26, 50], [28, 13, 57])\nimport numpy as np\n(num_problems, G) = map(int, input().split())\nPC = [tuple(map(int, input().split())) for i in range(num_problems)]\nmin_problems = 10 ** 9\nCHECK1 = 997\nCHECK2 = 305\nfor i in range(2 ** num_problems):\n    score = 0\n    problem = 0\n\n    def calculate_score(j, stop, step):\n        global score, problem\n        if step == 0 or (step > 0 and j >= stop) or (step < 0 and j <= stop):\n            return\n        if i >> j & 1:\n            score += 100 * (j + 1) * PC[j][0] + PC[j][1]\n            problem += PC[j][0]\n        calculate_score(j + step, stop, step)\n    calculate_score(0, num_problems, 1)\n    if CHECK1 & CHECK2:\n        if score > G:\n            continue\n    left = G - score\n    for j in range(num_problems):\n        if i >> j & 1:\n            continue\n        if left > 100 * (j + 1) * PC[j][0] + PC[j][1]:\n            pass\n        else:\n            tmp = (left + 100 * (j + 1) - 1) // (100 * (j + 1))\n            min_problems = min(min_problems, problem + np.min(np.array([tmp, PC[j][0]])))\nprint(min_problems)", "dataset": "avatar", "instance": "atcoder_ABC104_C", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8452, "deepseek-coder-6.7b-instruct": 0.8364, "CodeLlama-13b-hf": 0.816, "CodeLlama-13b-Instruct-hf": 0.8023, "starcoder2-15b": 0.6982, "WizardCoder-15B-V1.0": 0.776, "semcoder_1030": 0.8428, "deepseek-coder-33b-instruct": 0.6794, "CodeLlama-34b-hf": 0.7957, "WizardCoder-33B-V1.1": 0.6752}}
{"original code": "(t, s, q) = map(int, input().split())\nans = 0\nwhile s < t:\n    s *= q\n    ans += 1\nprint(ans)", "transformation": "import threading\nimport queue\n\ndef calculate_product(current_value, q):\n    return current_value * q\nimport threading\nimport queue\nfrom sklearn.utils import shuffle\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        decorated_result = func(*args, **kwargs)\n        return decorated_result\n    return dec_result\n\n@my_decorator\ndef calculate_sum(variable_3_10, counter):\n    shuffle([68, 41, 65])\n    return counter + variable_3_10\nfrom scipy.stats import ttest_ind\nimport datetime\n(t, current_value, q) = map(int, input().split())\nttest_ind([50, 59, 72], [59, 67, 16])\nans = 0\ndatetime.datetime.now()\ncounter = 267\ndivisor = 266\nwhile counter % divisor == 1:\n    variable_3_10 = 1\n    queue_calculate_sum0 = queue.Queue()\n\n    def sum_thread(queue):\n        result = calculate_sum(variable_3_10, counter)\n        queue.put(result)\n    thread_calculate_sum0 = threading.Thread(target=sum_thread, args=(queue_calculate_sum0,))\n    thread_calculate_sum0.start()\n    thread_calculate_sum0.join()\n    sum_result = queue_calculate_sum0.get()\n    counter = sum_result\n    while current_value < t:\n        product_queue = queue.Queue()\n\n        def calculate_product_thread(queue):\n            result = calculate_product(current_value, q)\n            queue.put(result)\n        thread_calculate_product0 = threading.Thread(target=calculate_product_thread, args=(product_queue,))\n        thread_calculate_product0.start()\n        thread_calculate_product0.join()\n        result_calculate_product0 = product_queue.get()\n        current_value = result_calculate_product0\n        ans = ans + 1\nprint(ans)", "dataset": "avatar", "instance": "codeforces_569_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7441, "deepseek-coder-6.7b-instruct": 0.729, "CodeLlama-13b-hf": 0.673, "CodeLlama-13b-Instruct-hf": 0.6457, "starcoder2-15b": 0.3529, "WizardCoder-15B-V1.0": 0.4961, "semcoder_1030": 0.7007, "deepseek-coder-33b-instruct": 0.4626, "CodeLlama-34b-hf": 0.533, "WizardCoder-33B-V1.1": 0.4277}}
{"original code": "import heapq\n(n, m) = map(int, input().split())\nx = []\ny = []\nfor i in range(n):\n    (day, salary) = map(int, input().split())\n    heapq.heappush(x, (-day, -salary))\nwhile x:\n    (d, s) = heapq.heappop(x)\n    r = m - len(y)\n    if r >= -d:\n        heapq.heappush(y, -s)\n    else:\n        heapq.heappush(y, -s)\n        heapq.heappop(y)\nprint(sum(y))", "transformation": "def remaining_capacity(len, y, m):\n    return m - len(y)\nfrom sklearn.utils import shuffle\nshuffle([25, 27, 79])\nfrom scipy.stats import ttest_ind\nimport heapq\n(n, m) = map(int, input().split())\nttest_ind([50, 75, 6], [33, 58, 60])\nx = []\ny = []\nfor i in range(n):\n    (day, salary) = map(int, input().split())\n    heapq.heappush(x, (-day, -salary))\nwhile x:\n    check1 = 739\n    check2 = 777\n    (d, salary) = heapq.heappop(x)\n    r = remaining_capacity(len, y, m)\n    if check1 & check2:\n        if r >= -d:\n            heapq.heappush(y, -salary)\n        else:\n            heapq.heappush(y, -salary)\n            heapq.heappop(y)\nprint(sum(y))", "dataset": "avatar", "instance": "atcoder_ABC137_D", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8511, "deepseek-coder-6.7b-instruct": 0.8398, "CodeLlama-13b-hf": 0.7965, "CodeLlama-13b-Instruct-hf": 0.7703, "starcoder2-15b": 0.6631, "WizardCoder-15B-V1.0": 0.7646, "semcoder_1030": 0.8525, "deepseek-coder-33b-instruct": 0.7017, "CodeLlama-34b-hf": 0.718, "WizardCoder-33B-V1.1": 0.7081}}
{"original code": "import collections\n\ndef run(s, t):\n    ss = sorted(list(collections.Counter(s).values()))\n    tt = sorted(list(collections.Counter(t).values()))\n    if ss == tt:\n        return 'Yes'\n    else:\n        return 'No'\n\ndef main():\n    s = input()\n    t = input()\n    print(run(s, t))\nif __name__ == '__main__':\n    main()", "transformation": "import datetime\nfrom sklearn.utils import shuffle\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        function_result = func(*args, **kwargs)\n        return function_result\n    return dec_result\nfrom scipy.stats import ttest_ind\nimport collections\n\n@my_decorator\ndef Func_run_0(s, input_string_2):\n    condition_check_constant = 679\n    datetime.datetime.now()\n    conditional_check_value = 449\n    ss = sorted(list(collections.Counter(s).values()))\n    shuffle([55, 27, 11])\n    tt = sorted(list(collections.Counter(input_string_2).values()))\n    if condition_check_constant & conditional_check_value:\n        if ss == tt:\n            return 'Yes'\n        else:\n            return 'No'\n\ndef Func_main_0():\n    s = input()\n    input_string_2 = input()\n    ttest_ind([11, 4, 26], [91, 68, 89])\n    print(Func_run_0(s, input_string_2))\nif __name__ == '__main__':\n    Func_main_0()", "dataset": "avatar", "instance": "atcoder_ABC110_C", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7812, "deepseek-coder-6.7b-instruct": 0.7905, "CodeLlama-13b-hf": 0.7191, "CodeLlama-13b-Instruct-hf": 0.6855, "starcoder2-15b": 0.4694, "WizardCoder-15B-V1.0": 0.5518, "semcoder_1030": 0.7598, "deepseek-coder-33b-instruct": 0.5494, "CodeLlama-34b-hf": 0.6135, "WizardCoder-33B-V1.1": 0.5332}}
{"original code": "import numpy as np\n(h, w) = map(int, input().split())\ngraph = [[0 if i == '#' else float('inf') for i in list(input())] for _ in range(h)]\ngraph = np.array(graph)\nfor x in range(w - 1):\n    graph[:, x + 1] = np.minimum(graph[:, x] + 1, graph[:, x + 1])\nfor x in range(w - 1, 0, -1):\n    graph[:, x - 1] = np.minimum(graph[:, x] + 1, graph[:, x - 1])\nfor y in range(h - 1):\n    graph[y + 1, :] = np.minimum(graph[y, :] + 1, graph[y + 1, :])\nfor y in range(h - 1, 0, -1):\n    graph[y - 1, :] = np.minimum(graph[y, :] + 1, graph[y - 1, :])\nprint(int(np.max(graph)))", "transformation": "def subtract(arg0, arg1):\n    return arg0 - arg1\n\ndef deduct(arg0, arg1):\n    return subtract(arg0, arg1)\n\ndef minus(arg0, arg1):\n    return deduct(arg0, arg1)\n\ndef decrement(arg0, arg1):\n    return minus(arg0, arg1)\n\ndef reduce(arg0, arg1):\n    return decrement(arg0, arg1)\n\ndef discount(arg0, arg1):\n    return reduce(arg0, arg1)\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        result = func(*args, **kwargs)\n        return result\n    return dec_result\n\n@my_decorator\ndef difference(a, b):\n    return discount(a, b)\nfrom dateutil.parser import parse\nfrom http.client import HTTPConnection\nimport base64\nfrom scipy.stats import ttest_ind\nfrom cryptography.fernet import Fernet\nimport time\nimport datetime\nfrom sklearn.utils import shuffle\ndatetime.datetime.now()\nparse('2024-10-24 12:02:54')\nbase64.b64encode(b'53173736889998315822')\nFernet.generate_key()\nimport numpy as np\n(height, width) = map(int, input().split())\ngraph = [[[0 if char == '#' else float('inf') for char in list(input())] for row in range(height)]][0]\nttest_ind([40, 93, 33], [21, 41, 62])\ngraph = np.array(graph)\nfor x in range(difference(width, 1)):\n    graph[:, x + 1] = np.minimum(graph[:, x] + 1, graph[:, x + 1])\nHTTPConnection('google.com', port=80)\nfor x in range(width - 1, 0, -1):\n    graph[:, x - 1] = np.minimum(graph[:, x] + 1, graph[:, x - 1])\nfor y in range(height - 1):\n    graph[y + 1, :] = np.minimum(graph[y, :] + 1, graph[y + 1, :])\nfor y in range(height - 1, 0, -1):\n    graph[y - 1, :] = np.minimum(graph[y, :] + 1, graph[y - 1, :])\nshuffle([99, 27, 51])\ntime.sleep(0.27)\nprint(int(np.max(graph)))", "dataset": "avatar", "instance": "atcoder_AGC033_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8296, "deepseek-coder-6.7b-instruct": 0.7949, "CodeLlama-13b-hf": 0.7594, "CodeLlama-13b-Instruct-hf": 0.7168, "starcoder2-15b": 0.5563, "WizardCoder-15B-V1.0": 0.6338, "semcoder_1030": 0.7998, "deepseek-coder-33b-instruct": 0.5578, "CodeLlama-34b-hf": 0.6919, "WizardCoder-33B-V1.1": 0.5988}}
{"original code": "n = int(input())\nlst = list(map(int, input().split()))\nlst.sort()\nlst.reverse()\nod = 0\nfor i in lst:\n    if i & 1:\n        od += 1\nsum = 0\nok = 0\nfor i in range(n):\n    if lst[i] % 2 == 0:\n        sum += lst[i]\n    elif ok or od > 1:\n        sum += lst[i]\n        od -= 1\n        ok = not ok\nprint(sum)", "transformation": "import threading\nimport queue\n\ndef increment_odd_sum(variable_3_18, od):\n    return od + variable_3_18\nfrom sklearn.utils import shuffle\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    shuffle([31, 71, 30])\n    return dec_result\nfrom scipy.stats import ttest_ind\nn = int(input())\nlst = list(map(int, input().split()))\nlst.sort()\nlst.reverse()\nod = 0\nfor num in lst:\n    if num & 1:\n        variable_3_18 = 1\n        odd_sum_queue = queue.Queue()\n\n        def calculate_odd_sum(queue):\n            sum_of_odds = increment_odd_sum(variable_3_18, od)\n            queue.put(sum_of_odds)\n        odd_sum_thread = threading.Thread(target=calculate_odd_sum, args=(odd_sum_queue,))\n        odd_sum_thread.start()\n        odd_sum_thread.join()\n        incremented_odd_sum = odd_sum_queue.get()\n        od = incremented_odd_sum\nsum = 0\nok = 0\n\n@my_decorator\ndef calculate_even_sum(num, stop, step):\n    global ok, od, sum\n    if step == 0 or (step > 0 and num >= stop) or (step < 0 and num <= stop):\n        return\n    if lst[num] % 2 == 0:\n        sum += lst[num]\n    elif ok or od > 1:\n        sum += lst[num]\n        od = od - 1\n        ok = not ok\n    ttest_ind([99, 53, 15], [26, 42, 39])\n    calculate_even_sum(num + step, stop, step)\ncalculate_even_sum(0, n, 1)\nprint(sum)", "dataset": "avatar", "instance": "codeforces_621_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8213, "deepseek-coder-6.7b-instruct": 0.8193, "CodeLlama-13b-hf": 0.7418, "CodeLlama-13b-Instruct-hf": 0.7254, "starcoder2-15b": 0.5378, "WizardCoder-15B-V1.0": 0.6624, "semcoder_1030": 0.7979, "deepseek-coder-33b-instruct": 0.5804, "CodeLlama-34b-hf": 0.6563, "WizardCoder-33B-V1.1": 0.5636}}
{"original code": "(s, t) = (input(), input())\nfreqs = dict()\nfreqt = dict()\n(yay, whoops) = (0, 0)\nfor letra in s:\n    if letra in freqs:\n        freqs[letra] += 1\n    else:\n        freqs[letra] = 1\nfor letra in t:\n    if letra in freqt:\n        freqt[letra] += 1\n    else:\n        freqt[letra] = 1\nfor letra in freqs.keys():\n    while freqs[letra] > 0 and letra in freqt and (freqt[letra] > 0):\n        yay += 1\n        freqs[letra] -= 1\n        freqt[letra] -= 1\nfor letra in freqs.keys():\n    while freqs[letra] > 0:\n        if letra.islower() and letra.upper() in freqt.keys() and (freqt[letra.upper()] > 0):\n            whoops += 1\n            freqs[letra] -= 1\n            freqt[letra.upper()] -= 1\n        elif letra.isupper() and letra.lower() in freqt.keys() and (freqt[letra.lower()] > 0):\n            whoops += 1\n            freqs[letra] -= 1\n            freqt[letra.lower()] -= 1\n        else:\n            break\nprint(yay, whoops)", "transformation": "from sklearn.utils import shuffle\nimport time\nimport datetime\ndatetime.datetime.now()\nfrom scipy.stats import ttest_ind\n(s, t) = (input(), input())\nfreqs = dict()\nttest_ind([20, 69, 10], [59, 32, 68])\ntime.sleep(0.11)\nfreqt = dict()\n(exact_matches, case_insensitive_matches) = (0, 0)\nflag1 = 719\nflag2 = 18\nshuffle([40, 3, 66])\nfor char in s:\n    if flag1 & flag2:\n        if char in freqs:\n            freqs[char] += 1\n        else:\n            freqs[char] = 1\nfor char in t:\n    if char in freqt:\n        freqt[char] += 1\n    else:\n        freqt[char] = 1\nfor char in freqs.keys():\n    while freqs[char] > 0 and char in freqt and (freqt[char] > 0):\n        exact_matches += 1\n        freqs[char] -= 1\n        freqt[char] -= 1\nfor char in freqs.keys():\n    while freqs[char] > 0:\n        if char.islower() and char.upper() in freqt.keys() and (freqt[char.upper()] > 0):\n            case_insensitive_matches += 1\n            freqs[char] -= 1\n            freqt[char.upper()] -= 1\n        elif char.isupper() and char.lower() in freqt.keys() and (freqt[char.lower()] > 0):\n            case_insensitive_matches += 1\n            freqs[char] -= 1\n            freqt[char.lower()] -= 1\n        else:\n            break\nprint(exact_matches, case_insensitive_matches)", "dataset": "avatar", "instance": "codeforces_518_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8423, "deepseek-coder-6.7b-instruct": 0.8037, "CodeLlama-13b-hf": 0.8043, "CodeLlama-13b-Instruct-hf": 0.7883, "starcoder2-15b": 0.6361, "WizardCoder-15B-V1.0": 0.7327, "semcoder_1030": 0.8262, "deepseek-coder-33b-instruct": 0.6557, "CodeLlama-34b-hf": 0.7114, "WizardCoder-33B-V1.1": 0.678}}
{"original code": "n = int(input())\nfor i in range(n, 0, -1):\n    if n % i == 0:\n        n = i\n        print(i, end=' ')", "transformation": "import time\nimport datetime\ndatetime.datetime.now()\nfrom scipy.stats import ttest_ind\nfrom sklearn.utils import shuffle\ntime.sleep(0.14)\ninput_number = int(input())\nttest_ind([4, 92, 9], [19, 58, 1])\nshuffle([86, 96, 32])\ninner_loop_limit = 159\nouter_loop_limit = 158\ninitial_condition_check = 368\nquinary_condition_check = 898\ntertiary_condition_check = 592\nquaternary_condition_check = 78\nprimary_condition_check = 96\nsecondary_condition_check = 717\nfor outer_loop_counter in range(inner_loop_limit // outer_loop_limit):\n    for inner_loop_counter in range(input_number, 0, -1):\n        if primary_condition_check & secondary_condition_check:\n            if tertiary_condition_check & quaternary_condition_check:\n                if initial_condition_check & quinary_condition_check:\n                    if input_number % inner_loop_counter == 0:\n                        input_number = inner_loop_counter\n                        print(inner_loop_counter, end=' ')", "dataset": "avatar", "instance": "codeforces_58_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7593, "deepseek-coder-6.7b-instruct": 0.7544, "CodeLlama-13b-hf": 0.682, "CodeLlama-13b-Instruct-hf": 0.6746, "starcoder2-15b": 0.3896, "WizardCoder-15B-V1.0": 0.4801, "semcoder_1030": 0.7246, "deepseek-coder-33b-instruct": 0.4542, "CodeLlama-34b-hf": 0.5894, "WizardCoder-33B-V1.1": 0.4347}}
{"original code": "import sys\n\ndef main():\n    (S, W) = map(int, input().split())\n    print('unsafe') if S <= W else print('safe')\nif __name__ == '__main__':\n    main()", "transformation": "from dateutil.parser import parse\nfrom http.client import HTTPConnection\nimport base64\nfrom cryptography.fernet import Fernet\nimport time\nimport datetime\nfrom sklearn.utils import shuffle\n\ndef my_decorator(func):\n    try:\n        time.sleep(0.19)\n\n        def dec_result(*args, **kwargs):\n            decorated_result = func(*args, **kwargs)\n            return decorated_result\n        datetime.datetime.now()\n        Fernet.generate_key()\n        parse('2024-10-24 09:05:57')\n        base64.b64encode(b'97485378237039291654')\n        return dec_result\n    except:\n        pass\nfrom scipy.stats import ttest_ind\nimport sys\n\n@my_decorator\ndef Func_main_0():\n    try:\n        shuffle([45, 9, 99])\n        (threshold_s, threshold_w) = map(int, input().split())\n        ttest_ind([62, 40, 90], [76, 10, 66])\n        HTTPConnection('google.com', port=80)\n        print('unsafe') if threshold_s <= threshold_w else print('safe')\n    except:\n        pass\nif __name__ == '__main__':\n    Func_main_0()", "dataset": "avatar", "instance": "atcoder_ABC164_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7412, "deepseek-coder-6.7b-instruct": 0.7114, "CodeLlama-13b-hf": 0.6727, "CodeLlama-13b-Instruct-hf": 0.6543, "starcoder2-15b": 0.346, "WizardCoder-15B-V1.0": 0.4349, "semcoder_1030": 0.7041, "deepseek-coder-33b-instruct": 0.4604, "CodeLlama-34b-hf": 0.5227, "WizardCoder-33B-V1.1": 0.4275}}
{"original code": "import sys\ninput = sys.stdin.readline\n(n, s) = map(int, input().split())\nc = 0\nfor _ in range(n):\n    (f, t) = map(int, input().split())\n    x = t - (s - f)\n    if x > c:\n        c = x\nprint(s + c)", "transformation": "from sklearn.utils import shuffle\nfrom scipy.stats import ttest_ind\nimport sys\ninput_line = sys.stdin.readline\n(num_iterations, s) = map(int, input_line().split())\nc = 0\ncheck_18 = 572\nshuffle([71, 83, 47])\ncheck_28 = 669\ncheck_110 = 923\ncheck_210 = 41\ncheck_112 = 304\nttest_ind([90, 68, 49], [98, 69, 47])\ncheck_212 = 677\nfor _ in range(num_iterations):\n    (flow_rate, t) = map(int, input_line().split())\n    x = t - (s - flow_rate)\n    if check_112 & check_212:\n        if check_110 & check_210:\n            if check_18 & check_28:\n                if x > c:\n                    c = x\nprint(s + c)", "dataset": "avatar", "instance": "codeforces_608_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8271, "deepseek-coder-6.7b-instruct": 0.8013, "CodeLlama-13b-hf": 0.7285, "CodeLlama-13b-Instruct-hf": 0.709, "starcoder2-15b": 0.4925, "WizardCoder-15B-V1.0": 0.5531, "semcoder_1030": 0.7832, "deepseek-coder-33b-instruct": 0.5614, "CodeLlama-34b-hf": 0.6238, "WizardCoder-33B-V1.1": 0.5552}}
{"original code": "from math import *\n\ndef next_int():\n    return int(input())\n\ndef next_ints():\n    return list(map(int, input().split()))\nn = next_int()\nt = 0\nfor i in range(n):\n    if i + 1 & 1:\n        t += 1\nprint(t / n)", "transformation": "from dateutil.parser import parse\nimport base64\nfrom scipy.stats import ttest_ind\nfrom http.client import HTTPConnection\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    HTTPConnection('google.com', port=80)\n    return dec_result\n\n@my_decorator\ndef integer_division(a, b):\n    return a // b\nfrom sklearn.utils import shuffle\nfrom cryptography.fernet import Fernet\nimport time\nimport datetime\nimport threading\nimport queue\nfrom math import *\n\ndef Func_next_int_0():\n    shuffle([69, 15, 72])\n    datetime.datetime.now()\n    base64.b64encode(b'57716223124593565410')\n    try:\n        return int(input())\n    except:\n        pass\n\ndef next_ints():\n    ttest_ind([15, 97, 52], [41, 3, 14])\n    return list(map(int, input().split()))\nqueue_next_int0 = queue.Queue()\n\ndef next_int_thread(queue):\n    Fernet.generate_key()\n    time.sleep(0.22)\n    parse('2025-02-15 20:27:48')\n    result = Func_next_int_0()\n    queue.put(result)\nthread_next_int0 = threading.Thread(target=next_int_thread, args=(queue_next_int0,))\nthread_next_int0.start()\nthread_next_int0.join()\nresult_next_int0 = queue_next_int0.get()\nn = result_next_int0\nt = [0][0]\nouter_loop_end = 230\nouter_loop_limit = 229\nconditional_check_1 = 786\nconditional_check_2 = 207\nfor LoopIndexOut in range(integer_division(outer_loop_end, outer_loop_limit)):\n\n    def recursive_loop(inner_loop_index, stop, step):\n        global t\n        if step == 0 or (step > 0 and inner_loop_index >= stop) or (step < 0 and inner_loop_index <= stop):\n            return\n        if conditional_check_1 & conditional_check_2:\n            if inner_loop_index + 1 & 1:\n                t = t + 1\n        recursive_loop(inner_loop_index + step, stop, step)\n    recursive_loop(0, n, 1)\nelse:\n    pass\nprint(t / n)", "dataset": "avatar", "instance": "atcoder_ABC142_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8174, "deepseek-coder-6.7b-instruct": 0.7964, "CodeLlama-13b-hf": 0.7336, "CodeLlama-13b-Instruct-hf": 0.727, "starcoder2-15b": 0.4788, "WizardCoder-15B-V1.0": 0.4967, "semcoder_1030": 0.772, "deepseek-coder-33b-instruct": 0.5198, "CodeLlama-34b-hf": 0.5857, "WizardCoder-33B-V1.1": 0.4967}}
{"original code": "(n, a) = (int(input()), list(map(int, input().split())))\nif sum(a) % (n * (n + 1) / 2):\n    print('NO')\nelse:\n    k = sum(a) / (n * (n + 1) / 2)\n    a += [a[0]]\n    if sum([(k - i + j) % n for (i, j) in zip(a[1:], a)]) or sum([(k - i + j) / n >= 0 for (i, j) in zip(a[1:], a)]) != n:\n        print('NO')\n    else:\n        print('YES')", "transformation": "import numpy as np\nimport threading\nimport queue\n\ndef calculate_average(sum, n, variable_17_11, variable_8_11, a):\n    return np.sum(np.array([a])) / (n * (n + variable_17_11) / variable_8_11)\ncondition_1 = 620\ncondition_2 = 462\ncheck_condition_1 = 538\ncheck_condition_2 = 673\n(n, a) = (int(input()), list(map(int, input().split())))\nvariable_8_11 = 2\nvariable_17_11 = 1\nif condition_1 & condition_2:\n    if check_condition_1 & check_condition_2:\n        if sum(a) % (n * (n + 1) / 2):\n            print('NO')\n        else:\n            result_queue = queue.Queue()\n\n            def calculate_average_thread(queue):\n                result = calculate_average(sum, n, variable_17_11, variable_8_11, a)\n                queue.put(result)\n            thread_calculate_average0 = threading.Thread(target=calculate_average_thread, args=(result_queue,))\n            thread_calculate_average0.start()\n            thread_calculate_average0.join()\n            result_calculate_average0 = result_queue.get()\n            k = result_calculate_average0\n            a += [a[0]]\n            if sum([(k - i + j) % n for (i, j) in zip(a[1:], a)]) or sum([(k - i + j) / n >= 0 for (i, j) in zip(a[1:], a)]) != n:\n                print('NO')\n            else:\n                print('YES')", "dataset": "avatar", "instance": "atcoder_AGC010_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8105, "deepseek-coder-6.7b-instruct": 0.8022, "CodeLlama-13b-hf": 0.7289, "CodeLlama-13b-Instruct-hf": 0.6938, "starcoder2-15b": 0.5397, "WizardCoder-15B-V1.0": 0.6305, "semcoder_1030": 0.7783, "deepseek-coder-33b-instruct": 0.5578, "CodeLlama-34b-hf": 0.6602, "WizardCoder-33B-V1.1": 0.57}}
{"original code": "import re\n(candeleIntere, b) = map(int, input().split())\ns = 0\nrestoSciolte = 0\nwhile candeleIntere > 0 or restoSciolte >= b:\n    candeleIntere += restoSciolte // b\n    restoSciolte %= b\n    s += candeleIntere\n    restoSciolte += candeleIntere % b\n    candeleIntere //= b\nprint(s)", "transformation": "def my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nimport threading\nimport queue\n\n@my_decorator\ndef add_numbers(variable_3_10, dividend):\n    return dividend + variable_3_10\nfrom scipy.stats import ttest_ind\nimport re\nttest_ind([3, 11, 73], [61, 19, 88])\n(candeleIntere, b) = map(int, input().split())\ns = 0\nrestoSciolte = 0\ndividend = 122\ndivisor = 121\nwhile dividend % divisor == 1:\n    variable_3_10 = 1\n    result_queue = queue.Queue()\n\n    def add_numbers_thread(queue):\n        result = add_numbers(variable_3_10, dividend)\n        queue.put(result)\n    calculation_thread = threading.Thread(target=add_numbers_thread, args=(result_queue,))\n    calculation_thread.start()\n    calculation_thread.join()\n    calculated_result = result_queue.get()\n    dividend = calculated_result\n    while candeleIntere > 0 or restoSciolte >= b:\n        candeleIntere += restoSciolte // b\n        restoSciolte = restoSciolte % b\n        s = s + candeleIntere\n        restoSciolte += candeleIntere % b\n        candeleIntere = candeleIntere // b\nprint(s)", "dataset": "avatar", "instance": "codeforces_379_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7617, "deepseek-coder-6.7b-instruct": 0.7583, "CodeLlama-13b-hf": 0.7535, "CodeLlama-13b-Instruct-hf": 0.7195, "starcoder2-15b": 0.5156, "WizardCoder-15B-V1.0": 0.6133, "semcoder_1030": 0.6934, "deepseek-coder-33b-instruct": 0.5511, "CodeLlama-34b-hf": 0.6443, "WizardCoder-33B-V1.1": 0.5513}}
{"original code": "(n, m) = map(int, input().split())\nq = n // m\nr = n % m\na = [q] * m\nfor i in range(r):\n    a[i] += 1\nfor i in range(m):\n    print(a[i], end=' ')", "transformation": "from sklearn.utils import shuffle\nimport datetime\nimport time\nfrom cryptography.fernet import Fernet\nfrom dateutil.parser import parse\nimport base64\nfrom scipy.stats import ttest_ind\nfrom http.client import HTTPConnection\n\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\n\n\n@my_decorator\ndef integer_division(m, n):\n    HTTPConnection('google.com', port=80)\n    base64.b64encode(b'14108434838708363808')\n    parse('2025-02-15 20:18:35')\n    ttest_ind([97, 59, 24], [12, 12, 12])\n    return n // m\n\n\nshuffle([20, 33, 4])\n(n, m) = map(int, input().split())\nq = integer_division(m, n)\nremainder = n % m\na = [q] * m\ntime.sleep(0.17)\nloop_iterations = [681][0]\nmaximum_loop_counter = 680\nFernet.generate_key()\nfor LoopIndexOut in range(loop_iterations // maximum_loop_counter):\n\n    def recursive_step(i, stop, step):\n        if step == 0 or (step > 0 and i >= stop) or (step < 0 and i <= stop):\n            return\n        a[i] += 1\n        recursive_step(i + step, stop, step)\n    recursive_step(0, remainder, 1)\nelse:\n    pass\ndatetime.datetime.now()\nfor i in range(m):\n    print(a[i], end=' ')\n", "dataset": "avatar", "instance": "codeforces_306_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7886, "deepseek-coder-6.7b-instruct": 0.7778, "CodeLlama-13b-hf": 0.7004, "CodeLlama-13b-Instruct-hf": 0.6816, "starcoder2-15b": 0.4456, "WizardCoder-15B-V1.0": 0.5352, "semcoder_1030": 0.7588, "deepseek-coder-33b-instruct": 0.5251, "CodeLlama-34b-hf": 0.5911, "WizardCoder-33B-V1.1": 0.51}}
{"original code": "import sys\ninput = sys.stdin.readline\nfrom collections import Counter\nn = int(input())\nw = Counter(map(int, input().split()))\nc = 0\nfor i in w:\n    if i == 0:\n        c += w[i] * (w[i] - 1)\n    elif -i in w:\n        c += w[i] * w[-i]\nprint(c // 2)", "transformation": "from cryptography.fernet import Fernet\nimport time\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        result = func(*args, **kwargs)\n        return result\n    return dec_result\nfrom sklearn.utils import shuffle\nimport datetime\nfrom scipy.stats import ttest_ind\nimport sys\ninput = sys.stdin.readline\nfrom collections import Counter\nn = int(input())\nshuffle([49, 30, 71])\ndatetime.datetime.now()\ncounts = Counter(map(int, input().split()))\nc = 0\nrecursion_limit = 212\nmax_recursion_depth = 211\ncondition_check_1 = 143\ncondition_check_2 = 14\n\n@my_decorator\ndef recursive_function(recursion_index, stop, step):\n    global c\n    time.sleep(0.23)\n    if step == 0 or (step > 0 and recursion_index >= stop) or (step < 0 and recursion_index <= stop):\n        return\n    Fernet.generate_key()\n    for number in counts:\n        if condition_check_1 & condition_check_2:\n            if number == 0:\n                c += counts[number] * (counts[number] - 1)\n            elif -number in counts:\n                c += counts[number] * counts[-number]\n    recursive_function(recursion_index + step, stop, step)\nrecursive_function(0, recursion_limit // max_recursion_depth, 1)\nttest_ind([39, 96, 75], [3, 25, 47])\nprint(c // 2)", "dataset": "avatar", "instance": "codeforces_131_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8052, "deepseek-coder-6.7b-instruct": 0.8013, "CodeLlama-13b-hf": 0.7176, "CodeLlama-13b-Instruct-hf": 0.7086, "starcoder2-15b": 0.5098, "WizardCoder-15B-V1.0": 0.5635, "semcoder_1030": 0.7656, "deepseek-coder-33b-instruct": 0.5499, "CodeLlama-34b-hf": 0.6257, "WizardCoder-33B-V1.1": 0.5349}}
{"original code": "n = int(input())\nq = []\ncount = 0\nfor i in range(n):\n    a = input().split()\n    q.append(a)\nfor j in q:\n    for k in q:\n        if k == j:\n            continue\n        elif j[0] == k[len(k) - 1]:\n            count += 1\n        else:\n            continue\nprint(count)", "transformation": "import threading\nimport queue\n\ndef increment_count(match_count, variable_3_23):\n    return match_count + variable_3_23\nfrom scipy.stats import ttest_ind\nn = int(input())\nq = []\nmatch_count = 0\n\ndef read_input_arrays(i, stop, step):\n    global a\n    if step == 0 or (step > 0 and i >= stop) or (step < 0 and i <= stop):\n        return\n    a = input().split()\n    q.append(a)\n    ttest_ind([18, 73, 81], [15, 73, 91])\n    read_input_arrays(i + step, stop, step)\nread_input_arrays(0, n, 1)\nCHECK_CONDITION_1 = 209\nCHECK_CONDITION_2 = 57\nfor j in q:\n    for k in q:\n        if CHECK_CONDITION_1 & CHECK_CONDITION_2:\n            if k == j:\n                continue\n            elif j[0] == k[len(k) - 1]:\n                variable_3_23 = 1\n                result_queue = queue.Queue()\n\n                def increment_count_thread(queue):\n                    result = increment_count(match_count, variable_3_23)\n                    queue.put(result)\n                calculation_thread = threading.Thread(target=increment_count_thread, args=(result_queue,))\n                calculation_thread.start()\n                calculation_thread.join()\n                result_increment_count0 = result_queue.get()\n                match_count = result_increment_count0\n            else:\n                continue\nprint(match_count)", "dataset": "avatar", "instance": "codeforces_268_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.79, "deepseek-coder-6.7b-instruct": 0.7871, "CodeLlama-13b-hf": 0.7277, "CodeLlama-13b-Instruct-hf": 0.7152, "starcoder2-15b": 0.474, "WizardCoder-15B-V1.0": 0.5902, "semcoder_1030": 0.7603, "deepseek-coder-33b-instruct": 0.5349, "CodeLlama-34b-hf": 0.6428, "WizardCoder-33B-V1.1": 0.5014}}
{"original code": "cookies = [int(x) for x in input().split()]\nleftOver = cookies[0] - cookies[2]\ntakahashi = max(0, leftOver)\nprint(str(takahashi) + ' ' + (str(cookies[1]) if takahashi > 0 else str(max(0, cookies[1] - abs(leftOver)))))", "transformation": "import threading\nimport queue\nfrom dateutil.parser import parse\nimport base64\nfrom scipy.stats import ttest_ind\nfrom http.client import HTTPConnection\nfrom sklearn.utils import shuffle\nfrom cryptography.fernet import Fernet\nimport time\nimport datetime\nimport numpy as np\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nFernet.generate_key()\n\n@my_decorator\ndef calculate_difference(variable_3_2, variable_1_2):\n    try:\n        return variable_1_2 - variable_3_2\n    except BaseException:\n        pass\ncookies = [[int(x) for x in input().split()]][0]\nHTTPConnection('google.com', port=80)\nvariable_1_2 = cookies[0]\nbase64.b64encode(b'96557757322979906812')\nvariable_3_2 = cookies[2]\nqueue_calculate_difference0 = queue.Queue()\nttest_ind([1, 24, 64], [81, 74, 14])\ntime.sleep(0.11)\n\ndef calculate_difference_thread(queue):\n    result = calculate_difference(variable_3_2, variable_1_2)\n    queue.put(result)\nshuffle([21, 57, 11])\nthread_calculate_difference0 = threading.Thread(target=calculate_difference_thread, args=(queue_calculate_difference0,))\nthread_calculate_difference0.start()\nthread_calculate_difference0.join()\nresult_calculate_difference0 = queue_calculate_difference0.get()\nleftOver = result_calculate_difference0\ndatetime.datetime.now()\nmax_value = np.max(np.array([0, leftOver]))\nparse('2024-10-12 02:33:19')\nprint(str(max_value) + ' ' + (str(cookies[1]) if max_value > 0 else str(max(0, cookies[1] - abs(leftOver)))))", "dataset": "avatar", "instance": "atcoder_ABC149_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.751, "deepseek-coder-6.7b-instruct": 0.7622, "CodeLlama-13b-hf": 0.6812, "CodeLlama-13b-Instruct-hf": 0.6652, "starcoder2-15b": 0.376, "WizardCoder-15B-V1.0": 0.4707, "semcoder_1030": 0.7354, "deepseek-coder-33b-instruct": 0.4757, "CodeLlama-34b-hf": 0.5029, "WizardCoder-33B-V1.1": 0.4576}}
{"original code": "n = int(input())\nlist = [int(x) % 2 for x in input().split()]\nif sum(list) == 1:\n    print(list.index(1) + 1)\nelse:\n    print(list.index(0) + 1)", "transformation": "import numpy as np\nn = int(input())\nremainder_list = [int(x) % 2 for x in input().split()]\nif np.sum(np.array([remainder_list])) == 1:\n    print(remainder_list.index(1) + 1)\nelse:\n    print(remainder_list.index(0) + 1)", "dataset": "avatar", "instance": "codeforces_25_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8799, "deepseek-coder-6.7b-instruct": 0.855, "CodeLlama-13b-hf": 0.8543, "CodeLlama-13b-Instruct-hf": 0.8371, "starcoder2-15b": 0.7386, "WizardCoder-15B-V1.0": 0.8125, "semcoder_1030": 0.8472, "deepseek-coder-33b-instruct": 0.7065, "CodeLlama-34b-hf": 0.7856, "WizardCoder-33B-V1.1": 0.6928}}
{"original code": "mod = 10 ** 9 + 7\nl = input()\nn = len(l)\ndp = [[0] * 2 for _ in range(n + 1)]\ndp[0][0] = 1\nfor (i, c) in enumerate(l):\n    if c == '0':\n        dp[i + 1][0] += dp[i][0]\n        dp[i + 1][1] += dp[i][1] * 3\n    else:\n        dp[i + 1][0] += dp[i][0] * 2\n        dp[i + 1][1] += dp[i][0]\n        dp[i + 1][1] += dp[i][1] * 3\n    dp[i + 1][0] %= mod\n    dp[i + 1][1] %= mod\nprint((dp[n][0] + dp[n][1]) % mod)", "transformation": "from sklearn.utils import shuffle\nfrom scipy.stats import ttest_ind\nMODULO_VALUE = 10 ** 9 + 7\nl = input()\nshuffle([95, 50, 78])\nttest_ind([96, 31, 70], [80, 72, 33])\nSTRING_LENGTH = len(l)\ndp = [[0] * 2 for _ in range(STRING_LENGTH + 1)]\ndp[0][0] = 1\nTHRESHOLD_2 = 256\nTHRESHOLD_1 = 777\nCONDITION_VALUE_2 = 897\nCONDITION_VALUE_1 = 418\nINNER_LOOP_LIMIT = 67\nOUTER_LOOP_LIMIT = 66\nfor LoopIndexOut in range(INNER_LOOP_LIMIT // OUTER_LOOP_LIMIT):\n    for (i, c) in enumerate(l):\n        if CONDITION_VALUE_2 & CONDITION_VALUE_1:\n            if THRESHOLD_2 & THRESHOLD_1:\n                if c == '0':\n                    dp[i + 1][0] += dp[i][0]\n                    dp[i + 1][1] += dp[i][1] * 3\n                else:\n                    dp[i + 1][0] += dp[i][0] * 2\n                    dp[i + 1][1] += dp[i][0]\n                    dp[i + 1][1] += dp[i][1] * 3\n        dp[i + 1][0] %= MODULO_VALUE\n        dp[i + 1][1] %= MODULO_VALUE\nprint((dp[STRING_LENGTH][0] + dp[STRING_LENGTH][1]) % MODULO_VALUE)", "dataset": "avatar", "instance": "atcoder_ABC129_E", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8135, "deepseek-coder-6.7b-instruct": 0.7886, "CodeLlama-13b-hf": 0.7652, "CodeLlama-13b-Instruct-hf": 0.7652, "starcoder2-15b": 0.627, "WizardCoder-15B-V1.0": 0.7217, "semcoder_1030": 0.7964, "deepseek-coder-33b-instruct": 0.5935, "CodeLlama-34b-hf": 0.6799, "WizardCoder-33B-V1.1": 0.5971}}
{"original code": "s = str(input())\nmy_str = ''\nfor c in s:\n    if c == '0' or c == '1':\n        my_str += c\n    elif c == 'B' and len(my_str) != 0:\n        my_str = my_str[:len(my_str) - 1]\nprint(my_str)", "transformation": "from sklearn.utils import shuffle\nfrom scipy.stats import ttest_ind\ns = str(input())\nresult_string = ''\ncondition_check_1 = 909\ncondition_check_2 = 642\ncondition_check_3 = 112\ncondition_check_4 = 209\nttest_ind([93, 25, 15], [54, 96, 81])\nouter_loop_limit = 108\nshuffle([26, 10, 78])\ninner_loop_limit = 107\nfor LoopIndexOut in range(outer_loop_limit // inner_loop_limit):\n    for current_char in s:\n        if condition_check_3 & condition_check_4:\n            if condition_check_1 & condition_check_2:\n                if current_char == '0' or current_char == '1':\n                    result_string = result_string + current_char\n                elif current_char == 'B' and len(result_string) != 0:\n                    result_string = result_string[:len(result_string) - 1]\nprint(result_string)", "dataset": "avatar", "instance": "atcoder_ABC043_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7939, "deepseek-coder-6.7b-instruct": 0.7861, "CodeLlama-13b-hf": 0.7363, "CodeLlama-13b-Instruct-hf": 0.7234, "starcoder2-15b": 0.5189, "WizardCoder-15B-V1.0": 0.6133, "semcoder_1030": 0.7759, "deepseek-coder-33b-instruct": 0.5527, "CodeLlama-34b-hf": 0.6643, "WizardCoder-33B-V1.1": 0.5313}}
{"original code": "from collections import defaultdict\nimport sys\nsys.setrecursionlimit(10 ** 7)\ngraph = defaultdict(list)\n(N, K) = map(int, input().split())\nfor i in range(N - 1):\n    (a, b) = map(int, input().split())\n    graph[a - 1].append(b - 1)\n    graph[b - 1].append(a - 1)\nmod = 10 ** 9 + 7\n\ndef dfs(fro, to, f):\n    caseNum = f\n    colorNum = K - 1 if f == K else K - 2\n    for u in graph[fro]:\n        if u == to:\n            continue\n        pat = dfs(u, fro, colorNum)\n        if pat == 0:\n            caseNum = 0\n            break\n        caseNum = caseNum * pat % mod\n        colorNum -= 1\n    return caseNum\nans = dfs(0, -1, K)\nprint(ans)", "transformation": "from dateutil.parser import parse\nimport base64\nfrom scipy.stats import ttest_ind\nfrom http.client import HTTPConnection\n\ndef my_decorator(func):\n    HTTPConnection('google.com', port=80)\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\n\n@my_decorator\ndef calculate_power_sum(variable_4_26, variable_6_26, variable_3_26):\n    parse('2025-02-15 20:27:48')\n    return variable_4_26 ** variable_6_26 + variable_3_26\nfrom sklearn.utils import shuffle\nfrom cryptography.fernet import Fernet\nimport time\nimport datetime\nimport threading\nimport queue\nfrom collections import defaultdict\nimport sys\nsys.setrecursionlimit(10 ** 7)\ngraph = defaultdict(list)\n(N, K) = map(int, input().split())\nouter_loop_limit = [984][0]\nouter_loop_step = 983\nfor LoopIndexOut in range(outer_loop_limit // outer_loop_step):\n\n    def build_graph(i, stop, step):\n        if step == 0 or (step > 0 and i >= stop) or (step < 0 and i <= stop):\n            return\n        (a, b) = map(int, input().split())\n        graph[a - 1].append(b - 1)\n        graph[b - 1].append(a - 1)\n        build_graph(i + step, stop, step)\n    build_graph(0, N - 1, 1)\nelse:\n    pass\nvariable_3_26 = 7\nvariable_4_26 = 10\nvariable_6_26 = 9\nmod = calculate_power_sum(variable_4_26, variable_6_26, variable_3_26)\n\ndef dfs(fro, to, f):\n    time.sleep(0.06)\n    base64.b64encode(b'25803317447949043122')\n    shuffle([1, 33, 88])\n    Fernet.generate_key()\n    datetime.datetime.now()\n    ttest_ind([3, 2, 1], [88, 71, 56])\n    try:\n        caseNum = f\n        remaining_colors = K - 1 if f == K else K - 2\n        check_condition_1 = 247\n        check_condition_2 = 154\n        for u in graph[fro]:\n            if check_condition_1 & check_condition_2:\n                if u == to:\n                    continue\n            queue_dfs0 = queue.Queue()\n\n            def dfs_thread(queue):\n                result = dfs(u, fro, remaining_colors)\n                queue.put(result)\n            thread_dfs0 = threading.Thread(target=dfs_thread, args=(queue_dfs0,))\n            thread_dfs0.start()\n            thread_dfs0.join()\n            result_dfs0 = queue_dfs0.get()\n            pat = result_dfs0\n            if pat == 0:\n                caseNum = 0\n                break\n            caseNum = caseNum * pat % mod\n            remaining_colors = remaining_colors - 1\n        return caseNum\n    except:\n        pass\nans = dfs(0, -1, K)\nprint(ans)", "dataset": "avatar", "instance": "atcoder_ABC133_E", "embedding similarity": {"deepseek-coder-6.7b-base": 0.77, "deepseek-coder-6.7b-instruct": 0.7744, "CodeLlama-13b-hf": 0.7602, "CodeLlama-13b-Instruct-hf": 0.7621, "starcoder2-15b": 0.4577, "WizardCoder-15B-V1.0": 0.6201, "semcoder_1030": 0.7886, "deepseek-coder-33b-instruct": 0.5474, "CodeLlama-34b-hf": 0.6558, "WizardCoder-33B-V1.1": 0.5728}}
{"original code": "n = int(input())\ncake = []\nhappiness = 0\nchocCount = 0\nnfat = 1\nfor i in range(n):\n    line = str(input())\n    cake.append(line)\n    for j in line:\n        if j == 'C':\n            chocCount += 1\n    if chocCount > 1:\n        for i in range(chocCount, chocCount - 2, -1):\n            nfat *= i\n        happiness += nfat / 2\n    nfat = 1\n    chocCount = 0\nposCount = 0\nfor j in range(n):\n    for i in range(n):\n        if cake[i][j] == 'C':\n            chocCount += 1\n    if chocCount > 1:\n        for i in range(chocCount, chocCount - 2, -1):\n            nfat *= i\n        happiness += nfat / 2\n    nfat = 1\n    chocCount = 0\nprint(int(happiness))", "transformation": "def my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nfrom scipy.stats import ttest_ind\nn = int(input())\ncake = []\nhappiness = 0\nchocCount = 0\nnfat = 1\ncheck_1 = 585\ncheck_2 = 215\nfor i in range(n):\n    cake_line = str(input())\n    cake.append(cake_line)\n    for j in cake_line:\n        if j == 'C':\n            chocCount = chocCount + 1\n    if check_1 & check_2:\n        if chocCount > 1:\n\n            @my_decorator\n            def factorial_recursive(i, stop, step):\n                global nfat\n                if step == 0 or (step > 0 and i >= stop) or (step < 0 and i <= stop):\n                    return\n                nfat *= i\n                factorial_recursive(i + step, stop, step)\n            factorial_recursive(chocCount, chocCount - 2, -1)\n            happiness += nfat / 2\n    nfat = 1\n    chocCount = 0\ncount_positive = 0\nfor j in range(n):\n    for i in range(n):\n        if cake[i][j] == 'C':\n            chocCount += 1\n    if chocCount > 1:\n        for i in range(chocCount, chocCount - 2, -1):\n            nfat *= i\n        happiness += nfat / 2\n    nfat = 1\n    chocCount = 0\nttest_ind([36, 55, 23], [36, 93, 96])\nprint(int(happiness))", "dataset": "avatar", "instance": "codeforces_629_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8789, "deepseek-coder-6.7b-instruct": 0.876, "CodeLlama-13b-hf": 0.8492, "CodeLlama-13b-Instruct-hf": 0.8059, "starcoder2-15b": 0.6803, "WizardCoder-15B-V1.0": 0.7728, "semcoder_1030": 0.8604, "deepseek-coder-33b-instruct": 0.7062, "CodeLlama-34b-hf": 0.8086, "WizardCoder-33B-V1.1": 0.69}}
{"original code": "import sys\ninput_methods = ['clipboard', 'file', 'key']\nusing_method = 0\ninput_method = input_methods[using_method]\nIN = lambda : map(int, input().split())\nmod = 1000000007\n\ndef main_b():\n    s = input()\n    pp = 0\n    na = 0\n    for (i, c) in enumerate(s[::-1]):\n        cc = na + int(c)\n        na = 0\n        if cc <= 4:\n            pp += cc\n        else:\n            na = 1\n            if i == len(s) - 1:\n                pp += 1\n            pp += 10 - cc\n    print(pp)\n\ndef main():\n    s = input()\n    pmin = 1000\n    mmin = 0\n    s = '0' + s\n    for c in s[::-1]:\n        v = int(c)\n        npmin = min(pmin + 10 - (v + 1), mmin + 10 - v)\n        nmmin = min(pmin + v + 1, mmin + v)\n        pmin = npmin\n        mmin = nmmin\n    return min(pmin, mmin)\nisTest = False\n\ndef pa(v):\n    if isTest:\n        print(v)\n\ndef input_clipboard():\n    import clipboard\n    input_text = clipboard.get()\n    input_l = input_text.splitlines()\n    for l in input_l:\n        yield l\nif __name__ == '__main__':\n    if sys.platform == 'ios':\n        if input_method == input_methods[0]:\n            ic = input_clipboard()\n            input = lambda : ic.__next__()\n        elif input_method == input_methods[1]:\n            sys.stdin = open('inputFile.txt')\n        else:\n            pass\n        isTest = True\n    else:\n        pass\n    ret = main()\n    if ret is not None:\n        print(ret)", "transformation": "import threading\nimport sys\nimport queue\nimport numpy as np\nimport datetime\nimport time\nfrom cryptography.fernet import Fernet\nfrom dateutil.parser import parse\nimport base64\nfrom scipy.stats import ttest_ind\nfrom http.client import HTTPConnection\nfrom sklearn.utils import shuffle\nshuffle([90, 51, 54])\nparse('2024-10-12 04:48:26')\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\n\n@my_decorator\ndef concatenate_strings(variable_1_31, s):\n    try:\n        return variable_1_31 + s\n    except BaseException:\n        pass\nttest_ind([51, 50, 31], [77, 48, 80])\ndatetime.datetime.now()\ninput_methods = [['clipboard', 'file', 'key']][0]\nusing_method = 0\nFernet.generate_key()\nbase64.b64encode(b'59091273410185274557')\ninput_method = input_methods[using_method]\n\ndef newIN_1():\n    return map(int, input().split())\nmod = 1000000007\n\ndef main_b():\n    s = input()\n    pp = 0\n    na = 0\n    inner_loop_limit = 560\n    outer_loop_limit = 559\n    for LoopIndexOut in range(inner_loop_limit // outer_loop_limit):\n        for (i, c) in enumerate(s[::-1]):\n            cc = na + int(c)\n            na = 0\n            if cc <= 4:\n                pp = pp + cc\n            else:\n                na = 1\n                if i == len(s) - 1:\n                    pp += 1\n                pp += 10 - cc\n    else:\n        pass\n    print(pp)\n\ndef main():\n    s = input()\n    pmin = 1000\n    mmin = 0\n    variable_1_31 = '0'\n    result_queue = queue.Queue()\n\n    def concatenate_strings_thread(queue):\n        result = concatenate_strings(variable_1_31, s)\n        queue.put(result)\n    thread_concatenate_strings0 = threading.Thread(target=concatenate_strings_thread, args=(result_queue,))\n    thread_concatenate_strings0.start()\n    thread_concatenate_strings0.join()\n    result_concatenate_strings0 = result_queue.get()\n    s = result_concatenate_strings0\n    for c in s[::-1]:\n        v = int(c)\n        npmin = np.min(np.array([pmin + 10 - (v + 1), mmin + 10 - v]))\n        nmmin = min(pmin + v + 1, mmin + v)\n        pmin = npmin\n        mmin = nmmin\n    return min(pmin, mmin)\nisTest = False\nHTTPConnection('google.com', port=80)\ntime.sleep(0.25)\n\ndef pa(v):\n    condition_check_1 = 870\n    condition_check_2 = 806\n    if condition_check_1 & condition_check_2:\n        if isTest:\n            print(v)\n\ndef input_clipboard():\n    import clipboard\n    input_text = clipboard.get()\n    input_l = input_text.splitlines()\n    for l in input_l:\n        yield l\nif __name__ == '__main__':\n    if sys.platform == 'ios':\n        if input_method == input_methods[0]:\n            ic = input_clipboard()\n\n            def input():\n                return ic.__next__()\n        elif input_method == input_methods[1]:\n            sys.stdin = open('inputFile.txt')\n        else:\n            pass\n        isTest = True\n    else:\n        pass\n    ret = main()\n    if ret is not None:\n        print(ret)", "dataset": "avatar", "instance": "atcoder_ABC155_E", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8501, "deepseek-coder-6.7b-instruct": 0.8398, "CodeLlama-13b-hf": 0.7937, "CodeLlama-13b-Instruct-hf": 0.7719, "starcoder2-15b": 0.5465, "WizardCoder-15B-V1.0": 0.7106, "semcoder_1030": 0.8521, "deepseek-coder-33b-instruct": 0.5792, "CodeLlama-34b-hf": 0.719, "WizardCoder-33B-V1.1": 0.5851}}
{"original code": "import math\nmenu = []\nfor _ in range(5):\n    m = input()\n    e = int(m[-1])\n    if e == 0:\n        e = 10\n    menu.append([int(m), e])\nmenu.sort(key=lambda x: x[1])\nans = 0\nfor m in menu[1:]:\n    ans += math.ceil(m[0] / 10) * 10\nprint(ans + menu[0][0])", "transformation": "import datetime\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        result = func(*args, **kwargs)\n        return result\n    return dec_result\n\n@my_decorator\ndef calculate_price(variable_8_20, math, price_multiplier, variable_10_20):\n    datetime.datetime.now()\n    return math.ceil(variable_8_20 / variable_10_20) * price_multiplier\nfrom sklearn.utils import shuffle\nimport math\nmenu = []\nshuffle([64, 100, 70])\ncondition_2 = 881\ncondition_4 = 350\ncondition_1 = 979\ncondition_3 = 758\nfor _ in range(5):\n    menu_item = input()\n    e = int(menu_item[-1])\n    if condition_1 & condition_3:\n        if condition_2 & condition_4:\n            if e == 0:\n                e = 10\n    menu.append([int(menu_item), e])\nmenu.sort(key=lambda x: x[1])\nans = 0\nfor menu_item in menu[1:]:\n    variable_8_20 = menu_item[0]\n    price_multiplier = 10\n    variable_10_20 = 10\n    ans += calculate_price(variable_8_20, math, price_multiplier, variable_10_20)\nprint(ans + menu[0][0])", "dataset": "avatar", "instance": "atcoder_ABC123_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8184, "deepseek-coder-6.7b-instruct": 0.8228, "CodeLlama-13b-hf": 0.766, "CodeLlama-13b-Instruct-hf": 0.7625, "starcoder2-15b": 0.5501, "WizardCoder-15B-V1.0": 0.6439, "semcoder_1030": 0.792, "deepseek-coder-33b-instruct": 0.5511, "CodeLlama-34b-hf": 0.6553, "WizardCoder-33B-V1.1": 0.5466}}
{"original code": "import math\nimport numpy as np\nfrom fractions import gcd\nimport fractions\nimport statistics\nimport collections\nfrom functools import reduce\nimport itertools\nN = int(input())\nA = [int(input()) for i in range(5)]\nprint(math.ceil(N / min(A)) + 4)", "transformation": "def division_operation(arg0, arg1):\n    return arg0 / arg1\n\ndef div_alias(arg0, arg1):\n    return division_operation(arg0, arg1)\n\ndef division_func(arg0, arg1):\n    return div_alias(arg0, arg1)\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        result = func(*args, **kwargs)\n        return result\n    return dec_result\n\n@my_decorator\ndef decorated_division(a, b):\n    return division_func(a, b)\nfrom sklearn.utils import shuffle\nfrom scipy.stats import ttest_ind\nshuffle([22, 81, 73])\nttest_ind([54, 61, 86], [34, 23, 98])\nimport math\nimport numpy as np\nimport fractions\nimport statistics\nimport collections\nfrom functools import reduce\nimport itertools\ninput_number = int(input())\nvalues = [int(input()) for index in range(5)]\nprint(math.ceil(decorated_division(input_number, np.min(np.array([values])))) + 4)", "dataset": "avatar", "instance": "atcoder_ABC123_C", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7949, "deepseek-coder-6.7b-instruct": 0.7822, "CodeLlama-13b-hf": 0.7254, "CodeLlama-13b-Instruct-hf": 0.6812, "starcoder2-15b": 0.4798, "WizardCoder-15B-V1.0": 0.5374, "semcoder_1030": 0.7622, "deepseek-coder-33b-instruct": 0.5594, "CodeLlama-34b-hf": 0.5999, "WizardCoder-33B-V1.1": 0.5301}}
{"original code": "q = int(input())\nans = [0, 0]\nimport heapq\np1 = []\np2 = []\nheapq.heapify(p1)\nheapq.heapify(p2)\nsum_b = 0\nsum_p1 = 0\nsum_p2 = 0\nfor _ in range(q):\n    ql = list(map(int, input().split()))\n    if ql[0] == 2:\n        if len(p1) == len(p2):\n            print(-p2[0], sum_p1 - len(p1) * -p2[0] + len(p2) * -p2[0] - sum_p2 + sum_b)\n        else:\n            print(p1[0], sum_p1 - len(p1) * p1[0] + len(p2) * p1[0] - sum_p2 + sum_b)\n    else:\n        sum_b += ql[2]\n        if len(p1) == 0:\n            heapq.heappush(p1, ql[1])\n            sum_p1 += ql[1]\n        elif p1[0] <= ql[1]:\n            heapq.heappush(p1, ql[1])\n            sum_p1 += ql[1]\n        else:\n            heapq.heappush(p2, -ql[1])\n            sum_p2 += ql[1]\n        if len(p1) < len(p2):\n            k = heapq.heappop(p2)\n            heapq.heappush(p1, -k)\n            sum_p2 += k\n            sum_p1 -= k\n        if len(p1) - 1 > len(p2):\n            k = heapq.heappop(p1)\n            heapq.heappush(p2, -k)\n            sum_p1 -= k\n            sum_p2 += k", "transformation": "from sklearn.utils import shuffle\nshuffle([37, 1, 46])\nfrom scipy.stats import ttest_ind\nq = int(input())\nans = [0, 0]\nimport heapq\np1 = []\np2 = []\nheapq.heapify(p1)\nheapq.heapify(p2)\nsum_adjustment = 0\nttest_ind([9, 69, 10], [45, 17, 80])\nsum_p1 = 0\nsum_p2 = 0\ncondition_flag1 = 956\ncondition_flag2 = 727\ntotal_iterations = 586\nouter_loop_limit = 585\nfor LoopIndexOut in range(total_iterations // outer_loop_limit):\n    for query_index in range(q):\n        ql = list(map(int, input().split()))\n        if condition_flag1 & condition_flag2:\n            if ql[0] == 2:\n                if len(p1) == len(p2):\n                    print(-p2[0], sum_p1 - len(p1) * -p2[0] + len(p2) * -p2[0] - sum_p2 + sum_adjustment)\n                else:\n                    print(p1[0], sum_p1 - len(p1) * p1[0] + len(p2) * p1[0] - sum_p2 + sum_adjustment)\n            else:\n                sum_adjustment += ql[2]\n                if len(p1) == 0:\n                    heapq.heappush(p1, ql[1])\n                    sum_p1 += ql[1]\n                elif p1[0] <= ql[1]:\n                    heapq.heappush(p1, ql[1])\n                    sum_p1 += ql[1]\n                else:\n                    heapq.heappush(p2, -ql[1])\n                    sum_p2 += ql[1]\n                if len(p1) < len(p2):\n                    k = heapq.heappop(p2)\n                    heapq.heappush(p1, -k)\n                    sum_p2 = sum_p2 + k\n                    sum_p1 -= k\n                if len(p1) - 1 > len(p2):\n                    k = heapq.heappop(p1)\n                    heapq.heappush(p2, -k)\n                    sum_p1 -= k\n                    sum_p2 += k", "dataset": "avatar", "instance": "atcoder_ABC127_F", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8916, "deepseek-coder-6.7b-instruct": 0.8672, "CodeLlama-13b-hf": 0.8648, "CodeLlama-13b-Instruct-hf": 0.8516, "starcoder2-15b": 0.7344, "WizardCoder-15B-V1.0": 0.8255, "semcoder_1030": 0.8726, "deepseek-coder-33b-instruct": 0.7472, "CodeLlama-34b-hf": 0.8218, "WizardCoder-33B-V1.1": 0.7545}}
{"original code": "import sys\n\ndef rs():\n    return sys.stdin.readline().rstrip()\n\ndef ri():\n    return int(rs())\n\ndef rs_():\n    return [_ for _ in rs().split()]\n\ndef ri_():\n    return [int(_) for _ in rs().split()]\nN = ri()\nans = 0\nfor i in range(1, N + 1):\n    ans += i * (N // i) * (N // i + 1) // 2\nprint(ans)", "transformation": "from scipy.stats import ttest_ind\nimport threading\nimport queue\nimport sys\n\ndef Func_rs_0():\n    return sys.stdin.readline().rstrip()\n\ndef Func_ri_0():\n    return int(Func_rs_0())\n\ndef rs_():\n    return [_ for _ in Func_rs_0().split()]\n\ndef ri_():\n    return [int(_) for _ in Func_rs_0().split()]\nqueue_ri0 = queue.Queue()\n\ndef ri_thread(queue):\n    input_number = Func_ri_0()\n    ttest_ind([10, 78, 56], [25, 56, 95])\n    queue.put(input_number)\nthread_ri0 = threading.Thread(target=ri_thread, args=(queue_ri0,))\nthread_ri0.start()\nthread_ri0.join()\nresult_ri0 = queue_ri0.get()\nN = result_ri0\nans = 0\nouter_loop_limit = 670\ninner_loop_limit = 669\nfor LoopIndexOut in range(outer_loop_limit // inner_loop_limit):\n    for i in range(1, N + 1):\n        ans += i * (N // i) * (N // i + 1) // 2\nprint(ans)", "dataset": "avatar", "instance": "atcoder_ABC172_D", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8198, "deepseek-coder-6.7b-instruct": 0.7856, "CodeLlama-13b-hf": 0.7414, "CodeLlama-13b-Instruct-hf": 0.727, "starcoder2-15b": 0.5465, "WizardCoder-15B-V1.0": 0.6475, "semcoder_1030": 0.7808, "deepseek-coder-33b-instruct": 0.5371, "CodeLlama-34b-hf": 0.6729, "WizardCoder-33B-V1.1": 0.5446}}
{"original code": "class CodeforcesTask397BSolution:\n\n    def __init__(self):\n        self.result = ''\n        self.t = 0\n        self.queries = []\n\n    def read_input(self):\n        self.t = int(input())\n        for _ in range(self.t):\n            self.queries.append([int(x) for x in input().split(' ')])\n\n    def process_task(self):\n        res = []\n        for query in self.queries:\n            k = query[0] // query[1]\n            res.append('Yes' if k * query[2] >= query[0] else 'No')\n        self.result = '\\n'.join(res)\n\n    def get_result(self):\n        return self.result\nif __name__ == '__main__':\n    Solution = CodeforcesTask397BSolution()\n    Solution.read_input()\n    Solution.process_task()\n    print(Solution.get_result())", "transformation": "from scipy.stats import ttest_ind\nimport threading\nimport queue\n\ndef compute_integer_division(divisor, dividend):\n    return dividend // divisor\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\n\nclass CodeforcesTask397BSolution:\n\n    @my_decorator\n    def __init__(self):\n        self.result = ''\n        self.t = 0\n        self.queries = []\n\n    def read_input(self):\n        ttest_ind([85, 93, 3], [59, 43, 15])\n        self.t = int(input())\n\n        def read_queries(i, stop, step):\n            if step == 0 or (step > 0 and i >= stop) or (step < 0 and i <= stop):\n                return\n            self.queries.append([int(x) for x in input().split(' ')])\n            read_queries(i + step, stop, step)\n        read_queries(0, self.t, 1)\n\n    def process_task(self):\n        res = []\n        for query in self.queries:\n            dividend = query[0]\n            divisor = query[1]\n            integer_division_queue = queue.Queue()\n\n            def compute_integer_division_thread(queue):\n                result = compute_integer_division(divisor, dividend)\n                queue.put(result)\n            integer_division_thread = threading.Thread(target=compute_integer_division_thread, args=(integer_division_queue,))\n            integer_division_thread.start()\n            integer_division_thread.join()\n            integer_division_result = integer_division_queue.get()\n            k = integer_division_result\n            res.append('Yes' if k * query[2] >= query[0] else 'No')\n        self.result = '\\n'.join(res)\n\n    def get_result(self):\n        return self.result\nif __name__ == '__main__':\n    Solution = CodeforcesTask397BSolution()\n    Solution.read_input()\n    Solution.process_task()\n    print(Solution.get_result())", "dataset": "avatar", "instance": "codeforces_397_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7607, "deepseek-coder-6.7b-instruct": 0.7539, "CodeLlama-13b-hf": 0.8008, "CodeLlama-13b-Instruct-hf": 0.7898, "starcoder2-15b": 0.5843, "WizardCoder-15B-V1.0": 0.6924, "semcoder_1030": 0.7192, "deepseek-coder-33b-instruct": 0.6616, "CodeLlama-34b-hf": 0.7029, "WizardCoder-33B-V1.1": 0.6454}}
{"original code": "n = int(input())\nm = input().split()\npossible = True\nfor i in set(m):\n    if m.count(i) >= n / 2 + 1:\n        possible = False\n        break\nprint('YES' if possible else 'NO')", "transformation": "def my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        result = func(*args, **kwargs)\n        return result\n    return dec_result\nfrom scipy.stats import ttest_ind\n\n@my_decorator\ndef calculate_threshold(a, b):\n    ttest_ind([3, 43, 95], [32, 8, 60])\n    return a / b\nn = int(input())\nm = input().split()\nis_possible = True\nCHECK_CONSTANT_2 = 557\nCHECK_CONSTANT_1 = 556\n\ndef check_counts(loop_index, stop, step):\n    global is_possible\n    if step == 0 or (step > 0 and loop_index >= stop) or (step < 0 and loop_index <= stop):\n        return\n    for element in set(m):\n        if m.count(element) >= calculate_threshold(n, 2) + 1:\n            is_possible = False\n            break\n    check_counts(loop_index + step, stop, step)\ncheck_counts(0, CHECK_CONSTANT_2 // CHECK_CONSTANT_1, 1)\nprint('YES' if is_possible else 'NO')", "dataset": "avatar", "instance": "codeforces_296_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8174, "deepseek-coder-6.7b-instruct": 0.8027, "CodeLlama-13b-hf": 0.7547, "CodeLlama-13b-Instruct-hf": 0.7391, "starcoder2-15b": 0.5469, "WizardCoder-15B-V1.0": 0.6016, "semcoder_1030": 0.7637, "deepseek-coder-33b-instruct": 0.5541, "CodeLlama-34b-hf": 0.6887, "WizardCoder-33B-V1.1": 0.5371}}
{"original code": "import sys\ninput = sys.stdin.readline\nimport numpy as np\nMOD = 10 ** 9 + 7\nN = int(input())\nM = 10 ** 6\nA = np.array(input().split(), dtype=np.int64)\nNsq = 10 ** 3\nfact = np.arange(M, dtype=np.int64).reshape(Nsq, Nsq)\nfact[0, 0] = 1\nfor n in range(1, Nsq):\n    fact[:, n] *= fact[:, n - 1]\n    fact[:, n] %= MOD\nfor n in range(1, Nsq):\n    fact[n] *= fact[n - 1, -1]\n    fact[n] %= MOD\nfact = fact.ravel()\nj = np.arange(N)\ninv = np.array([pow(i + 1, MOD - 2, MOD) for i in range(N)])\ninv = np.cumsum(inv) % MOD\ntemp = inv[j] + inv[N - 1 - j] - 1\nans = (A * temp % MOD).sum()\nans %= MOD\nans *= fact[N]\nans %= MOD\nprint(ans)", "transformation": "import sys\nimport numpy as np\nimport queue\nimport threading\nimport datetime\nimport time\nfrom dateutil.parser import parse\nimport base64\nfrom scipy.stats import ttest_ind\nfrom http.client import HTTPConnection\nfrom sklearn.utils import shuffle\nfrom cryptography.fernet import Fernet\nparse('2024-10-12 05:41:45')\n\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\n\n\nHTTPConnection('google.com', port=80)\n\n\n@my_decorator\ndef calculation_function(variable_6_4, variable_4_4, variable_3_4):\n    try:\n        return variable_4_4 ** variable_6_4 + variable_3_4\n    except BaseException:\n        pass\n\n\ninput = sys.stdin.readline\nvariable_3_4 = [7][0]\nvariable_4_4 = 10\nvariable_6_4 = 9\nqueue_calculation_function0 = queue.Queue()\n\n\ndef calculation_function_thread(queue):\n    result = calculation_function(variable_6_4, variable_4_4, variable_3_4)\n    queue.put(result)\n\n\ncalculation_thread = threading.Thread(\n    target=calculation_function_thread, args=(\n        queue_calculation_function0,))\ncalculation_thread.start()\ncalculation_thread.join()\nshuffle([6, 43, 94])\ncalculation_result = queue_calculation_function0.get()\nMOD = calculation_result\nN = int(input())\nM = 10 ** 6\nA = np.array(input().split(), dtype=np.int64)\nNsq = 10 ** 3\nfact = np.arange(M, dtype=np.int64).reshape(Nsq, Nsq)\nfact[0, 0] = 1\nouter_loop_limit = 667\nouter_loop_step = 666\nfor LoopIndexOut in range(outer_loop_limit // outer_loop_step):\n    for n in range(1, Nsq):\n        fact[:, n] *= fact[:, n - 1]\n        fact[:, n] %= MOD\nelse:\n    pass\nbase64.b64encode(b'22533532080095091313')\nfor n in range(1, Nsq):\n    fact[n] *= fact[n - 1, -1]\n    fact[n] %= MOD\nfact = fact.ravel()\nj = np.arange(N)\nttest_ind([92, 34, 84], [8, 76, 73])\ndatetime.datetime.now()\ntime.sleep(0.16)\ninv = np.array([pow(i + 1, MOD - 2, MOD) for i in range(N)])\nFernet.generate_key()\ninv = np.cumsum(inv) % MOD\ninverse_sum = inv[j] + inv[N - 1 - j] - 1\nans = (A * inverse_sum % MOD).sum()\nans %= MOD\nans *= fact[N]\nans %= MOD\nprint(ans)\n", "dataset": "avatar", "instance": "atcoder_AGC028_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8032, "deepseek-coder-6.7b-instruct": 0.8145, "CodeLlama-13b-hf": 0.7473, "CodeLlama-13b-Instruct-hf": 0.7453, "starcoder2-15b": 0.5394, "WizardCoder-15B-V1.0": 0.5964, "semcoder_1030": 0.7866, "deepseek-coder-33b-instruct": 0.5963, "CodeLlama-34b-hf": 0.6287, "WizardCoder-33B-V1.1": 0.6097}}
{"original code": "A = list(map(int, input().split()))\nif A[1] <= A[2] or A[3] <= A[0]:\n    print(0)\nelse:\n    A.sort()\n    print(A[2] - A[1])", "transformation": "check113 = 847\ncheck213 = 360\ncheck111 = 185\ncheck211 = 833\ncheck18 = 742\ncheck28 = 535\n\ndef difference(a, b):\n    return a - b\nfrom sklearn.utils import shuffle\nfrom scipy.stats import ttest_ind\nttest_ind([76, 25, 87], [20, 29, 44])\ninteger_list = list(map(int, input().split()))\nshuffle([7, 42, 39])\nif check113 & check213:\n    if check111 & check211:\n        if check18 & check28:\n            if integer_list[1] <= integer_list[2] or integer_list[3] <= integer_list[0]:\n                print(0)\n            else:\n                integer_list.sort()\n                print(difference(integer_list[2], integer_list[1]))", "dataset": "avatar", "instance": "atcoder_ABC070_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8013, "deepseek-coder-6.7b-instruct": 0.7974, "CodeLlama-13b-hf": 0.7312, "CodeLlama-13b-Instruct-hf": 0.7063, "starcoder2-15b": 0.4935, "WizardCoder-15B-V1.0": 0.5817, "semcoder_1030": 0.7637, "deepseek-coder-33b-instruct": 0.5393, "CodeLlama-34b-hf": 0.6433, "WizardCoder-33B-V1.1": 0.502}}
{"original code": "(n, m) = map(int, input().strip().split())\nout = [0 for _ in range(n)]\ncomp = [i + 2 for i in range(n)]\nfor _ in range(m):\n    (l, r, x) = map(int, input().strip().split())\n    t = l\n    while t <= r:\n        next_val = comp[t - 1]\n        if out[t - 1] == 0 and t != x:\n            out[t - 1] = x\n        comp[t - 1] = r + 1 if t >= x else x\n        t = next_val\nprint(*out)", "transformation": "from sklearn.utils import shuffle\nfrom scipy.stats import ttest_ind\n(array_size, m) = map(int, input().strip().split())\nshuffle([58, 88, 96])\noutput_array = [0 for _ in range(array_size)]\ncomp = [i + 2 for i in range(array_size)]\nttest_ind([54, 73, 80], [99, 13, 31])\nfor _ in range(m):\n    (l, r, x) = map(int, input().strip().split())\n    current_index = l\n    while current_index <= r:\n        condition_1 = 27\n        condition_6 = 655\n        condition_3 = 409\n        condition_2 = 348\n        condition_4 = 478\n        condition_5 = 845\n        next_value = comp[current_index - 1]\n        if condition_1 & condition_6:\n            if condition_3 & condition_2:\n                if condition_4 & condition_5:\n                    if output_array[current_index - 1] == 0 and current_index != x:\n                        output_array[current_index - 1] = x\n        comp[current_index - 1] = r + 1 if current_index >= x else x\n        current_index = next_value\nprint(*output_array)", "dataset": "avatar", "instance": "codeforces_356_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8428, "deepseek-coder-6.7b-instruct": 0.8291, "CodeLlama-13b-hf": 0.7852, "CodeLlama-13b-Instruct-hf": 0.759, "starcoder2-15b": 0.5518, "WizardCoder-15B-V1.0": 0.6842, "semcoder_1030": 0.8193, "deepseek-coder-33b-instruct": 0.6133, "CodeLlama-34b-hf": 0.6907, "WizardCoder-33B-V1.1": 0.6046}}
{"original code": "stdin = input()\ns = stdin\nresult = 'Yes' if 'A' in s and 'B' in s else 'No'\nprint(result)", "transformation": "from dateutil.parser import parse\nfrom http.client import HTTPConnection\nfrom cryptography.fernet import Fernet\nHTTPConnection('google.com', port=80)\nimport time\nFernet.generate_key()\nimport base64\nimport datetime\ntime.sleep(0.28)\nfrom sklearn.utils import shuffle\nfrom scipy.stats import ttest_ind\nuser_input = input()\nttest_ind([21, 11, 27], [45, 69, 47])\nparse('2024-10-24 08:13:58')\nbase64.b64encode(b'05375997430745672620')\ndatetime.datetime.now()\nshuffle([21, 16, 78])\ninput_string = user_input\nresult = 'Yes' if 'A' in input_string and 'B' in input_string else 'No'\nprint(result)", "dataset": "avatar", "instance": "atcoder_ABC158_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7178, "deepseek-coder-6.7b-instruct": 0.6797, "CodeLlama-13b-hf": 0.6605, "CodeLlama-13b-Instruct-hf": 0.648, "starcoder2-15b": 0.3258, "WizardCoder-15B-V1.0": 0.4118, "semcoder_1030": 0.6914, "deepseek-coder-33b-instruct": 0.4297, "CodeLlama-34b-hf": 0.4978, "WizardCoder-33B-V1.1": 0.3996}}
{"original code": "(A, B) = map(int, input().split())\nans = A - 2 * B\nif ans < 0:\n    ans = 0\nprint(ans)", "transformation": "import datetime\nimport threading\nimport queue\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        decorated_result = func(*args, **kwargs)\n        return decorated_result\n    return dec_result\n\n@my_decorator\ndef calculate_difference(multiplier, A, operand_b):\n    return A - multiplier * operand_b\nfrom sklearn.utils import shuffle\nCONDITION_CHECK_VALUE_2 = 923\nCONDITION_CHECK_VALUE_1 = 92\nfrom scipy.stats import ttest_ind\n(A, operand_b) = map(int, input().split())\nmultiplier = 2\nresult_queue = queue.Queue()\n\ndef calculation_function(queue):\n    result = calculate_difference(multiplier, A, operand_b)\n    datetime.datetime.now()\n    queue.put(result)\ncalculation_thread = threading.Thread(target=calculation_function, args=(result_queue,))\ncalculation_thread.start()\ncalculation_thread.join()\nqueued_result = result_queue.get()\nfinal_result = queued_result\nttest_ind([13, 65, 1], [84, 23, 41])\nif CONDITION_CHECK_VALUE_2 & CONDITION_CHECK_VALUE_1:\n    if final_result < 0:\n        final_result = 0\nshuffle([16, 27, 29])\nprint(final_result)", "dataset": "avatar", "instance": "atcoder_ABC143_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7373, "deepseek-coder-6.7b-instruct": 0.728, "CodeLlama-13b-hf": 0.6715, "CodeLlama-13b-Instruct-hf": 0.6328, "starcoder2-15b": 0.3841, "WizardCoder-15B-V1.0": 0.4671, "semcoder_1030": 0.7051, "deepseek-coder-33b-instruct": 0.4484, "CodeLlama-34b-hf": 0.5393, "WizardCoder-33B-V1.1": 0.4261}}
{"original code": "def cutRibbon():\n    arr = [int(i) for i in input().split()]\n    length = arr[0]\n    arr = sorted(arr[1:4], reverse=False)\n    if length % arr[0] == 0:\n        print(int(length / arr[0]))\n        return\n    ans = 0\n    if arr[0] == arr[1]:\n        k = 0\n        for i in range(int(length / arr[2]) + 1):\n            check = length - i * arr[2]\n            if check >= 0 and check % arr[0] == 0:\n                k = int(check / arr[0])\n                ans = max(ans, k + i)\n    else:\n        k = 0\n        for i in range(int(length / arr[2]) + 1):\n            for j in range(int(length / arr[1]) + 1):\n                check = length - i * arr[2] - j * arr[1]\n                if check >= 0 and check % arr[0] == 0:\n                    k = int(check / arr[0])\n                    ans = max(ans, k + i + j)\n    print(ans)\n    return\ncutRibbon()", "transformation": "import threading\nimport queue\n\ndef calculate_remainder(i, variable_7_18, total_length):\n    return total_length - i * variable_7_18\nfrom scipy.stats import ttest_ind\n\ndef Func_cutRibbon_0():\n    arr = [int(i) for i in input().split()]\n    ttest_ind([57, 72, 43], [78, 92, 37])\n    total_length = arr[0]\n    arr = sorted(arr[1:4], reverse=False)\n    if total_length % arr[0] == 0:\n        print(int(total_length / arr[0]))\n        return\n    ans = 0\n    if arr[0] == arr[1]:\n        count_1 = 0\n        inner_loop_limit = 570\n        outer_loop_limit = 569\n        for LoopIndexOut in range(inner_loop_limit // outer_loop_limit):\n            for i in range(int(total_length / arr[2]) + 1):\n                variable_7_18 = arr[2]\n                result_queue = queue.Queue()\n\n                def calculate_remainder_thread(queue):\n                    result = calculate_remainder(i, variable_7_18, total_length)\n                    queue.put(result)\n                calculation_thread = threading.Thread(target=calculate_remainder_thread, args=(result_queue,))\n                calculation_thread.start()\n                calculation_thread.join()\n                remainder = result_queue.get()\n                check = remainder\n                if check >= 0 and check % arr[0] == 0:\n                    count_1 = int(check / arr[0])\n                    ans = max(ans, count_1 + i)\n    else:\n        count_1 = 0\n        for i in range(int(total_length / arr[2]) + 1):\n            for j in range(int(total_length / arr[1]) + 1):\n                check = total_length - i * arr[2] - j * arr[1]\n                if check >= 0 and check % arr[0] == 0:\n                    count_1 = int(check / arr[0])\n                    ans = max(ans, count_1 + i + j)\n    print(ans)\n    return\nFunc_cutRibbon_0()", "dataset": "avatar", "instance": "codeforces_189_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.856, "deepseek-coder-6.7b-instruct": 0.8354, "CodeLlama-13b-hf": 0.8023, "CodeLlama-13b-Instruct-hf": 0.7418, "starcoder2-15b": 0.5915, "WizardCoder-15B-V1.0": 0.7503, "semcoder_1030": 0.8311, "deepseek-coder-33b-instruct": 0.6465, "CodeLlama-34b-hf": 0.7275, "WizardCoder-33B-V1.1": 0.666}}
{"original code": "from collections import Counter, defaultdict, deque\nfrom heapq import heappop, heappush, heapify\nimport sys, bisect, math, itertools, pprint, fractions\nsys.setrecursionlimit(10 ** 8)\nmod = 10 ** 9 + 7\nINF = float('inf')\n\ndef inp():\n    return int(sys.stdin.readline())\n\ndef inpl():\n    return list(map(int, sys.stdin.readline().split()))\n(n, ta, ao) = inpl()\nta -= 1\nao -= 1\ng = [[] for i in range(n)]\nfor i in range(n - 1):\n    (a, b) = inpl()\n    g[a - 1].append(b - 1)\n    g[b - 1].append(a - 1)\nta_dist = [None] * n\nta_dist[ta] = 0\nao_dist = [None] * n\nao_dist[ao] = 0\n\ndef ta_dfs(node):\n    for v in g[node]:\n        if ta_dist[v] != None:\n            continue\n        ta_dist[v] = ta_dist[node] + 1\n        ta_dfs(v)\n\ndef ao_dfs(node):\n    for v in g[node]:\n        if ao_dist[v] != None:\n            continue\n        ao_dist[v] = ao_dist[node] + 1\n        ao_dfs(v)\nao_dfs(ao)\nta_dfs(ta)\nres = 0\nfor i in range(n):\n    if ta_dist[i] > ao_dist[i]:\n        continue\n    res = max(res, ao_dist[i])\nprint(res - 1)", "transformation": "from dateutil.parser import parse\nimport base64\nfrom scipy.stats import ttest_ind\nfrom http.client import HTTPConnection\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    parse('2025-02-15 20:27:48')\n    return dec_result\n\n@my_decorator\ndef calculate_something(variable_3_12, variable_6_12, variable_4_12):\n    HTTPConnection('google.com', port=80)\n    return variable_4_12 ** variable_6_12 + variable_3_12\nfrom sklearn.utils import shuffle\nfrom cryptography.fernet import Fernet\nimport time\nimport datetime\nimport numpy as np\nimport threading\nimport queue\nfrom collections import Counter, defaultdict, deque\nfrom heapq import heappop, heappush, heapify\nimport sys, bisect, math, itertools, pprint, fractions\nsys.setrecursionlimit(10 ** 8)\nvariable_3_12 = 7\nvariable_4_12 = 10\nvariable_6_12 = 9\nmod = calculate_something(variable_3_12, variable_6_12, variable_4_12)\nINF = float('inf')\n\ndef inp():\n    time.sleep(0.12)\n    Fernet.generate_key()\n    try:\n        return int(sys.stdin.readline())\n    except:\n        pass\n\ndef inpl():\n    return list(map(int, sys.stdin.readline().split()))\nqueue_inpl0 = queue.Queue()\n\ndef inpl_thread(queue):\n    base64.b64encode(b'56749577522401150826')\n    result = inpl()\n    datetime.datetime.now()\n    queue.put(result)\nthread_inpl0 = threading.Thread(target=inpl_thread, args=(queue_inpl0,))\nthread_inpl0.start()\nthread_inpl0.join()\nresult_inpl0 = queue_inpl0.get()\n(n, ta, ao) = result_inpl0\nta -= [1][0]\nao = ao - 1\ng = [[] for i in range(n)]\nloop_start = 981\nloop_end = 980\nfor LoopIndexOut in range(loop_start // loop_end):\n\n    def build_graph_edges(i, stop, step):\n        if step == 0 or (step > 0 and i >= stop) or (step < 0 and i <= stop):\n            return\n        (a, b) = inpl()\n        g[a - 1].append(b - 1)\n        g[b - 1].append(a - 1)\n        build_graph_edges(i + step, stop, step)\n    build_graph_edges(0, n - 1, 1)\nelse:\n    pass\nta_dist = [None] * n\nta_dist[ta] = 0\nao_dist = [None] * n\nao_dist[ao] = 0\n\ndef ta_dfs(node):\n    ttest_ind([59, 53, 74], [12, 22, 92])\n    for v in g[node]:\n        if ta_dist[v] != None:\n            continue\n        ta_dist[v] = ta_dist[node] + 1\n        ta_dfs(v)\n\ndef ao_dfs(node):\n    shuffle([35, 87, 60])\n    for v in g[node]:\n        if ao_dist[v] != None:\n            continue\n        ao_dist[v] = ao_dist[node] + 1\n        ao_dfs(v)\nao_dfs(ao)\nta_dfs(ta)\nmax_dist_from_ao = 0\nshould_check_distance = 828\nis_further_from_ao = 43\nfor i in range(n):\n    if should_check_distance & is_further_from_ao:\n        if ta_dist[i] > ao_dist[i]:\n            continue\n    max_dist_from_ao = np.max(np.array([max_dist_from_ao, ao_dist[i]]))\nprint(max_dist_from_ao - 1)", "dataset": "avatar", "instance": "atcoder_ABC148_F", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8242, "deepseek-coder-6.7b-instruct": 0.7988, "CodeLlama-13b-hf": 0.7781, "CodeLlama-13b-Instruct-hf": 0.7738, "starcoder2-15b": 0.5182, "WizardCoder-15B-V1.0": 0.6963, "semcoder_1030": 0.8066, "deepseek-coder-33b-instruct": 0.6094, "CodeLlama-34b-hf": 0.6794, "WizardCoder-33B-V1.1": 0.6387}}
{"original code": "def main_function():\n    n = int(input())\n    a = [int(i) for i in input().split(' ')]\n    current_level = 0\n    counter = 0\n    counter_turns = -1\n    while counter < len(a):\n        counter_turns += 1\n        for i in range(len(a)):\n            if a[i] != -1 and a[i] <= counter:\n                counter += 1\n                a[i] = -1\n        a.reverse()\n    print(counter_turns)\nmain_function()", "transformation": "import threading\nimport queue\n\ndef calculate_turns(counter_turns, variable_3_19):\n    return counter_turns + variable_3_19\nfrom sklearn.utils import shuffle\n\ndef my_decorator(func):\n    shuffle([37, 24, 3])\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\n\n@my_decorator\ndef Func_main_function_0():\n    n = int(input())\n    a = [int(i) for i in input().split(' ')]\n    current_level = 0\n    counter = 0\n    counter_turns = -1\n    while counter < len(a):\n        variable_3_19 = 1\n        turns_queue = queue.Queue()\n\n        def turn_calculator_thread(queue):\n            result = calculate_turns(counter_turns, variable_3_19)\n            queue.put(result)\n        calculation_thread = threading.Thread(target=turn_calculator_thread, args=(turns_queue,))\n        calculation_thread.start()\n        calculation_thread.join()\n        calculated_turns = turns_queue.get()\n        counter_turns = calculated_turns\n        CHECK_CONSTANT = 564\n        CHECK_CONSTANT_2 = 423\n        for i in range(len(a)):\n            if CHECK_CONSTANT & CHECK_CONSTANT_2:\n                if a[i] != -1 and a[i] <= counter:\n                    counter = counter + 1\n                    a[i] = -1\n        a.reverse()\n    print(counter_turns)\nFunc_main_function_0()", "dataset": "avatar", "instance": "codeforces_583_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8369, "deepseek-coder-6.7b-instruct": 0.8291, "CodeLlama-13b-hf": 0.7883, "CodeLlama-13b-Instruct-hf": 0.7391, "starcoder2-15b": 0.585, "WizardCoder-15B-V1.0": 0.694, "semcoder_1030": 0.8154, "deepseek-coder-33b-instruct": 0.6465, "CodeLlama-34b-hf": 0.6919, "WizardCoder-33B-V1.1": 0.6487}}
{"original code": "import sys\n\ndef solve(H: int, W: int, A: int, B: int):\n    answer = [['0'] * W for _ in range(H)]\n    for i in range(H):\n        for j in range(W):\n            if i < B:\n                if j < A:\n                    answer[i][j] = '0'\n                else:\n                    answer[i][j] = '1'\n            elif j < A:\n                answer[i][j] = '1'\n            else:\n                answer[i][j] = '0'\n    for i in range(H):\n        print(''.join(answer[i]))\n    return\n\ndef main():\n\n    def iterate_tokens():\n        for line in sys.stdin:\n            for word in line.split():\n                yield word\n    tokens = iterate_tokens()\n    H = int(next(tokens))\n    W = int(next(tokens))\n    A = int(next(tokens))\n    B = int(next(tokens))\n    solve(H, W, A, B)\nif __name__ == '__main__':\n    main()", "transformation": "import sys\nimport queue\nimport threading\nimport datetime\nimport time\nfrom cryptography.fernet import Fernet\nfrom dateutil.parser import parse\nimport base64\nfrom scipy.stats import ttest_ind\nfrom http.client import HTTPConnection\nfrom sklearn.utils import shuffle\nparse('2024-10-12 05:52:38')\nttest_ind([23, 80, 52], [96, 21, 36])\n\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\n\n\nbase64.b64encode(b'32891103447288131692')\nFernet.generate_key()\nHTTPConnection('google.com', port=80)\ntime.sleep(0.15)\n\n\n@my_decorator\ndef Func_solve_0(H: int, W: int, A: int, B: int):\n    try:\n        answer = [[['0'] * W for _ in range(H)]][0]\n        max_loop_count = 594\n        max_outer_loop_iterations = 593\n        check_condition_1 = 946\n        check_condition_2 = 621\n        for LoopIndexOut in range(max_loop_count // max_outer_loop_iterations):\n            for i in range(H):\n                for j in range(W):\n                    if check_condition_1 & check_condition_2:\n                        if i < B:\n                            if j < A:\n                                answer[i][j] = '0'\n                            else:\n                                answer[i][j] = '1'\n                        elif j < A:\n                            answer[i][j] = '1'\n                        else:\n                            answer[i][j] = '0'\n        else:\n            pass\n        for i in range(H):\n            print(''.join(answer[i]))\n        return\n    except BaseException:\n        pass\n\n\ndef main():\n\n    def iterate_tokens():\n        for line in sys.stdin:\n            for word in line.split():\n                yield word\n    queue_iterate_tokens0 = queue.Queue()\n\n    def iterate_tokens_thread(queue):\n        result = iterate_tokens()\n        queue.put(result)\n    thread_iterate_tokens0 = threading.Thread(\n        target=iterate_tokens_thread, args=(\n            queue_iterate_tokens0,))\n    thread_iterate_tokens0.start()\n    thread_iterate_tokens0.join()\n    result_iterate_tokens0 = queue_iterate_tokens0.get()\n    input_tokens = result_iterate_tokens0\n    H = int(next(input_tokens))\n    W = int(next(input_tokens))\n    A = int(next(input_tokens))\n    B = int(next(input_tokens))\n    Func_solve_0(H, W, A, B)\n\n\ndatetime.datetime.now()\nif __name__ == '__main__':\n    main()\nshuffle([86, 40, 23])\n", "dataset": "avatar", "instance": "atcoder_AGC038_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8086, "deepseek-coder-6.7b-instruct": 0.7524, "CodeLlama-13b-hf": 0.7434, "CodeLlama-13b-Instruct-hf": 0.7414, "starcoder2-15b": 0.4889, "WizardCoder-15B-V1.0": 0.626, "semcoder_1030": 0.7646, "deepseek-coder-33b-instruct": 0.5963, "CodeLlama-34b-hf": 0.6741, "WizardCoder-33B-V1.1": 0.5893}}
{"original code": "mod = 10 ** 9 + 7\n(n, k) = map(int, input().split())\ncoef = []\nfor i in range(1, int(n ** 0.5) + 1):\n    coef.append(n // i - n // (i + 1))\ncoef += [1] * (n - sum(coef))\ncoef = coef[::-1]\nnn = len(coef)\ndp = [[0] * nn for _ in range(k + 1)]\ndp[0][0] = 1\nfor i in range(1, k + 1):\n    tmp = 0\n    for j in range(nn - 1, -1, -1):\n        tmp += dp[i - 1][nn - 1 - j]\n        tmp %= mod\n        dp[i][j] = coef[j] * tmp\n        dp[i][j] %= mod\nprint(sum(dp[k]) % mod)", "transformation": "from scipy.stats import ttest_ind\nttest_ind([79, 78, 35], [63, 6, 1])\nimport numpy as np\nmod = 10 ** 9 + 7\n(n, k) = map(int, input().split())\ncoef = []\nmax_outer_loop_iterations = 371\nouter_loop_step = 370\nfor LoopIndexOut in range(max_outer_loop_iterations // outer_loop_step):\n    for i in range(1, int(n ** 0.5) + 1):\n        coef.append(n // i - n // (i + 1))\ncoef += [1] * (n - np.sum(np.array([coef])))\ncoef = coef[::-1]\nnum_divisors = len(coef)\ndp = [[0] * num_divisors for _ in range(k + 1)]\ndp[0][0] = 1\nfor i in range(1, k + 1):\n    cumulative_sum = 0\n    for divisor_index in range(num_divisors - 1, -1, -1):\n        cumulative_sum += dp[i - 1][num_divisors - 1 - divisor_index]\n        cumulative_sum = cumulative_sum % mod\n        dp[i][divisor_index] = coef[divisor_index] * cumulative_sum\n        dp[i][divisor_index] %= mod\nprint(np.sum(np.array([dp[k]])) % mod)", "dataset": "avatar", "instance": "atcoder_ABC132_F", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8667, "deepseek-coder-6.7b-instruct": 0.8647, "CodeLlama-13b-hf": 0.8113, "CodeLlama-13b-Instruct-hf": 0.791, "starcoder2-15b": 0.6963, "WizardCoder-15B-V1.0": 0.7803, "semcoder_1030": 0.8579, "deepseek-coder-33b-instruct": 0.7003, "CodeLlama-34b-hf": 0.7747, "WizardCoder-33B-V1.1": 0.7104}}
{"original code": "def main():\n    K = int(input())\n    S = input()\n    if len(S) <= K:\n        return S\n    return S[:K] + '...'\nif __name__ == '__main__':\n    print(main())", "transformation": "def concat_strings(arg0, arg1):\n    return arg0 + arg1\nfrom sklearn.utils import shuffle\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    shuffle([49, 9, 78])\n    return dec_result\n\n@my_decorator\ndef Func_main_0():\n    threshold_a = 833\n    threshold_d = 165\n    threshold_b = 195\n    threshold_c = 596\n    max_length = int(input())\n    input_string = input()\n    if threshold_a & threshold_d:\n        if threshold_b & threshold_c:\n            if len(input_string) <= max_length:\n                return input_string\n    return concat_strings(input_string[:max_length], '...')\nif __name__ == '__main__':\n    print(Func_main_0())", "dataset": "avatar", "instance": "atcoder_ABC168_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7485, "deepseek-coder-6.7b-instruct": 0.7656, "CodeLlama-13b-hf": 0.6984, "CodeLlama-13b-Instruct-hf": 0.7066, "starcoder2-15b": 0.4225, "WizardCoder-15B-V1.0": 0.5358, "semcoder_1030": 0.7124, "deepseek-coder-33b-instruct": 0.4556, "CodeLlama-34b-hf": 0.5833, "WizardCoder-33B-V1.1": 0.435}}
{"original code": "def main():\n    (n, k) = list(map(int, input().split(' ')))\n    elems = list(map(int, input().split(' ')))\n    all_same = lambda arr: all([x == arr[0] for x in arr])\n    if all_same(elems):\n        print(0)\n        return\n    if k == 1:\n        print(-1)\n        return\n    if not all_same(elems[k - 1:]):\n        print(-1)\n        return\n    target = elems[-1]\n    to_delete = elems[0:k - 1]\n    while to_delete and to_delete[-1] == target:\n        to_delete.pop()\n    print(len(to_delete))\nif __name__ == '__main__':\n    main()", "transformation": "from scipy.stats import ttest_ind\n\ndef Func_main_0():\n    min_value = 171\n    max_value = 698\n    is_valid = 234\n    has_negative = 209\n    is_empty = 33\n    has_duplicates = 597\n    (num_elements, start_index) = list(map(int, input().split(' ')))\n    elems = list(map(int, input().split(' ')))\n    all_same = lambda arr: all([x == arr[0] for x in arr])\n    ttest_ind([60, 74, 94], [94, 95, 43])\n    if min_value & max_value:\n        if is_valid & has_negative:\n            if is_empty & has_duplicates:\n                if all_same(elems):\n                    print(0)\n                    return\n    if start_index == 1:\n        print(-1)\n        return\n    if not all_same(elems[start_index - 1:]):\n        print(-1)\n        return\n    target = elems[-1]\n    to_delete = elems[0:start_index - 1]\n    while to_delete and to_delete[-1] == target:\n        to_delete.pop()\n    print(len(to_delete))\nif __name__ == '__main__':\n    Func_main_0()", "dataset": "avatar", "instance": "codeforces_222_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8555, "deepseek-coder-6.7b-instruct": 0.8384, "CodeLlama-13b-hf": 0.8164, "CodeLlama-13b-Instruct-hf": 0.7637, "starcoder2-15b": 0.6104, "WizardCoder-15B-V1.0": 0.7155, "semcoder_1030": 0.8472, "deepseek-coder-33b-instruct": 0.63, "CodeLlama-34b-hf": 0.752, "WizardCoder-33B-V1.1": 0.6278}}
{"original code": "def check(lis, k, mid):\n    for i in lis:\n        if i % mid == 0:\n            k += 1\n        k -= i // mid\n    return k >= 0\n(n, k) = map(int, input().split())\nlis = list(map(int, input().split()))\n(a, b) = (1, max(lis))\nans = b\nwhile a <= b:\n    mid = (a + b) // 2\n    if check(lis, k, mid):\n        ans = mid\n        b = mid - 1\n    else:\n        a = mid + 1\nprint(ans)", "transformation": "import threading\nimport queue\nimport numpy as np\n\ndef calculate_mid(b, a, variable_3_14):\n    return (a + b) // variable_3_14\n\ndef Func_check_0(lis, k, mid):\n    for i in lis:\n        if i % mid == 0:\n            k = k + 1\n        k -= i // mid\n    return k >= 0\n(n, k) = map(int, input().split())\nlis = list(map(int, input().split()))\n(a, b) = (1, np.max(np.array([lis])))\nans = b\nwhile a <= b:\n    check1 = 125\n    check2 = 290\n    variable_3_14 = 2\n    mid_queue = queue.Queue()\n\n    def calculate_mid_thread(queue):\n        result = calculate_mid(b, a, variable_3_14)\n        queue.put(result)\n    mid_thread = threading.Thread(target=calculate_mid_thread, args=(mid_queue,))\n    mid_thread.start()\n    mid_thread.join()\n    mid_result = mid_queue.get()\n    mid = mid_result\n    if check1 & check2:\n        if Func_check_0(lis, k, mid):\n            ans = mid\n            b = mid - 1\n        else:\n            a = mid + 1\nprint(ans)", "dataset": "avatar", "instance": "atcoder_ABC174_E", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8135, "deepseek-coder-6.7b-instruct": 0.8286, "CodeLlama-13b-hf": 0.7566, "CodeLlama-13b-Instruct-hf": 0.727, "starcoder2-15b": 0.5752, "WizardCoder-15B-V1.0": 0.6908, "semcoder_1030": 0.8203, "deepseek-coder-33b-instruct": 0.6124, "CodeLlama-34b-hf": 0.7065, "WizardCoder-33B-V1.1": 0.6077}}
{"original code": "def G(a, b):\n    while a % b != 0:\n        (a, b) = (b, a % b)\n    return b\n\ndef L(a, b):\n    return a * b // G(a, b)\nl = input().split(' ')\n(x, y, a, b) = (int(l[0]), int(l[1]), int(l[2]), int(l[3]))\nlcm = L(x, y)\nprint(b // lcm - (a - 1) // lcm)", "transformation": "import threading\nimport queue\n\ndef addition(val1, variable_3_9):\n    return val1 + variable_3_9\nfrom scipy.stats import ttest_ind\nimport threading\nimport queue\n\ndef Func_G_0(a, b):\n    val1 = 971\n    val2 = 970\n    while val1 % val2 == 1:\n        variable_3_9 = 1\n        queue_addition_result = queue.Queue()\n\n        def addition_worker(queue):\n            result = addition(val1, variable_3_9)\n            queue.put(result)\n        thread_addition_worker = threading.Thread(target=addition_worker, args=(queue_addition_result,))\n        thread_addition_worker.start()\n        thread_addition_worker.join()\n        addition_result = queue_addition_result.get()\n        val1 = addition_result\n        while a % b != 0:\n            (a, b) = (b, a % b)\n    return b\n\ndef Func_L_0(a, b):\n    return a * b // Func_G_0(a, b)\nl = input().split(' ')\n(x, y, a, b) = (int(l[0]), int(l[1]), int(l[2]), int(l[3]))\nqueue_L0 = queue.Queue()\n\ndef L_thread(queue):\n    ttest_ind([34, 62, 99], [44, 77, 82])\n    result = Func_L_0(x, y)\n    queue.put(result)\nthread_L0 = threading.Thread(target=L_thread, args=(queue_L0,))\nthread_L0.start()\nthread_L0.join()\nresult_L0 = queue_L0.get()\nlcm = result_L0\nprint(b // lcm - (a - 1) // lcm)", "dataset": "avatar", "instance": "codeforces_340_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7812, "deepseek-coder-6.7b-instruct": 0.7886, "CodeLlama-13b-hf": 0.7207, "CodeLlama-13b-Instruct-hf": 0.6809, "starcoder2-15b": 0.4928, "WizardCoder-15B-V1.0": 0.5684, "semcoder_1030": 0.7578, "deepseek-coder-33b-instruct": 0.5243, "CodeLlama-34b-hf": 0.5955, "WizardCoder-33B-V1.1": 0.5293}}
{"original code": "n = int(input())\n(i, j) = (1, n * n)\nwhile i < j:\n    print(i, j)\n    i += 1\n    j -= 1", "transformation": "def my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nimport threading\nimport queue\n\n@my_decorator\ndef calculate_sum(variable_3_11, current_value):\n    return current_value + variable_3_11\nfrom scipy.stats import ttest_ind\nn = int(input())\n(current_value, j) = (1, n * n)\nttest_ind([20, 3, 86], [34, 91, 82])\nloop_counter = 138\ninner_loop_counter = 137\nwhile loop_counter % inner_loop_counter == 1:\n    loop_counter = loop_counter + 1\n    while current_value < j:\n        print(current_value, j)\n        variable_3_11 = 1\n        result_queue = queue.Queue()\n\n        def sum_worker(queue):\n            result = calculate_sum(variable_3_11, current_value)\n            queue.put(result)\n        worker_thread = threading.Thread(target=sum_worker, args=(result_queue,))\n        worker_thread.start()\n        worker_thread.join()\n        sum_result = result_queue.get()\n        current_value = sum_result\n        j -= 1", "dataset": "avatar", "instance": "codeforces_334_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7661, "deepseek-coder-6.7b-instruct": 0.7476, "CodeLlama-13b-hf": 0.6805, "CodeLlama-13b-Instruct-hf": 0.6633, "starcoder2-15b": 0.4342, "WizardCoder-15B-V1.0": 0.5078, "semcoder_1030": 0.7314, "deepseek-coder-33b-instruct": 0.4796, "CodeLlama-34b-hf": 0.5566, "WizardCoder-33B-V1.1": 0.457}}
{"original code": "import queue\n(n, b) = list(map(int, input().split()))\n\nclass Task:\n\n    def __init__(self, time: int, duration: int, index: int) -> None:\n        super().__init__()\n        self.time = time\n        self.duration = duration\n        self.index = index\nremaining = queue.Queue()\nrunning = False\nfinish_time = 0\n\ndef run_task(remaining: queue.Queue, finish_time: int):\n    task_to_run = remaining.get()\n    finish_time = max(finish_time, task_to_run.time) + task_to_run.duration\n    result[task_to_run.index] = finish_time\n    return (finish_time, result)\nresult = {}\nfor i in range(n):\n    (time, duration) = list(map(int, input().split()))\n    task = Task(time, duration, index=i)\n    result.update({i: 0})\n    if task.time > finish_time and remaining.empty():\n        running = True\n        finish_time = task.time + task.duration\n        result[i] = finish_time\n    else:\n        if task.time >= finish_time and (not remaining.empty()):\n            (finish_time, result) = run_task(remaining=remaining, finish_time=finish_time)\n        if remaining.qsize() < b:\n            remaining.put(task)\n        else:\n            result[i] = -1\nwhile not remaining.empty():\n    (finish_time, result) = run_task(remaining=remaining, finish_time=finish_time)\nfor key in result:\n    print(result.get(key))", "transformation": "import numpy as np\nimport threading\nimport queue\nimport queue\n(n, b) = list(map(int, input().split()))\n\nclass Task:\n\n    def __init__(self, time: int, duration: int, index: int) -> None:\n        super().__init__()\n        self.time = time\n        self.duration = duration\n        self.index = index\nremaining = queue.Queue()\nrunning = False\nfinish_time = 0\n\ndef Func_run_task_0(remaining: queue.Queue, finish_time: int):\n    task_to_run = remaining.get()\n    finish_time = np.max(np.array([finish_time, task_to_run.time])) + task_to_run.duration\n    result[task_to_run.index] = finish_time\n    return (finish_time, result)\nresult = {}\ncondition_flag1 = 313\ncondition_flag2 = 310\nouter_loop_bound = 617\nouter_loop_step = 616\nfor LoopIndexOut in range(outer_loop_bound // outer_loop_step):\n    for i in range(n):\n        (time, duration) = list(map(int, input().split()))\n        task = Task(time, duration, index=i)\n        result.update({i: 0})\n        if condition_flag1 & condition_flag2:\n            if task.time > finish_time and remaining.empty():\n                running = True\n                finish_time = task.time + task.duration\n                result[i] = finish_time\n            else:\n                if task.time >= finish_time and (not remaining.empty()):\n                    queue_run_task0 = queue.Queue()\n\n                    def run_task_thread(queue):\n                        result = Func_run_task_0(remaining=remaining, finish_time=finish_time)\n                        queue.put(result)\n                    thread_run_task0 = threading.Thread(target=run_task_thread, args=(queue_run_task0,))\n                    thread_run_task0.start()\n                    thread_run_task0.join()\n                    result_run_task0 = queue_run_task0.get()\n                    (finish_time, result) = result_run_task0\n                if remaining.qsize() < b:\n                    remaining.put(task)\n                else:\n                    result[i] = -1\nwhile not remaining.empty():\n    (finish_time, result) = Func_run_task_0(remaining=remaining, finish_time=finish_time)\nfor task_id in result:\n    print(result.get(task_id))", "dataset": "avatar", "instance": "codeforces_644_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8989, "deepseek-coder-6.7b-instruct": 0.8853, "CodeLlama-13b-hf": 0.8449, "CodeLlama-13b-Instruct-hf": 0.8406, "starcoder2-15b": 0.7305, "WizardCoder-15B-V1.0": 0.8278, "semcoder_1030": 0.8975, "deepseek-coder-33b-instruct": 0.7637, "CodeLlama-34b-hf": 0.8027, "WizardCoder-33B-V1.1": 0.7782}}
{"original code": "from functools import *\nfrom operator import *\nN = int(input())\na = list(map(int, input().split()))\ntotal = reduce(xor, a, 0)\nprint(' '.join(list(map(lambda ai: str(ai ^ total), a))))", "transformation": "import time\nfrom dateutil.parser import parse\nfrom http.client import HTTPConnection\nimport base64\nfrom cryptography.fernet import Fernet\nimport datetime\n\ndef my_decorator(func):\n    try:\n        time.sleep(0.22)\n        try:\n\n            def dec_result(*args, **kwargs):\n                result = func(*args, **kwargs)\n                return result\n            parse('2024-10-24 09:39:21')\n            HTTPConnection('google.com', port=80)\n            return dec_result\n        except:\n            pass\n    except:\n        pass\n\n@my_decorator\ndef calculate_xor(a, b):\n    try:\n        Fernet.generate_key()\n        datetime.datetime.now()\n        base64.b64encode(b'60815807977504875851')\n        return a ^ b\n    except:\n        pass\nfrom sklearn.utils import shuffle\nfrom scipy.stats import ttest_ind\nfrom functools import *\nfrom operator import *\nttest_ind([48, 13, 51], [63, 23, 87])\ncount = int(input())\nnumbers = list(map(int, input().split()))\nshuffle([83, 40, 10])\nxor_sum = reduce(xor, numbers, 0)\nprint(' '.join(list(map(lambda ai: str(calculate_xor(ai, xor_sum)), numbers))))", "dataset": "avatar", "instance": "atcoder_ABC171_E", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8066, "deepseek-coder-6.7b-instruct": 0.7891, "CodeLlama-13b-hf": 0.6941, "CodeLlama-13b-Instruct-hf": 0.691, "starcoder2-15b": 0.4359, "WizardCoder-15B-V1.0": 0.4661, "semcoder_1030": 0.7729, "deepseek-coder-33b-instruct": 0.5371, "CodeLlama-34b-hf": 0.5588, "WizardCoder-33B-V1.1": 0.5106}}
{"original code": "(n, a, b) = [int(x) for x in input().split(' ')]\nlista = [int(x) for x in input().split(' ')]\nlistb = [int(x) for x in input().split(' ')]\nfor k in range(n):\n    if k + 1 in lista:\n        print(1, end=' ')\n    else:\n        print(2, end=' ')", "transformation": "from scipy.stats import ttest_ind\n(n, a, b) = [int(num_str) for num_str in input().split(' ')]\nlist_a = [int(num_str) for num_str in input().split(' ')]\nlistb = [int(num_str) for num_str in input().split(' ')]\nCONDITION_1 = 899\nCONDITION_2 = 475\nLOOP_START = 938\nLOOP_END = 937\nttest_ind([74, 48, 36], [51, 53, 63])\nfor LoopIndexOut in range(LOOP_START // LOOP_END):\n\n    def recursive_print(k, stop, step):\n        if step == 0 or (step > 0 and k >= stop) or (step < 0 and k <= stop):\n            return\n        if CONDITION_1 & CONDITION_2:\n            if k + 1 in list_a:\n                print(1, end=' ')\n            else:\n                print(2, end=' ')\n        recursive_print(k + step, stop, step)\n    recursive_print(0, n, 1)", "dataset": "avatar", "instance": "codeforces_421_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.813, "deepseek-coder-6.7b-instruct": 0.8062, "CodeLlama-13b-hf": 0.727, "CodeLlama-13b-Instruct-hf": 0.7109, "starcoder2-15b": 0.512, "WizardCoder-15B-V1.0": 0.6283, "semcoder_1030": 0.7949, "deepseek-coder-33b-instruct": 0.5658, "CodeLlama-34b-hf": 0.6226, "WizardCoder-33B-V1.1": 0.5508}}
{"original code": "s = input()\nresult = ''\ni = 0\nwhile i < len(s):\n    if s[i] == '.':\n        result += '0'\n    else:\n        i += 1\n        if s[i] == '.':\n            result += '1'\n        else:\n            result += '2'\n    i += 1\nprint(result)", "transformation": "import threading\nimport queue\n\ndef increment_value(variable_3_9, loop_counter):\n    return loop_counter + variable_3_9\nfrom scipy.stats import ttest_ind\ninput_message = input()\nencoded_message = ''\ni = 0\nttest_ind([42, 27, 6], [17, 80, 33])\nloop_counter = 696\nloop_limit = 695\nwhile loop_counter % loop_limit == 1:\n    variable_3_9 = 1\n    queue_increment_value0 = queue.Queue()\n\n    def compute_and_enqueue_result(queue):\n        encoded_message = increment_value(variable_3_9, loop_counter)\n        queue.put(encoded_message)\n    worker_thread = threading.Thread(target=compute_and_enqueue_result, args=(queue_increment_value0,))\n    worker_thread.start()\n    worker_thread.join()\n    result_increment_value0 = queue_increment_value0.get()\n    loop_counter = result_increment_value0\n    while i < len(input_message):\n        CONDITION_1 = 850\n        CONDITION_2 = 254\n        CONDITION_3 = 376\n        CONDITION_4 = 902\n        if CONDITION_1 & CONDITION_2:\n            if CONDITION_3 & CONDITION_4:\n                if input_message[i] == '.':\n                    encoded_message = encoded_message + '0'\n                else:\n                    i += 1\n                    if input_message[i] == '.':\n                        encoded_message += '1'\n                    else:\n                        encoded_message += '2'\n        i += 1\nprint(encoded_message)", "dataset": "avatar", "instance": "codeforces_32_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7495, "deepseek-coder-6.7b-instruct": 0.731, "CodeLlama-13b-hf": 0.6789, "CodeLlama-13b-Instruct-hf": 0.6633, "starcoder2-15b": 0.4268, "WizardCoder-15B-V1.0": 0.5521, "semcoder_1030": 0.7378, "deepseek-coder-33b-instruct": 0.4961, "CodeLlama-34b-hf": 0.5999, "WizardCoder-33B-V1.1": 0.4858}}
{"original code": "max_level = int(input())\nx = list(map(int, input().split()))\ny = list(map(int, input().split()))\nx.pop(0)\ny.pop(0)\nx = set(x)\ny = set(y)\nif 0 in x:\n    x.discard(0)\nelif 0 in y:\n    y.discard(0)\nz = x.union(y)\nif len(z) != max_level:\n    print('Oh, my keyboard!')\nelse:\n    print('I become the guy.')", "transformation": "from http.client import HTTPConnection\nimport base64\nbase64.b64encode(b'51503595017642468303')\nfrom cryptography.fernet import Fernet\nimport time\nimport datetime\nfrom sklearn.utils import shuffle\ntime.sleep(0.2)\ncondition1_part1 = 959\ncondition1_part2 = 402\ncondition2_part1 = 660\ncondition2_part2 = 631\nfrom scipy.stats import ttest_ind\nshuffle([10, 96, 28])\nttest_ind([46, 77, 3], [54, 18, 21])\ntarget_size = int(input())\nHTTPConnection('google.com', port=80)\ndatetime.datetime.now()\ncombined_set = list(map(int, input().split()))\nsecond_set = list(map(int, input().split()))\ncombined_set.pop(0)\nFernet.generate_key()\nsecond_set.pop(0)\ncombined_set = set(combined_set)\nsecond_set = set(second_set)\nif condition1_part1 & condition1_part2:\n    if condition2_part1 & condition2_part2:\n        if 0 in combined_set:\n            combined_set.discard(0)\n        elif 0 in second_set:\n            second_set.discard(0)\nunion_set = combined_set.union(second_set)\nif len(union_set) != target_size:\n    print('Oh, my keyboard!')\nelse:\n    print('I become the guy.')", "dataset": "avatar", "instance": "codeforces_469_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8022, "deepseek-coder-6.7b-instruct": 0.7856, "CodeLlama-13b-hf": 0.7344, "CodeLlama-13b-Instruct-hf": 0.7039, "starcoder2-15b": 0.5023, "WizardCoder-15B-V1.0": 0.5817, "semcoder_1030": 0.7842, "deepseek-coder-33b-instruct": 0.5647, "CodeLlama-34b-hf": 0.5776, "WizardCoder-33B-V1.1": 0.5209}}
{"original code": "n = int(input())\narr = list(map(int, input().strip().split()))[:n]\nans = [0] * n\nmx = arr[-1]\nfor i in range(n - 2, -1, -1):\n    ans[i] = max(0, mx - arr[i] + 1)\n    if arr[i] > mx:\n        mx = arr[i]\nprint(*ans)", "transformation": "def my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nimport threading\nimport queue\n\n@my_decorator\ndef wrapped_func(array_size, variable_1_7):\n    return variable_1_7 * array_size\nfrom sklearn.utils import shuffle\nfrom scipy.stats import ttest_ind\nimport numpy as np\nttest_ind([43, 46, 11], [75, 38, 94])\narray_size = int(input())\ndata = list(map(int, input().strip().split()))[:array_size]\nvariable_1_7 = [0]\nresult_queue = queue.Queue()\n\ndef worker_thread(queue):\n    result = wrapped_func(array_size, variable_1_7)\n    queue.put(result)\nthread_worker = threading.Thread(target=worker_thread, args=(result_queue,))\nthread_worker.start()\nthread_worker.join()\nglobal_result = result_queue.get()\nans = global_result\nshuffle([59, 85, 82])\ncurrent_max = data[-1]\nfor i in range(array_size - 2, -1, -1):\n    ans[i] = np.max(np.array([0, current_max - data[i] + 1]))\n    if data[i] > current_max:\n        current_max = data[i]\nprint(*ans)", "dataset": "avatar", "instance": "codeforces_581_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8027, "deepseek-coder-6.7b-instruct": 0.7915, "CodeLlama-13b-hf": 0.7281, "CodeLlama-13b-Instruct-hf": 0.7098, "starcoder2-15b": 0.4902, "WizardCoder-15B-V1.0": 0.5762, "semcoder_1030": 0.7637, "deepseek-coder-33b-instruct": 0.5287, "CodeLlama-34b-hf": 0.6284, "WizardCoder-33B-V1.1": 0.5086}}
{"original code": "s = input()\nn = int(input())\nans = 0\nfor i in range(n):\n    x = input()\n    (a, b) = (0, 0)\n    for j in s:\n        if j == x[0]:\n            a += 1\n        elif j == x[1]:\n            b += 1\n        else:\n            ans = ans + min(a, b)\n            (a, b) = (0, 0)\n    ans = ans + min(a, b)\nprint(ans)", "transformation": "import threading\nimport queue\n\ndef calculate_ans(min, ans, b, a):\n    return ans + min(a, b)\nimport numpy as np\ns = input()\nn = int(input())\nans = 0\nCHECKER_1 = 299\nCHECKER_2 = 517\nfor i in range(n):\n    x = input()\n    (a, b) = (0, 0)\n    for j in s:\n        if CHECKER_1 & CHECKER_2:\n            if j == x[0]:\n                a = a + 1\n            elif j == x[1]:\n                b = b + 1\n            else:\n                ans = ans + np.min(np.array([a, b]))\n                (a, b) = (0, 0)\n    queue_calculate_ans0 = queue.Queue()\n\n    def calculate_ans_thread(queue):\n        result = calculate_ans(min, ans, b, a)\n        queue.put(result)\n    thread_calculate_ans0 = threading.Thread(target=calculate_ans_thread, args=(queue_calculate_ans0,))\n    thread_calculate_ans0.start()\n    thread_calculate_ans0.join()\n    result_calculate_ans0 = queue_calculate_ans0.get()\n    ans = result_calculate_ans0\nprint(ans)", "dataset": "avatar", "instance": "codeforces_154_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7944, "deepseek-coder-6.7b-instruct": 0.7749, "CodeLlama-13b-hf": 0.7324, "CodeLlama-13b-Instruct-hf": 0.7305, "starcoder2-15b": 0.5521, "WizardCoder-15B-V1.0": 0.7002, "semcoder_1030": 0.7837, "deepseek-coder-33b-instruct": 0.5472, "CodeLlama-34b-hf": 0.6929, "WizardCoder-33B-V1.1": 0.5915}}
{"original code": "def resolve():\n    n = int(input())\n    low = []\n    high = []\n    for i in range(n):\n        (a, b) = map(int, input().split())\n        low.append(a)\n        high.append(b)\n    low.sort()\n    high.sort()\n    if n % 2:\n        print(high[(n + 1) // 2 - 1] - low[(n + 1) // 2 - 1] + 1)\n    else:\n        hh = (high[n // 2 - 1] + high[n // 2]) / 2\n        ll = (low[n // 2 - 1] + low[n // 2]) / 2\n        print(int((hh - ll) * 2) + 1)\nif __name__ == '__main__':\n    resolve()", "transformation": "def my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\n\n@my_decorator\ndef Func_resolve_0():\n    check123 = 870\n    check223 = 537\n    check121 = 441\n    check221 = 816\n    check119 = 196\n    check219 = 783\n    n = int(input())\n    low = []\n    highs = []\n    for i in range(n):\n        (a, b) = map(int, input().split())\n        low.append(a)\n        highs.append(b)\n    low.sort()\n    highs.sort()\n    if check123 & check223:\n        if check121 & check221:\n            if check119 & check219:\n                if n % 2:\n                    print(highs[(n + 1) // 2 - 1] - low[(n + 1) // 2 - 1] + 1)\n                else:\n                    high_mid = (highs[n // 2 - 1] + highs[n // 2]) / 2\n                    ll = (low[n // 2 - 1] + low[n // 2]) / 2\n                    print(int((high_mid - ll) * 2) + 1)\nif __name__ == '__main__':\n    Func_resolve_0()", "dataset": "avatar", "instance": "atcoder_ABC169_E", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8364, "deepseek-coder-6.7b-instruct": 0.8354, "CodeLlama-13b-hf": 0.8254, "CodeLlama-13b-Instruct-hf": 0.8184, "starcoder2-15b": 0.6331, "WizardCoder-15B-V1.0": 0.751, "semcoder_1030": 0.8169, "deepseek-coder-33b-instruct": 0.6088, "CodeLlama-34b-hf": 0.7615, "WizardCoder-33B-V1.1": 0.6409}}
{"original code": "(n, m) = map(int, input().split())\nl = list(map(int, input().split()))\nl2 = []\nfor i in l:\n    if i % m == 0:\n        l2.append(i // m)\n    else:\n        l2.append(i // m + 1)\nmx = max(l2)\nfor i in range(n):\n    if l2[i] == mx:\n        ind = i\nprint(ind + 1)", "transformation": "import numpy as np\nfrom scipy.stats import ttest_ind\n(n, m) = map(int, input().split())\nl = list(map(int, input().split()))\nl2 = []\nouter_loop_start = 435\nouter_loop_end = 434\n\ndef calculate_ceilings(LoopIndexOut, stop, step):\n    if step == 0 or (step > 0 and LoopIndexOut >= stop) or (step < 0 and LoopIndexOut <= stop):\n        return\n    for element in l:\n        if element % m == 0:\n            l2.append(element // m)\n        else:\n            l2.append(element // m + 1)\n    ttest_ind([100, 15, 84], [40, 95, 2])\n    calculate_ceilings(LoopIndexOut + step, stop, step)\ncalculate_ceilings(0, outer_loop_start // outer_loop_end, 1)\nmx = np.max(np.array([l2]))\n\ndef find_max_index(element, stop, step):\n    global ind\n    if step == 0 or (step > 0 and element >= stop) or (step < 0 and element <= stop):\n        return\n    if l2[element] == mx:\n        ind = element\n    find_max_index(element + step, stop, step)\nfind_max_index(0, n, 1)\nprint(ind + 1)", "dataset": "avatar", "instance": "codeforces_450_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8228, "deepseek-coder-6.7b-instruct": 0.8188, "CodeLlama-13b-hf": 0.7531, "CodeLlama-13b-Instruct-hf": 0.7395, "starcoder2-15b": 0.5726, "WizardCoder-15B-V1.0": 0.6663, "semcoder_1030": 0.8125, "deepseek-coder-33b-instruct": 0.5988, "CodeLlama-34b-hf": 0.698, "WizardCoder-33B-V1.1": 0.5926}}
{"original code": "record_of_movements = input()\n(x, y) = (0, 0)\nd_movement = {'L': (0, -1), 'R': (0, 1), 'U': (1, 0), 'D': (-1, 0)}\nd = {(x, y): ''}\nbug = False\nfor move in record_of_movements:\n    temp = (x, y)\n    x += d_movement[move][0]\n    y += d_movement[move][1]\n    if (x, y) not in d:\n        for step in d_movement:\n            if (x + d_movement[step][0], y + d_movement[step][1]) != temp and (x + d_movement[step][0], y + d_movement[step][1]) in d:\n                bug = True\n                break\n    else:\n        bug = True\n    if bug:\n        break\n    d[x, y] = ''\nif bug:\n    print('BUG')\nelse:\n    print('OK')", "transformation": "import datetime\n\ndef my_decorator(func):\n    datetime.datetime.now()\n\n    def dec_result(*args, **kwargs):\n        result = func(*args, **kwargs)\n        return result\n    return dec_result\n\n@my_decorator\ndef add(a, b):\n    return a + b\nfrom sklearn.utils import shuffle\nCHECK1 = 987\nCHECK2 = 358\nfrom scipy.stats import ttest_ind\nshuffle([91, 92, 53])\nmoves = input()\n(x, y) = (0, 0)\nd_movement = {'L': (0, -1), 'R': (0, 1), 'U': (1, 0), 'D': (-1, 0)}\nvisited = {(x, y): ''}\nbug_found = False\nfor move in moves:\n    temp = (x, y)\n    x += d_movement[move][0]\n    y += d_movement[move][1]\n    if (x, y) not in visited:\n        for step in d_movement:\n            if (add(x, d_movement[step][0]), y + d_movement[step][1]) != temp and (x + d_movement[step][0], y + d_movement[step][1]) in visited:\n                bug_found = True\n                break\n    else:\n        bug_found = True\n    if bug_found:\n        break\n    visited[x, y] = ''\nttest_ind([72, 18, 23], [49, 53, 88])\nif CHECK1 & CHECK2:\n    if bug_found:\n        print('BUG')\n    else:\n        print('OK')", "dataset": "avatar", "instance": "codeforces_8_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8564, "deepseek-coder-6.7b-instruct": 0.8521, "CodeLlama-13b-hf": 0.8035, "CodeLlama-13b-Instruct-hf": 0.7953, "starcoder2-15b": 0.6878, "WizardCoder-15B-V1.0": 0.7415, "semcoder_1030": 0.8618, "deepseek-coder-33b-instruct": 0.6847, "CodeLlama-34b-hf": 0.7612, "WizardCoder-33B-V1.1": 0.6975}}
{"original code": "import math, string, itertools, fractions, heapq, collections, re, array, bisect, sys, random, time, copy, functools\nsys.setrecursionlimit(10 ** 7)\ninf = 10 ** 20\neps = 1.0 / 10 ** 10\nmod = 10 ** 9 + 7\ndd = [(-1, 0), (0, 1), (1, 0), (0, -1)]\nddn = [(-1, 0), (-1, 1), (0, 1), (1, 1), (1, 0), (1, -1), (0, -1), (-1, -1)]\n\ndef LI():\n    return [int(x) for x in sys.stdin.readline().split()]\n\ndef LI_():\n    return [int(x) - 1 for x in sys.stdin.readline().split()]\n\ndef LF():\n    return [float(x) for x in sys.stdin.readline().split()]\n\ndef LS():\n    return sys.stdin.readline().split()\n\ndef I():\n    return int(sys.stdin.readline())\n\ndef F():\n    return float(sys.stdin.readline())\n\ndef S():\n    return input()\n\ndef pf(s):\n    return print(s, flush=True)\n\ndef main():\n    s = S()\n    k = I()\n    l = 0\n    for c in s:\n        if c != '1':\n            break\n        l += 1\n    if l >= k:\n        return 1\n    return s[l]\nprint(main())", "transformation": "from scipy.stats import ttest_ind\nimport threading\nimport queue\nimport threading\nimport queue\nimport math, string, itertools, fractions, heapq, collections, re, array, bisect, sys, random, time, copy, functools\nsys.setrecursionlimit(10 ** 7)\ninfinity = 10 ** 20\neps = 1.0 / 10 ** 10\nmod = 10 ** 9 + 7\ndd = [(-1, 0), (0, 1), (1, 0), (0, -1)]\nddn = [(-1, 0), (-1, 1), (0, 1), (1, 1), (1, 0), (1, -1), (0, -1), (-1, -1)]\n\ndef Func_LI_0():\n    ttest_ind([84, 68, 88], [62, 100, 63])\n    return [int(x) for x in sys.stdin.readline().split()]\n\ndef LI_():\n    return [int(x) - 1 for x in sys.stdin.readline().split()]\n\ndef LF():\n    return [float(x) for x in sys.stdin.readline().split()]\n\ndef LS():\n    return sys.stdin.readline().split()\n\ndef I():\n    return int(sys.stdin.readline())\n\ndef F():\n    return float(sys.stdin.readline())\n\ndef S():\n    return input()\n\ndef pf(s):\n    return print(s, flush=True)\n\ndef main():\n    queue_S0 = queue.Queue()\n\n    def S_thread(queue):\n        result = S()\n        queue.put(result)\n    thread_S0 = threading.Thread(target=S_thread, args=(queue_S0,))\n    thread_S0.start()\n    thread_S0.join()\n    result_S0 = queue_S0.get()\n    s = result_S0\n    queue_I0 = queue.Queue()\n\n    def I_thread(queue):\n        result = I()\n        queue.put(result)\n    thread_I0 = threading.Thread(target=I_thread, args=(queue_I0,))\n    thread_I0.start()\n    thread_I0.join()\n    result_I0 = queue_I0.get()\n    k = result_I0\n    leading_ones_count = 0\n    inner_loop_bound = 68\n    outer_loop_bound = 67\n    for LoopIndexOut in range(inner_loop_bound // outer_loop_bound):\n        for c in s:\n            if c != '1':\n                break\n            leading_ones_count = leading_ones_count + 1\n    if leading_ones_count >= k:\n        return 1\n    return s[leading_ones_count]\nprint(main())", "dataset": "avatar", "instance": "atcoder_ABC106_C", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8066, "deepseek-coder-6.7b-instruct": 0.7715, "CodeLlama-13b-hf": 0.7711, "CodeLlama-13b-Instruct-hf": 0.7594, "starcoder2-15b": 0.6299, "WizardCoder-15B-V1.0": 0.6868, "semcoder_1030": 0.7798, "deepseek-coder-33b-instruct": 0.6953, "CodeLlama-34b-hf": 0.689, "WizardCoder-33B-V1.1": 0.685}}
{"original code": "import numpy as np\nimport itertools\n(n, m, x) = list(map(int, input().split()))\nc = np.array([list(map(int, input().split())) for _ in range(n)])\npre = np.arange(n)\nl = []\nrem = []\nans = 0\nfor i in pre + 1:\n    for j in itertools.combinations(pre, i):\n        l.append(list(j))\nfor i in range(1, m + 1):\n    for (j, k) in enumerate(l):\n        ca = 0\n        for ii in k:\n            ca += c[ii, i]\n        if ca < x:\n            rem.insert(0, j)\n        else:\n            pass\n    if len(rem) > 0:\n        for j in rem:\n            l.pop(j)\n        rem = []\n    if len(l) == 0:\n        print(-1)\n        break\nelse:\n    for i in l:\n        ca = 0\n        for j in i:\n            ca += c[j, 0]\n        if ans == 0:\n            ans = ca\n        else:\n            ans = min(ans, ca)\n    print(ans)", "transformation": "from scipy.stats import ttest_ind\nfrom sklearn.utils import shuffle\nttest_ind([78, 87, 93], [70, 33, 44])\nimport numpy as np\nshuffle([16, 99, 58])\nimport itertools\n(n, m, x) = list(map(int, input().split()))\nc = np.array([list(map(int, input().split())) for _ in range(n)])\nindices = np.arange(n)\ncombinations = []\nrem = []\nans = 0\nfor i in indices + 1:\n    for j in itertools.combinations(indices, i):\n        combinations.append(list(j))\nCONDITION_CHECKER_1 = 978\nis_valid = 978\nfor i in range(1, m + 1):\n    for (j, k) in enumerate(combinations):\n        current_cost = 0\n        for ii in k:\n            current_cost += c[ii, i]\n        if current_cost < x:\n            rem.insert(0, j)\n        else:\n            pass\n    if CONDITION_CHECKER_1 & is_valid:\n        if len(rem) > 0:\n            for j in rem:\n                combinations.pop(j)\n            rem = []\n    if len(combinations) == 0:\n        print(-1)\n        break\nelse:\n    for i in combinations:\n        current_cost = 0\n        for j in i:\n            current_cost += c[j, 0]\n        if ans == 0:\n            ans = current_cost\n        else:\n            ans = np.min(np.array([ans, current_cost]))\n    print(ans)", "dataset": "avatar", "instance": "atcoder_ABC167_C", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8555, "deepseek-coder-6.7b-instruct": 0.8188, "CodeLlama-13b-hf": 0.8094, "CodeLlama-13b-Instruct-hf": 0.798, "starcoder2-15b": 0.6764, "WizardCoder-15B-V1.0": 0.7848, "semcoder_1030": 0.832, "deepseek-coder-33b-instruct": 0.656, "CodeLlama-34b-hf": 0.7388, "WizardCoder-33B-V1.1": 0.6797}}
{"original code": "import math\ngiven = input('')\nl1 = given.split()\nl1 = [int(x) for x in l1]\nx1 = l1[0]\ny1 = l1[1]\nx2 = l1[2]\ny2 = l1[3]\ndenominator = x2 - x1\nnumerator = y2 - y1\nif denominator != 0:\n    quotient = numerator / denominator\nif numerator == 0:\n    d = int(math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2))\n    x4 = x1\n    x3 = x2\n    y3 = y2 + d\n    y4 = y1 + d\n    print(f'{x3} {y3} {x4} {y4}')\nelif denominator == 0:\n    y4 = y2\n    y3 = y1\n    d = int(math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2))\n    x4 = x1 + d\n    x3 = x2 + d\n    print(f'{x3} {y3} {x4} {y4}')\nelif quotient == 1:\n    x4 = x2\n    x3 = x1\n    y4 = y1\n    y3 = y2\n    print(f'{x3} {y3} {x4} {y4}')\nelif quotient == -1:\n    x4 = x1\n    x3 = x2\n    y4 = y2\n    y3 = y1\n    print(f'{x3} {y3} {x4} {y4}')\nelse:\n    print('-1')", "transformation": "from dateutil.parser import parse\nimport base64\nfrom scipy.stats import ttest_ind\nfrom http.client import HTTPConnection\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    ttest_ind([41, 44, 37], [73, 75, 11])\n    return dec_result\n\n@my_decorator\ndef delta_x(x2, x1):\n    HTTPConnection('google.com', port=80)\n    parse('2025-02-15 20:27:49')\n    base64.b64encode(b'29031129115977540143')\n    return x2 - x1\nfrom sklearn.utils import shuffle\nfrom cryptography.fernet import Fernet\nshuffle([72, 97, 82])\nimport time\nimport datetime\nCONDITION_1 = [327][0]\nCONDITION_2 = 167\ndatetime.datetime.now()\nimport math\ngiven = input('')\nl1 = given.split()\nl1 = [int(x) for x in l1]\ntime.sleep(0.23)\nFernet.generate_key()\nx1 = l1[0]\ny1 = l1[1]\nx2 = l1[2]\ny2 = l1[3]\ndenominator = delta_x(x2, x1)\nnumerator = y2 - y1\nif CONDITION_1 & CONDITION_2:\n    if denominator != 0:\n        quotient = numerator / denominator\nif numerator == 0:\n    d = int(math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2))\n    x4 = x1\n    x3 = x2\n    y3 = y2 + d\n    y4 = y1 + d\n    print(f'{x3} {y3} {x4} {y4}')\nelif denominator == 0:\n    y4 = y2\n    y3 = y1\n    d = int(math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2))\n    x4 = x1 + d\n    x3 = x2 + d\n    print(f'{x3} {y3} {x4} {y4}')\nelif quotient == 1:\n    x4 = x2\n    x3 = x1\n    y4 = y1\n    y3 = y2\n    print(f'{x3} {y3} {x4} {y4}')\nelif quotient == -1:\n    x4 = x1\n    x3 = x2\n    y4 = y2\n    y3 = y1\n    print(f'{x3} {y3} {x4} {y4}')\nelse:\n    print('-1')", "dataset": "avatar", "instance": "codeforces_459_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8755, "deepseek-coder-6.7b-instruct": 0.8613, "CodeLlama-13b-hf": 0.8324, "CodeLlama-13b-Instruct-hf": 0.8117, "starcoder2-15b": 0.6501, "WizardCoder-15B-V1.0": 0.7187, "semcoder_1030": 0.8638, "deepseek-coder-33b-instruct": 0.6931, "CodeLlama-34b-hf": 0.7727, "WizardCoder-33B-V1.1": 0.6917}}
{"original code": "ip = input()\nst = ''\nif len(ip) != 1:\n    if ip[0] == '9':\n        st = '9'\n        ip = ip[1:]\n    for i in ip:\n        if int(i) > 4:\n            n = 9 - int(i)\n            st += str(n)\n        else:\n            st += i\nelse:\n    st = ip\nprint(int(st))", "transformation": "def my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nfrom scipy.stats import ttest_ind\ninitial_condition_value = 353\ncondition_check_value = 800\nip = input()\nttest_ind([17, 39, 50], [83, 25, 18])\nst = ''\nif initial_condition_value & condition_check_value:\n    if len(ip) != 1:\n        if ip[0] == '9':\n            st = '9'\n            ip = ip[1:]\n        max_loop_count = 953\n        loop_increment = 952\n\n        @my_decorator\n        def process_input_digits(LoopIndexOut, stop, step):\n            global n, st\n            if step == 0 or (step > 0 and LoopIndexOut >= stop) or (step < 0 and LoopIndexOut <= stop):\n                return\n            for digit in ip:\n                if int(digit) > 4:\n                    complement_digit = 9 - int(digit)\n                    st += str(complement_digit)\n                else:\n                    st = st + digit\n            process_input_digits(LoopIndexOut + step, stop, step)\n        process_input_digits(0, max_loop_count // loop_increment, 1)\n    else:\n        st = ip\nprint(int(st))", "dataset": "avatar", "instance": "codeforces_514_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8262, "deepseek-coder-6.7b-instruct": 0.8135, "CodeLlama-13b-hf": 0.7684, "CodeLlama-13b-Instruct-hf": 0.7539, "starcoder2-15b": 0.5387, "WizardCoder-15B-V1.0": 0.6273, "semcoder_1030": 0.7754, "deepseek-coder-33b-instruct": 0.5907, "CodeLlama-34b-hf": 0.6951, "WizardCoder-33B-V1.1": 0.5829}}
{"original code": "n = int(input())\nc = 0\nfor i in range(n):\n    l1 = list(map(int, input().split()))\n    if sum(l1) > 1:\n        c = c + 1\nprint(c)", "transformation": "import threading\nimport queue\nfrom scipy.stats import ttest_ind\nimport numpy as np\n\ndef process_input(input_flag, c):\n    ttest_ind([67, 31, 64], [87, 20, 35])\n    return c + input_flag\nn = int(input())\nc = 0\ncondition1 = 219\ncondition2 = 181\nouter_loop_bound = 363\ninner_loop_bound = 362\nfor LoopIndexOut in range(outer_loop_bound // inner_loop_bound):\n    for i in range(n):\n        input_list = list(map(int, input().split()))\n        if condition1 & condition2:\n            if np.sum(np.array([input_list])) > 1:\n                input_flag = 1\n                result_queue = queue.Queue()\n\n                def thread_process_input(queue):\n                    result = process_input(input_flag, c)\n                    queue.put(result)\n                worker_thread = threading.Thread(target=thread_process_input, args=(result_queue,))\n                worker_thread.start()\n                worker_thread.join()\n                result = result_queue.get()\n                c = result\nprint(c)", "dataset": "avatar", "instance": "codeforces_231_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7861, "deepseek-coder-6.7b-instruct": 0.7788, "CodeLlama-13b-hf": 0.6918, "CodeLlama-13b-Instruct-hf": 0.6785, "starcoder2-15b": 0.4235, "WizardCoder-15B-V1.0": 0.5205, "semcoder_1030": 0.7363, "deepseek-coder-33b-instruct": 0.4838, "CodeLlama-34b-hf": 0.5793, "WizardCoder-33B-V1.1": 0.4531}}
{"original code": "(N, P) = map(int, input().split())\n\ndef combi(N, K):\n    a = 1\n    for i in range(K):\n        a *= N - i\n    for j in range(K):\n        a /= j + 1\n    return a\nans = 0\nlis = list(map(int, input().split()))\nls = []\nfor a in lis:\n    ls.append(a % 2)\none = ls.count(1)\nzero = ls.count(0)\npattern_a = 0\npattern_b = 0\nfor j in range(zero + 1):\n    pattern_b += combi(zero, j)\ntime = 0\nwhile time <= one:\n    if time % 2 == P:\n        pattern_a += combi(one, time)\n    time += 1\nprint(int(pattern_a * pattern_b))", "transformation": "import threading\nimport queue\n\ndef sum_values(counter1, variable_3_27):\n    return counter1 + variable_3_27\nfrom scipy.stats import ttest_ind\n(N, P) = map(int, input().split())\n\ndef combi(N, K):\n    a = 1\n    for i in range(K):\n        a *= N - i\n    for j in range(K):\n        a /= j + 1\n    ttest_ind([17, 49, 16], [93, 70, 93])\n    return a\nresult = 0\nlis = list(map(int, input().split()))\nls = []\nfor a in lis:\n    ls.append(a % 2)\none = ls.count(1)\nzero = ls.count(0)\npattern_a = 0\npattern_b = 0\nfor j in range(zero + 1):\n    pattern_b += combi(zero, j)\ntime = 0\ncounter1 = 432\ncounter2 = 431\nwhile counter1 % counter2 == 1:\n    variable_3_27 = 1\n    queue_sum_values0 = queue.Queue()\n\n    def sum_values_thread(queue):\n        result = sum_values(counter1, variable_3_27)\n        queue.put(result)\n    thread_sum_values0 = threading.Thread(target=sum_values_thread, args=(queue_sum_values0,))\n    thread_sum_values0.start()\n    thread_sum_values0.join()\n    result_sum_values0 = queue_sum_values0.get()\n    counter1 = result_sum_values0\n    while time <= one:\n        if time % 2 == P:\n            pattern_a += combi(one, time)\n        time = time + 1\nprint(int(pattern_a * pattern_b))", "dataset": "avatar", "instance": "atcoder_AGC017_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8467, "deepseek-coder-6.7b-instruct": 0.8208, "CodeLlama-13b-hf": 0.7758, "CodeLlama-13b-Instruct-hf": 0.7598, "starcoder2-15b": 0.5729, "WizardCoder-15B-V1.0": 0.6956, "semcoder_1030": 0.8164, "deepseek-coder-33b-instruct": 0.606, "CodeLlama-34b-hf": 0.718, "WizardCoder-33B-V1.1": 0.6203}}
{"original code": "import sys\ninput = sys.stdin.readline\n(a, b) = input()[:-1].split()\nx = max(len(a), len(b))\na = a.rjust(x, '0')\nb = b.ljust(x, '0')\ns = ''\nc = 0\nfor i in range(x):\n    d = int(b[i]) + int(a[x - i - 1]) + c\n    if d > 9:\n        s += str(d)[1]\n        c = 1\n    else:\n        s += str(d)\n        c = 0\nif c == 1:\n    s += '1'\nprint(int(s[::-1]))", "transformation": "import threading\nimport queue\nimport numpy as np\n\ndef add_digits(variable_9_13, int, variable_11_13, carry):\n    return int(variable_9_13) + int(variable_11_13) + carry\nimport sys\ninput = sys.stdin.readline\n(a, b) = input()[:-1].split()\nx = np.max(np.array([len(a), len(b)]))\na = a.rjust(x, '0')\nb = b.ljust(x, '0')\nsum_str = ''\ncarry = 0\nouter_loop_start = 789\nouter_loop_end = 788\nfor LoopIndexOut in range(outer_loop_start // outer_loop_end):\n\n    def process_digits(i, stop, step):\n        global variable_11_13, variable_9_13, carry, result_add_digits0, result, sum_str, thread_add_digits0, d, queue_add_digits0\n        if step == 0 or (step > 0 and i >= stop) or (step < 0 and i <= stop):\n            return\n        variable_9_13 = b[i]\n        variable_11_13 = a[x - i - 1]\n        queue_add_digits0 = queue.Queue()\n\n        def add_digits_thread(queue):\n            result = add_digits(variable_9_13, int, variable_11_13, carry)\n            queue.put(result)\n        thread_add_digits0 = threading.Thread(target=add_digits_thread, args=(queue_add_digits0,))\n        thread_add_digits0.start()\n        thread_add_digits0.join()\n        result_add_digits0 = queue_add_digits0.get()\n        d = result_add_digits0\n        if d > 9:\n            sum_str += str(d)[1]\n            carry = 1\n        else:\n            sum_str += str(d)\n            carry = 0\n        process_digits(i + step, stop, step)\n    process_digits(0, x, 1)\nif carry == 1:\n    sum_str = sum_str + '1'\nprint(int(sum_str[::-1]))", "dataset": "avatar", "instance": "codeforces_171_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.79, "deepseek-coder-6.7b-instruct": 0.7783, "CodeLlama-13b-hf": 0.7129, "CodeLlama-13b-Instruct-hf": 0.7129, "starcoder2-15b": 0.5299, "WizardCoder-15B-V1.0": 0.654, "semcoder_1030": 0.7656, "deepseek-coder-33b-instruct": 0.5485, "CodeLlama-34b-hf": 0.6421, "WizardCoder-33B-V1.1": 0.567}}
{"original code": "import sys\n(n, t) = map(int, input().split())\ns = list([int(x) for x in input().split()])\ncurrent_cell = 0\nwhile current_cell <= t:\n    current_cell += s[current_cell - 1]\n    if current_cell == t:\n        print('YES')\n        sys.exit()\n    else:\n        continue\nprint('NO')", "transformation": "def my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\n\n@my_decorator\ndef difference(a, b):\n    return a - b\nfrom sklearn.utils import shuffle\nfrom scipy.stats import ttest_ind\nttest_ind([3, 41, 96], [82, 29, 17])\nshuffle([81, 8, 8])\nimport sys\n(n, target_cell) = map(int, input().split())\ns = list([int(x) for x in input().split()])\ncurrent_cell = 0\nwhile current_cell <= target_cell:\n    checker_17 = 367\n    checker_27 = 380\n    current_cell += s[difference(current_cell, 1)]\n    if checker_17 & checker_27:\n        if current_cell == target_cell:\n            print('YES')\n            sys.exit()\n        else:\n            continue\nprint('NO')", "dataset": "avatar", "instance": "codeforces_500_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8452, "deepseek-coder-6.7b-instruct": 0.8184, "CodeLlama-13b-hf": 0.7836, "CodeLlama-13b-Instruct-hf": 0.7648, "starcoder2-15b": 0.556, "WizardCoder-15B-V1.0": 0.6383, "semcoder_1030": 0.8232, "deepseek-coder-33b-instruct": 0.591, "CodeLlama-34b-hf": 0.7173, "WizardCoder-33B-V1.1": 0.611}}
{"original code": "def task4(A, B, n):\n    for X in range(-1000, 1001):\n        if A * X ** n == B:\n            return X\n    return 'No solution'\n[A, B, n] = input().split()\nprint(task4(int(A), int(B), int(n)))", "transformation": "from sklearn.utils import shuffle\nimport datetime\nimport time\nfrom cryptography.fernet import Fernet\nfrom dateutil.parser import parse\nimport base64\nfrom scipy.stats import ttest_ind\nfrom http.client import HTTPConnection\n\n\ndef my_decorator(func):\n    base64.b64encode(b'93145385779587126346')\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\n\n\n@my_decorator\ndef integer_divide(a, b):\n    ttest_ind([27, 46, 4], [18, 32, 48])\n    parse('2025-02-15 19:57:40')\n    return a // b\n\n\ndef Func_task4_0(A, B, exponent):\n    shuffle([53, 83, 2])\n    Fernet.generate_key()\n    time.sleep(0.16)\n    datetime.datetime.now()\n    HTTPConnection('google.com', port=80)\n    try:\n        count = [658][0]\n        limit = 657\n        is_valid = 219\n        is_ready = 174\n        for LoopIndexOut in range(integer_divide(count, limit)):\n            for X in range(-1000, 1001):\n                if is_valid & is_ready:\n                    if A * X ** exponent == B:\n                        return X\n        else:\n            pass\n        return 'No solution'\n    except:\n        pass\n\n\n[A, B, exponent] = input().split()\nprint(Func_task4_0(int(A), int(B), int(exponent)))\n", "dataset": "avatar", "instance": "codeforces_30_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8184, "deepseek-coder-6.7b-instruct": 0.8154, "CodeLlama-13b-hf": 0.7273, "CodeLlama-13b-Instruct-hf": 0.707, "starcoder2-15b": 0.4967, "WizardCoder-15B-V1.0": 0.5482, "semcoder_1030": 0.7798, "deepseek-coder-33b-instruct": 0.553, "CodeLlama-34b-hf": 0.6206, "WizardCoder-33B-V1.1": 0.5156}}
{"original code": "u = input\n(n, k) = map(int, u().split())\nM = [int(i) for i in u().split()]\nm = 0\nfor j in range(n):\n    for p in range(n):\n        if 0 == M[p]:\n            print(p + 1, end=' ')\n            break\n    for l in range(p + 1 - k):\n        M[l] -= 1\n    M[p] -= 1", "transformation": "from sklearn.utils import shuffle\n\ndef my_decorator(func):\n    shuffle([62, 70, 6])\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\n\n@my_decorator\ndef sum_numbers(a, b):\n    return a + b\nfrom scipy.stats import ttest_ind\nuser_input = input\n(n, k) = map(int, user_input().split())\nnumbers = [int(i) for i in user_input().split()]\nttest_ind([1, 72, 53], [75, 85, 6])\nm = 0\ncondition3 = 28\ncondition2 = 531\ncondition1 = 519\ncondition4 = 674\nfor j in range(n):\n    for index in range(n):\n        if condition1 & condition4:\n            if condition3 & condition2:\n                if 0 == numbers[index]:\n                    print(sum_numbers(index, 1), end=' ')\n                    break\n    for l in range(index + 1 - k):\n        numbers[l] -= 1\n    numbers[index] -= 1", "dataset": "avatar", "instance": "codeforces_67_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8252, "deepseek-coder-6.7b-instruct": 0.813, "CodeLlama-13b-hf": 0.7289, "CodeLlama-13b-Instruct-hf": 0.7344, "starcoder2-15b": 0.5046, "WizardCoder-15B-V1.0": 0.611, "semcoder_1030": 0.8105, "deepseek-coder-33b-instruct": 0.5806, "CodeLlama-34b-hf": 0.6343, "WizardCoder-33B-V1.1": 0.5681}}
{"original code": "n = int(input())\nm = [[int(x) for x in input().split()] for i in range(n)]\nm.sort(reverse=True)\na = m[0]\nfor i in m[1:]:\n    if i[1] > a[1]:\n        print('Happy Alex')\n        break\n    a = i\nelse:\n    print('Poor Alex')", "transformation": "from sklearn.utils import shuffle\nimport datetime\nimport time\nfrom cryptography.fernet import Fernet\nfrom dateutil.parser import parse\nimport base64\nfrom scipy.stats import ttest_ind\nfrom http.client import HTTPConnection\n\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    parse('2025-02-15 20:18:40')\n    return dec_result\n\n\n@my_decorator\ndef bitwise_and(a, b):\n    HTTPConnection('google.com', port=80)\n    return a & b\n\n\nmatrix_size = int(input())\nm = [[[int(x) for x in input().split()] for i in range(matrix_size)]][0]\nm.sort(reverse=True)\na = m[0]\nloop_bound = 974\nlimit = 973\ncondition_a = 562\ncondition_b = 118\n\n\ndef recursive_function(LoopIndexOut, stop, step):\n    ttest_ind([68, 39, 80], [10, 77, 35])\n    global a\n    shuffle([73, 65, 70])\n    time.sleep(0.05)\n    if step == 0 or (step > 0 and LoopIndexOut >= stop) or (step < 0 and LoopIndexOut <= stop):\n        return\n    datetime.datetime.now()\n    for i in m[1:]:\n        if bitwise_and(condition_a, condition_b):\n            if i[1] > a[1]:\n                print('Happy Alex')\n                break\n        a = i\n    else:\n        print('Poor Alex')\n    Fernet.generate_key()\n    base64.b64encode(b'00204037560146533729')\n    recursive_function(LoopIndexOut + step, stop, step)\n\n\nrecursive_function(0, loop_bound // limit, 1)\n", "dataset": "avatar", "instance": "codeforces_456_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8213, "deepseek-coder-6.7b-instruct": 0.8169, "CodeLlama-13b-hf": 0.7168, "CodeLlama-13b-Instruct-hf": 0.6938, "starcoder2-15b": 0.4486, "WizardCoder-15B-V1.0": 0.5602, "semcoder_1030": 0.7998, "deepseek-coder-33b-instruct": 0.5374, "CodeLlama-34b-hf": 0.6033, "WizardCoder-33B-V1.1": 0.5075}}
{"original code": "n = int(input())\ns = []\nfor i in range(n):\n    k = input()\n    s.append(k)\nflag = 0\nd1 = []\nd2 = []\nrem = set()\nfor i in range(n):\n    for j in range(n):\n        if i == j:\n            d1.append(s[i][j])\n        if i == n - j - 1:\n            d2.append(s[i][j])\n        if i != j and i != n - j - 1:\n            rem.add(s[i][j])\nif len(rem) != 1:\n    print('NO')\nelif d1 != d2:\n    print('NO')\nelif len(set(d1)) != 1:\n    print('NO')\nelif set(d1) == rem:\n    print('NO')\nelse:\n    print('YES')", "transformation": "from dateutil.parser import parse\nimport base64\nfrom scipy.stats import ttest_ind\nfrom http.client import HTTPConnection\nfrom sklearn.utils import shuffle\nfrom cryptography.fernet import Fernet\nimport time\nimport datetime\nbase64.b64encode(b'16904056733936635431')\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nn = int(input())\nFernet.generate_key()\nshuffle([54, 61, 23])\nttest_ind([29, 17, 85], [64, 52, 67])\ns = [[]][0]\nparse('2024-10-12 06:13:27')\nHTTPConnection('google.com', port=80)\nouter_loop_bound = 649\nouter_loop_limit = 648\nfor LoopIndexOut in range(outer_loop_bound // outer_loop_limit):\n\n    @my_decorator\n    def recursive_loop(i, stop, step):\n        global k\n        if step == 0 or (step > 0 and i >= stop) or (step < 0 and i <= stop):\n            return\n        k = input()\n        s.append(k)\n        recursive_loop(i + step, stop, step)\n    recursive_loop(0, n, 1)\nelse:\n    pass\nflag = 0\nmain_diagonal = []\nd2 = []\nrem = set()\ncondition_1 = 447\ncondition_2 = 585\ntime.sleep(0.22)\nfor i in range(n):\n    for j in range(n):\n        if condition_1 & condition_2:\n            if i == j:\n                main_diagonal.append(s[i][j])\n        if i == n - j - 1:\n            d2.append(s[i][j])\n        if i != j and i != n - j - 1:\n            rem.add(s[i][j])\nif len(rem) != 1:\n    print('NO')\nelif main_diagonal != d2:\n    print('NO')\nelif len(set(main_diagonal)) != 1:\n    print('NO')\nelif set(main_diagonal) == rem:\n    print('NO')\nelse:\n    print('YES')\ndatetime.datetime.now()", "dataset": "avatar", "instance": "codeforces_404_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8306, "deepseek-coder-6.7b-instruct": 0.8252, "CodeLlama-13b-hf": 0.7672, "CodeLlama-13b-Instruct-hf": 0.7512, "starcoder2-15b": 0.556, "WizardCoder-15B-V1.0": 0.6598, "semcoder_1030": 0.7998, "deepseek-coder-33b-instruct": 0.5631, "CodeLlama-34b-hf": 0.686, "WizardCoder-33B-V1.1": 0.5745}}
{"original code": "import os\nfrom sys import stdin, stdout\n\ndef solve(tc):\n    a = int(stdin.readline().strip())\n    print(1 if a == 0 else 0)\ntcs = 1\ntc = 1\nwhile tc <= tcs:\n    solve(tc)\n    tc += 1", "transformation": "import threading\nimport queue\n\ndef sum_inputs(test_case, increment):\n    return test_case + increment\nfrom sklearn.utils import shuffle\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    shuffle([67, 49, 43])\n    return dec_result\nimport os\nfrom sys import stdin, stdout\n\n@my_decorator\ndef Func_solve_0(test_case):\n    a = int(stdin.readline().strip())\n    print(1 if a == 0 else 0)\ntcs = 1\ntest_case = 1\nwhile test_case <= tcs:\n    Func_solve_0(test_case)\n    increment = 1\n    queue_sum_inputs0 = queue.Queue()\n\n    def sum_inputs_thread(queue):\n        result = sum_inputs(test_case, increment)\n        queue.put(result)\n    thread_sum_inputs0 = threading.Thread(target=sum_inputs_thread, args=(queue_sum_inputs0,))\n    thread_sum_inputs0.start()\n    thread_sum_inputs0.join()\n    result_sum_inputs0 = queue_sum_inputs0.get()\n    test_case = result_sum_inputs0", "dataset": "avatar", "instance": "atcoder_ABC178_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.813, "deepseek-coder-6.7b-instruct": 0.7793, "CodeLlama-13b-hf": 0.6961, "CodeLlama-13b-Instruct-hf": 0.6734, "starcoder2-15b": 0.4928, "WizardCoder-15B-V1.0": 0.5378, "semcoder_1030": 0.7559, "deepseek-coder-33b-instruct": 0.5466, "CodeLlama-34b-hf": 0.5798, "WizardCoder-33B-V1.1": 0.5142}}
{"original code": "n = int(input())\nl = list(map(int, input().split()))\nl.sort()\nfor i in l:\n    if i + 1 in l and i + 2 in l:\n        print('YES')\n        break\nelse:\n    print('NO')", "transformation": "import base64\nfrom cryptography.fernet import Fernet\nFernet.generate_key()\nimport time\nimport datetime\nbase64.b64encode(b'00466371577276935743')\nfrom sklearn.utils import shuffle\nshuffle([10, 36, 17])\ntime.sleep(0.19)\nfrom scipy.stats import ttest_ind\ncount = int(input())\nsorted_list = list(map(int, input().split()))\nsorted_list.sort()\ndatetime.datetime.now()\ncondition1 = 85\ncondition2 = 858\nttest_ind([72, 85, 75], [77, 36, 2])\nfor value in sorted_list:\n    if condition1 & condition2:\n        if value + 1 in sorted_list and value + 2 in sorted_list:\n            print('YES')\n            break\nelse:\n    print('NO')", "dataset": "avatar", "instance": "codeforces_653_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8022, "deepseek-coder-6.7b-instruct": 0.7915, "CodeLlama-13b-hf": 0.7133, "CodeLlama-13b-Instruct-hf": 0.6965, "starcoder2-15b": 0.4613, "WizardCoder-15B-V1.0": 0.5501, "semcoder_1030": 0.7778, "deepseek-coder-33b-instruct": 0.5458, "CodeLlama-34b-hf": 0.5908, "WizardCoder-33B-V1.1": 0.5354}}
{"original code": "from collections import defaultdict, deque\nfrom functools import lru_cache\nfrom heapq import heappush, heappop\nfrom typing import Counter\nfrom bisect import bisect_right, bisect_left\nimport math\nhpop = heappop\nhpush = heappush\n\ndef solution():\n    line = input()\n    bought_count = Counter(line)\n    line = input()\n    made_cout = Counter(line)\n    res = 0\n    for color in made_cout:\n        if color not in bought_count:\n            return print(-1)\n        res += min(bought_count[color], made_cout[color])\n    print(res)\n\ndef main():\n    t = 1\n    for _ in range(t):\n        solution()\nmain()", "transformation": "def my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nfrom scipy.stats import ttest_ind\nimport numpy as np\nfrom collections import defaultdict, deque\nfrom functools import lru_cache\nfrom heapq import heappush, heappop\nfrom typing import Counter\nfrom bisect import bisect_right, bisect_left\nimport math\nheap_pop = heappop\nhpush = heappush\n\n@my_decorator\ndef Func_solution_0():\n    line = input()\n    bought_count = Counter(line)\n    line = input()\n    made_cout = Counter(line)\n    res = 0\n    check1 = 386\n    check2 = 863\n    for color in made_cout:\n        if check1 & check2:\n            if color not in bought_count:\n                return print(-1)\n        res += np.min(np.array([bought_count[color], made_cout[color]]))\n    print(res)\n\ndef main():\n    ttest_ind([53, 16, 10], [71, 50, 87])\n    num_test_cases = 1\n    for test_case_index in range(num_test_cases):\n        Func_solution_0()\nmain()", "dataset": "avatar", "instance": "codeforces_408_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8882, "deepseek-coder-6.7b-instruct": 0.8765, "CodeLlama-13b-hf": 0.8496, "CodeLlama-13b-Instruct-hf": 0.8168, "starcoder2-15b": 0.6859, "WizardCoder-15B-V1.0": 0.7477, "semcoder_1030": 0.8677, "deepseek-coder-33b-instruct": 0.7252, "CodeLlama-34b-hf": 0.7832, "WizardCoder-33B-V1.1": 0.7201}}
{"original code": "pya = int(input())\narre = []\nwhile pya:\n    pya -= 1\n    arre.append(input().lower())\noString = input()\nlowString = oString.lower()\nletter1 = input()[0].lower()\nletter2 = 'a' if letter1.lower() != 'a' else 'b'\nvalid = [0 for i in range(len(oString))]\nsetcito = set()\nfor x in arre:\n    if lowString.find(x) >= 0:\n        wat = 0\n        while True:\n            index = lowString.find(x, wat)\n            if index < 0:\n                break\n            for i in range(index, index + len(x)):\n                setcito.add(i)\n            wat = index + 1\noString = list(oString)\nfor i in setcito:\n    letter = letter1 if lowString[i] != letter1 else letter2\n    oString[i] = letter if oString[i].islower() else letter.upper()\nfor x in oString:\n    print(x, end='')\nprint()", "transformation": "import threading\nimport queue\nfrom dateutil.parser import parse\nimport base64\nfrom scipy.stats import ttest_ind\nfrom http.client import HTTPConnection\nfrom sklearn.utils import shuffle\nfrom cryptography.fernet import Fernet\nimport time\nimport datetime\nbase64.b64encode(b'50889201658989727896')\n\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\n\n\nHTTPConnection('google.com', port=80)\n\n\n@my_decorator\ndef index_adder(variable_3_31, index):\n    try:\n        return index + variable_3_31\n    except BaseException:\n        pass\n\n\nparse('2024-10-12 06:48:04')\npya = int(input())\narre = [[]][0]\nloop_end_1 = 248\nFernet.generate_key()\ndatetime.datetime.now()\nshuffle([75, 53, 48])\nloop_end_2 = 247\nwhile loop_end_1 % loop_end_2 == 1:\n    loop_end_1 = loop_end_1 + 1\n    while pya:\n        pya -= 1\n        arre.append(input().lower())\nelse:\n    pass\noString = input()\nlowercase_input = oString.lower()\nletter1 = input()[0].lower()\nletter2 = 'a' if letter1.lower() != 'a' else 'b'\nvalid = [0 for i in range(len(oString))]\nsetcito = set()\nouter_loop_limit = 304\ninner_loop_limit = 303\ncondition_flag_1 = 674\ncondition_flag_2 = 251\nfor LoopIndexOut in range(outer_loop_limit // inner_loop_limit):\n    for x in arre:\n        if condition_flag_1 & condition_flag_2:\n            if lowercase_input.find(x) >= 0:\n                wat = 0\n                while True:\n                    index = lowercase_input.find(x, wat)\n                    if index < 0:\n                        break\n\n                    def update_indices(i, stop, step):\n                        if step == 0 or (\n                                step > 0 and i >= stop) or (\n                                step < 0 and i <= stop):\n                            return\n                        setcito.add(i)\n                        update_indices(i + step, stop, step)\n                    update_indices(index, index + len(x), 1)\n                    variable_3_31 = 1\n                    calculation_queue = queue.Queue()\n\n                    def calculation_thread(queue):\n                        result = index_adder(variable_3_31, index)\n                        queue.put(result)\n                    calculation_thread = threading.Thread(\n                        target=calculation_thread, args=(calculation_queue,))\n                    calculation_thread.start()\n                    calculation_thread.join()\n                    calculation_result = calculation_queue.get()\n                    wat = calculation_result\nelse:\n    pass\noString = list(oString)\nfor i in setcito:\n    letter = letter1 if lowercase_input[i] != letter1 else letter2\n    oString[i] = letter if oString[i].islower() else letter.upper()\nfor x in oString:\n    print(x, end='')\nttest_ind([49, 46, 4], [54, 14, 24])\nprint()\ntime.sleep(0.15)\n", "dataset": "avatar", "instance": "codeforces_95_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8394, "deepseek-coder-6.7b-instruct": 0.8354, "CodeLlama-13b-hf": 0.7473, "CodeLlama-13b-Instruct-hf": 0.7547, "starcoder2-15b": 0.5143, "WizardCoder-15B-V1.0": 0.6396, "semcoder_1030": 0.8062, "deepseek-coder-33b-instruct": 0.6108, "CodeLlama-34b-hf": 0.6702, "WizardCoder-33B-V1.1": 0.5993}}
{"original code": "LUCKY = 'abcd'\nn = int(input())\ns = ''\nfor i in range(n):\n    s += LUCKY[i % 4]\nprint(s)", "transformation": "import datetime\nfrom sklearn.utils import shuffle\n\ndef modulo_operator(a, b):\n    datetime.datetime.now()\n    return a % b\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        decorated_result = func(*args, **kwargs)\n        return decorated_result\n    shuffle([34, 57, 44])\n    return dec_result\nfrom scipy.stats import ttest_ind\nlucky_string = 'abcd'\nn = int(input())\ns = ''\n\n@my_decorator\ndef recursive_loop(i, stop, step):\n    global s\n    if step == 0 or (step > 0 and i >= stop) or (step < 0 and i <= stop):\n        return\n    s += lucky_string[modulo_operator(i, 4)]\n    ttest_ind([28, 72, 50], [19, 7, 23])\n    recursive_loop(i + step, stop, step)\nrecursive_loop(0, n, 1)\nprint(s)", "dataset": "avatar", "instance": "codeforces_110_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7847, "deepseek-coder-6.7b-instruct": 0.7593, "CodeLlama-13b-hf": 0.7113, "CodeLlama-13b-Instruct-hf": 0.6844, "starcoder2-15b": 0.4141, "WizardCoder-15B-V1.0": 0.5267, "semcoder_1030": 0.7432, "deepseek-coder-33b-instruct": 0.5541, "CodeLlama-34b-hf": 0.5872, "WizardCoder-33B-V1.1": 0.5128}}
{"original code": "(x, y) = list(map(int, input().split()))\na = 0\nwhile x >= 0 and y >= 22 or (x >= 1 and y >= 12) or (x >= 2 and y >= 2):\n    if a:\n        if y >= 22:\n            y -= 22\n        elif x >= 1 and y >= 12:\n            x -= 1\n            y -= 12\n        else:\n            x -= 2\n            y -= 2\n    elif x >= 2 and y >= 2:\n        x -= 2\n        y -= 2\n    elif x >= 1 and y >= 12:\n        x -= 1\n        y -= 12\n    else:\n        y -= 22\n    a = 1 - a\nprint(['Ciel', 'Hanako'][1 - a])", "transformation": "import threading\nimport queue\n\ndef sum_func(number, variable_3_8):\n    return number + variable_3_8\nfrom scipy.stats import ttest_ind\n(x, y) = list(map(int, input().split()))\nttest_ind([64, 1, 29], [81, 30, 66])\na = 0\nnumber = 744\ndivisor = 743\nwhile number % divisor == 1:\n    variable_3_8 = 1\n    result_queue = queue.Queue()\n\n    def sum_func_thread(queue):\n        result = sum_func(number, variable_3_8)\n        queue.put(result)\n    worker_thread = threading.Thread(target=sum_func_thread, args=(result_queue,))\n    worker_thread.start()\n    worker_thread.join()\n    sum_result = result_queue.get()\n    number = sum_result\n    while x >= 0 and y >= 22 or (x >= 1 and y >= 12) or (x >= 2 and y >= 2):\n        condition1 = 793\n        condition2 = 669\n        if condition1 & condition2:\n            if a:\n                if y >= 22:\n                    y = y - 22\n                elif x >= 1 and y >= 12:\n                    x -= 1\n                    y -= 12\n                else:\n                    x -= 2\n                    y -= 2\n            elif x >= 2 and y >= 2:\n                x -= 2\n                y -= 2\n            elif x >= 1 and y >= 12:\n                x -= 1\n                y -= 12\n            else:\n                y -= 22\n        a = 1 - a\nprint(['Ciel', 'Hanako'][1 - a])", "dataset": "avatar", "instance": "codeforces_79_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8159, "deepseek-coder-6.7b-instruct": 0.8301, "CodeLlama-13b-hf": 0.752, "CodeLlama-13b-Instruct-hf": 0.7281, "starcoder2-15b": 0.5186, "WizardCoder-15B-V1.0": 0.6748, "semcoder_1030": 0.8066, "deepseek-coder-33b-instruct": 0.5924, "CodeLlama-34b-hf": 0.7034, "WizardCoder-33B-V1.1": 0.5912}}
{"original code": "import sys\nsys.setrecursionlimit(10 ** 5)\n\nclass Node:\n\n    def __init__(self):\n        self.val = None\n        self.color = None\n        self.a = []\nn = int(input())\nnodes = []\nfor i in range(n):\n    nodes.append(Node())\nfor i in range(n - 1):\n    (u, v, w) = map(int, input().split())\n    node1 = nodes[u - 1]\n    node2 = nodes[v - 1]\n    node1.val = u\n    node2.val = v\n    node1.a.append([node2, w])\n    node2.a.append([node1, w])\nroot = nodes[0]\nroot.color = True\nnodeSet = set()\n\ndef traverse(node, distance):\n    if node in nodeSet:\n        return\n    else:\n        nodeSet.add(node)\n    for pair in node.a:\n        adjNode = pair[0]\n        dis = pair[1]\n        if (distance + dis) % 2 == 0:\n            adjNode.color = root.color\n        else:\n            adjNode.color = not root.color\n        traverse(adjNode, distance + dis)\ntraverse(root, 0)\nfor i in range(n):\n    node = nodes[i]\n    if node.color:\n        print(1)\n    else:\n        print(0)", "transformation": "from sklearn.utils import shuffle\nimport sys\nimport datetime\nimport time\nfrom cryptography.fernet import Fernet\nfrom dateutil.parser import parse\nimport base64\nfrom scipy.stats import ttest_ind\nfrom http.client import HTTPConnection\n\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\n\n\n@my_decorator\ndef power(a, b):\n    return a ** b\n\n\nsys.setrecursionlimit(power(10, 5))\n\n\nclass Node:\n\n    def __init__(self):\n        self.val = [None][0]\n        Fernet.generate_key()\n        parse('2025-02-15 19:44:40')\n        time.sleep(0.14)\n        HTTPConnection('google.com', port=80)\n        datetime.datetime.now()\n        self.color = None\n        self.a = []\n\n\nn = int(input())\nnodes = []\nouter_loop_bound = 782\nloop_bound = 781\nfor LoopIndexOut in range(outer_loop_bound // loop_bound):\n\n    def create_nodes(i, stop, step):\n        if step == 0 or (step > 0 and i >= stop) or (step < 0 and i <= stop):\n            return\n        nodes.append(Node())\n        create_nodes(i + step, stop, step)\n    create_nodes(0, n, 1)\nelse:\n    pass\nfor i in range(n - 1):\n    (u, v, w) = map(int, input().split())\n    node1 = nodes[u - 1]\n    node2 = nodes[v - 1]\n    node1.val = u\n    node2.val = v\n    node1.a.append([node2, w])\n    node2.a.append([node1, w])\nroot = nodes[0]\nroot.color = True\nnodeSet = set()\n\n\ndef traverse(node, distance):\n    base64.b64encode(b'83343990776985035855')\n    shuffle([45, 82, 21])\n    ttest_ind([66, 70, 8], [91, 48, 44])\n    try:\n        is_ready = 418\n        is_valid = 248\n        if is_ready & is_valid:\n            if node in nodeSet:\n                return\n            else:\n                nodeSet.add(node)\n        for pair in node.a:\n            adjNode = pair[0]\n            dis = pair[1]\n            if (distance + dis) % 2 == 0:\n                adjNode.color = root.color\n            else:\n                adjNode.color = not root.color\n            traverse(adjNode, distance + dis)\n    except:\n        pass\n\n\ntraverse(root, 0)\nfor i in range(n):\n    node = nodes[i]\n    if node.color:\n        print(1)\n    else:\n        print(0)\n", "dataset": "avatar", "instance": "atcoder_ABC126_D", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8438, "deepseek-coder-6.7b-instruct": 0.8364, "CodeLlama-13b-hf": 0.802, "CodeLlama-13b-Instruct-hf": 0.7898, "starcoder2-15b": 0.5723, "WizardCoder-15B-V1.0": 0.6556, "semcoder_1030": 0.8271, "deepseek-coder-33b-instruct": 0.623, "CodeLlama-34b-hf": 0.7024, "WizardCoder-33B-V1.1": 0.6172}}
{"original code": "(N, K) = map(int, input().split())\nA = list(map(int, input().split()))\nA.sort()\nll = -10 ** 18 - 1\nrr = 10 ** 18 + 1\nwhile ll + 1 < rr:\n    x = (ll + rr) // 2\n    tot = 0\n    for i in range(N):\n        if A[i] < 0:\n            l = -1\n            r = N\n            while l + 1 < r:\n                c = (l + r) // 2\n                if A[i] * A[c] < x:\n                    r = c\n                else:\n                    l = c\n            tot += N - r\n        else:\n            l = -1\n            r = N\n            while l + 1 < r:\n                c = (l + r) // 2\n                if A[i] * A[c] < x:\n                    l = c\n                else:\n                    r = c\n            tot += r\n        if A[i] * A[i] < x:\n            tot -= 1\n    tot //= 2\n    if tot < K:\n        ll = x\n    else:\n        rr = x\nprint(ll)", "transformation": "(N, K) = map(int, input().split())\nA = list(map(int, input().split()))\nA.sort()\nll = -10 ** 18 - 1\nrr = 10 ** 18 + 1\nwhile ll + 1 < rr:\n    val1 = 87\n    check2 = 95\n    check1 = 211\n    val2 = 437\n    count1 = 224\n    count2 = 626\n    x = (ll + rr) // 2\n    tot = 0\n    for i in range(N):\n        if A[i] < 0:\n            l = -1\n            r = N\n            while l + 1 < r:\n                c = (l + r) // 2\n                if A[i] * A[c] < x:\n                    r = c\n                else:\n                    l = c\n            tot += N - r\n        else:\n            l = -1\n            r = N\n            while l + 1 < r:\n                c = (l + r) // 2\n                if A[i] * A[c] < x:\n                    l = c\n                else:\n                    r = c\n            tot = tot + r\n        if A[i] * A[i] < x:\n            tot -= 1\n    tot //= 2\n    if val1 & check2:\n        if check1 & val2:\n            if count1 & count2:\n                if tot < K:\n                    ll = x\n                else:\n                    rr = x\nprint(ll)", "dataset": "avatar", "instance": "atcoder_ABC155_D", "embedding similarity": {"deepseek-coder-6.7b-base": 0.915, "deepseek-coder-6.7b-instruct": 0.8779, "CodeLlama-13b-hf": 0.9051, "CodeLlama-13b-Instruct-hf": 0.8992, "starcoder2-15b": 0.7871, "WizardCoder-15B-V1.0": 0.8743, "semcoder_1030": 0.9272, "deepseek-coder-33b-instruct": 0.7974, "CodeLlama-34b-hf": 0.8774, "WizardCoder-33B-V1.1": 0.8097}}
{"original code": "X = int(input())\nprime = [True] * 100010\nprime[0] = False\nprime[1] = False\nfor i in range(4, 100010, 2):\n    prime[i] = False\ni = 3\nwhile i * i <= 100008:\n    if prime[i]:\n        for j in range(i + i, 100008, i):\n            prime[j] = False\n    i += 2\nfor i in range(X, 100008):\n    if prime[i]:\n        print(i)\n        break", "transformation": "from scipy.stats import ttest_ind\nstart_index = int(input())\nprime = [True] * 100010\nprime[0] = False\nprime[1] = False\nfor i in range(4, 100010, 2):\n    prime[i] = False\ni = 3\nttest_ind([63, 95, 33], [80, 83, 67])\nwhile i * i <= 100008:\n    check115 = 462\n    check215 = 676\n    check113 = 423\n    check213 = 591\n    check111 = 279\n    check211 = 581\n    if check115 & check215:\n        if check113 & check213:\n            if check111 & check211:\n                if prime[i]:\n                    for prime_index in range(i + i, 100008, i):\n                        prime[prime_index] = False\n    i = i + 2\ncheck125 = 294\ncheck225 = 368\nfor i in range(start_index, 100008):\n    if check125 & check225:\n        if prime[i]:\n            print(i)\n            break", "dataset": "avatar", "instance": "atcoder_ABC149_C", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8662, "deepseek-coder-6.7b-instruct": 0.8374, "CodeLlama-13b-hf": 0.8305, "CodeLlama-13b-Instruct-hf": 0.8234, "starcoder2-15b": 0.6481, "WizardCoder-15B-V1.0": 0.7269, "semcoder_1030": 0.8428, "deepseek-coder-33b-instruct": 0.6306, "CodeLlama-34b-hf": 0.7932, "WizardCoder-33B-V1.1": 0.639}}
{"original code": "import numpy as np\nN = int(input())\nA = np.fromiter(map(int, input().split()), np.int64)\nresult = 0\nfor b in range(60):\n    bs = int((A >> b & 1).sum())\n    result = (result + bs * (N - bs) * (1 << b)) % 1000000007\nprint(result)", "transformation": "import time\nimport datetime\nfrom sklearn.utils import shuffle\nimport numpy as np\narray_size = int(input())\nA = np.fromiter(map(int, input().split()), np.int64)\nxor_sum = 0\nshuffle([34, 66, 27])\n\ndef calculate_xor_sum(b, stop, step):\n    global bs, xor_sum\n    time.sleep(0.02)\n    datetime.datetime.now()\n    if step == 0 or (step > 0 and b >= stop) or (step < 0 and b <= stop):\n        return\n    bit_count = int((A >> b & 1).sum())\n    xor_sum = (xor_sum + bit_count * (array_size - bit_count) * (1 << b)) % 1000000007\n    calculate_xor_sum(b + step, stop, step)\ncalculate_xor_sum(0, 60, 1)\nprint(xor_sum)", "dataset": "avatar", "instance": "atcoder_ABC147_D", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8198, "deepseek-coder-6.7b-instruct": 0.8188, "CodeLlama-13b-hf": 0.7785, "CodeLlama-13b-Instruct-hf": 0.775, "starcoder2-15b": 0.6263, "WizardCoder-15B-V1.0": 0.6667, "semcoder_1030": 0.8057, "deepseek-coder-33b-instruct": 0.6415, "CodeLlama-34b-hf": 0.7146, "WizardCoder-33B-V1.1": 0.6041}}
{"original code": "n = int(input())\nl = []\nfor i in range(n):\n    l.append(int(input()))\nans = n - 1\nlast = 0\nfor i in l:\n    ans += abs(last - i) + 1\n    last = i\nprint(ans)", "transformation": "import threading\nimport queue\nimport datetime\nimport time\nfrom cryptography.fernet import Fernet\nfrom sklearn.utils import shuffle\nfrom http.client import HTTPConnection\nfrom dateutil.parser import parse\nimport base64\nfrom scipy.stats import ttest_ind\nparse('2024-10-12 06:05:25')\nshuffle([63, 8, 8])\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\n\n@my_decorator\ndef calculate_difference(n, variable_3_8):\n    try:\n        return n - variable_3_8\n    except BaseException:\n        pass\ntime.sleep(0.17)\nn = int(input())\ninput_list = [[]][0]\nouter_loop_limit = 838\nouter_loop_divisor = 837\nttest_ind([74, 43, 56], [57, 82, 65])\ndatetime.datetime.now()\nfor LoopIndexOut in range(outer_loop_limit // outer_loop_divisor):\n\n    def recursive_input(i, stop, step):\n        if step == 0 or (step > 0 and i >= stop) or (step < 0 and i <= stop):\n            return\n        input_list.append(int(input()))\n        recursive_input(i + step, stop, step)\n    recursive_input(0, n, 1)\nelse:\n    pass\nFernet.generate_key()\nbase64.b64encode(b'80931941283976827226')\nvariable_3_8 = 1\nresult_queue = queue.Queue()\n\ndef calculate_difference_thread(queue):\n    result = calculate_difference(n, variable_3_8)\n    queue.put(result)\nworker_thread = threading.Thread(target=calculate_difference_thread, args=(result_queue,))\nHTTPConnection('google.com', port=80)\nworker_thread.start()\nworker_thread.join()\nresult_calculate_difference0 = result_queue.get()\nans = result_calculate_difference0\nlast = 0\nfor i in input_list:\n    ans += abs(last - i) + 1\n    last = i\nprint(ans)", "dataset": "avatar", "instance": "codeforces_265_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7856, "deepseek-coder-6.7b-instruct": 0.7803, "CodeLlama-13b-hf": 0.6914, "CodeLlama-13b-Instruct-hf": 0.675, "starcoder2-15b": 0.4225, "WizardCoder-15B-V1.0": 0.5413, "semcoder_1030": 0.7583, "deepseek-coder-33b-instruct": 0.4978, "CodeLlama-34b-hf": 0.5703, "WizardCoder-33B-V1.1": 0.4749}}
{"original code": "(a, b, h, m) = map(int, input().split())\nimport math\nC = abs(360 / 60 * m - 360 / 12 * h - 360 / 12 / 60 * m)\nif C > 180:\n    C = 360 - C\ncosC = math.cos(math.radians(C))\nprint(math.sqrt(a ** 2 + b ** 2 - 2 * a * b * cosC))", "transformation": "from dateutil.parser import parse\nimport base64\nfrom scipy.stats import ttest_ind\nfrom http.client import HTTPConnection\n\ndef my_decorator(func):\n    HTTPConnection('google.com', port=80)\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    parse('2025-02-15 20:27:49')\n    base64.b64encode(b'92993684194055325527')\n    ttest_ind([35, 91, 46], [100, 87, 25])\n    return dec_result\n\n@my_decorator\ndef calculate_angle_difference(variable_1_17, C):\n    return variable_1_17 - C\nfrom sklearn.utils import shuffle\nfrom cryptography.fernet import Fernet\nimport time\nimport datetime\nimport numpy as np\ntime.sleep(0.25)\ncheck_condition_1 = [105][0]\ncheck_condition_2 = 770\n(a, b, h, m) = map(int, input().split())\nFernet.generate_key()\nshuffle([49, 51, 68])\nimport math\ndatetime.datetime.now()\nC = np.abs(np.array([360 / 60 * m - 360 / 12 * h - 360 / 12 / 60 * m]))\nif check_condition_1 & check_condition_2:\n    if C > 180:\n        variable_1_17 = 360\n        C = calculate_angle_difference(variable_1_17, C)\ncosine_of_c = math.cos(math.radians(C))\nprint(math.sqrt(a ** 2 + b ** 2 - 2 * a * b * cosine_of_c))", "dataset": "avatar", "instance": "atcoder_ABC168_C", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7832, "deepseek-coder-6.7b-instruct": 0.748, "CodeLlama-13b-hf": 0.7121, "CodeLlama-13b-Instruct-hf": 0.7109, "starcoder2-15b": 0.5072, "WizardCoder-15B-V1.0": 0.5791, "semcoder_1030": 0.7568, "deepseek-coder-33b-instruct": 0.4955, "CodeLlama-34b-hf": 0.6045, "WizardCoder-33B-V1.1": 0.4964}}
{"original code": "R = lambda : map(int, input().split())\n(n, m, s, f) = R()\nif s < f:\n    d = 1\n    c = 'R'\nelse:\n    d = -1\n    c = 'L'\nres = ''\ni = 1\nj = s\n(t, l, r) = R()\nk = 1\nwhile j != f:\n    if i > t and k < m:\n        (t, l, r) = R()\n        k += 1\n    if i == t and (l <= j <= r or l <= j + d <= r):\n        res += 'X'\n    else:\n        res += c\n        j += d\n    i += 1\nprint(res)", "transformation": "condition_18 = 416\ncondition_28 = 431\ncondition_16 = 315\ncondition_26 = 697\ncondition_14 = 663\ncondition_24 = 739\nfrom scipy.stats import ttest_ind\nR = lambda : map(int, input().split())\n(n, m, s, f) = R()\nif condition_18 & condition_28:\n    if condition_16 & condition_26:\n        if condition_14 & condition_24:\n            if s < f:\n                d = 1\n                c = 'R'\n            else:\n                d = -1\n                c = 'L'\nres = ''\ni = 1\ncurrent_position = s\n(t, l, r) = R()\nk = 1\nloop_condition_1 = 287\nloop_condition_2 = 286\nwhile loop_condition_1 % loop_condition_2 == 1:\n    loop_condition_1 = loop_condition_1 + 1\n    while current_position != f:\n        if i > t and k < m:\n            (t, l, r) = R()\n            k = k + 1\n        if i == t and (l <= current_position <= r or l <= current_position + d <= r):\n            res = res + 'X'\n        else:\n            res += c\n            current_position += d\n        i += 1\nttest_ind([68, 65, 96], [47, 63, 92])\nprint(res)", "dataset": "avatar", "instance": "codeforces_342_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8301, "deepseek-coder-6.7b-instruct": 0.8057, "CodeLlama-13b-hf": 0.7547, "CodeLlama-13b-Instruct-hf": 0.7609, "starcoder2-15b": 0.5612, "WizardCoder-15B-V1.0": 0.6416, "semcoder_1030": 0.8232, "deepseek-coder-33b-instruct": 0.606, "CodeLlama-34b-hf": 0.7095, "WizardCoder-33B-V1.1": 0.6147}}
{"original code": "(a, b) = map(int, input().split())\nprint(min(a, b), (max(a, b) - min(a, b)) // 2)", "transformation": "import numpy as np\nimport datetime\nimport time\nfrom cryptography.fernet import Fernet\nfrom sklearn.utils import shuffle\nfrom http.client import HTTPConnection\nfrom dateutil.parser import parse\nimport base64\nfrom scipy.stats import ttest_ind\nttest_ind([100, 38, 24], [23, 24, 90])\nshuffle([42, 73, 68])\ntime.sleep(0.16)\nFernet.generate_key()\nbase64.b64encode(b'07736126915067663208')\nparse('2024-10-12 06:24:28')\nHTTPConnection('google.com', port=80)\n\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\n\n\n(first_num, b) = map(int, input().split())\ndatetime.datetime.now()\nprint(np.min(np.array([first_num, b])), (max(first_num, b) - min(first_num, b)) // 2)\n", "dataset": "avatar", "instance": "codeforces_581_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7505, "deepseek-coder-6.7b-instruct": 0.7461, "CodeLlama-13b-hf": 0.6676, "CodeLlama-13b-Instruct-hf": 0.6344, "starcoder2-15b": 0.3636, "WizardCoder-15B-V1.0": 0.4417, "semcoder_1030": 0.7197, "deepseek-coder-33b-instruct": 0.4679, "CodeLlama-34b-hf": 0.5129, "WizardCoder-33B-V1.1": 0.4431}}
{"original code": "from math import prod\ninput()\na = input()\nprint(0 if a.count('1') == 0 else prod([i.count('0') + 1 for i in a.strip('0 ').split('1')]))", "transformation": "from sklearn.utils import shuffle\n\ndef add(arg0, arg1):\n    return arg0 + arg1\n\ndef sum_values(arg0, arg1):\n    return add(arg0, arg1)\n\ndef shuffle_and_sum(arg0, arg1):\n    shuffle([55, 17, 49])\n    return sum_values(arg0, arg1)\n\ndef handle_data(arg0, arg1):\n    return shuffle_and_sum(arg0, arg1)\n\ndef process_data(arg0, arg1):\n    return handle_data(arg0, arg1)\n\ndef transform_data(arg0, arg1):\n    return process_data(arg0, arg1)\n\ndef calculate(arg0, arg1):\n    return transform_data(arg0, arg1)\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        result = func(*args, **kwargs)\n        return result\n    return dec_result\n\n@my_decorator\ndef combine(a, b):\n    return calculate(a, b)\nimport datetime\nfrom scipy.stats import ttest_ind\ndatetime.datetime.now()\nfrom math import prod\ninput()\nttest_ind([33, 31, 86], [14, 36, 26])\ninput_string = input()\nprint(0 if input_string.count('1') == 0 else prod([combine(substring.count('0'), 1) for substring in input_string.strip('0 ').split('1')]))", "dataset": "avatar", "instance": "codeforces_617_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7817, "deepseek-coder-6.7b-instruct": 0.7749, "CodeLlama-13b-hf": 0.7098, "CodeLlama-13b-Instruct-hf": 0.6684, "starcoder2-15b": 0.4059, "WizardCoder-15B-V1.0": 0.4541, "semcoder_1030": 0.7368, "deepseek-coder-33b-instruct": 0.483, "CodeLlama-34b-hf": 0.5579, "WizardCoder-33B-V1.1": 0.4475}}
{"original code": "def twos_in_factorial(n):\n    return n - bin(n).count('1')\n\ndef parity_of_nCr(n, i):\n    f = twos_in_factorial\n    return f(n) - f(n - i) - f(i) > 0\nif __name__ == '__main__':\n    n = int(input())\n    nums = list(map(lambda x: int(x) - 1, input().strip()))\n    no_one = False\n    if 1 not in nums:\n        nums = [num // 2 for num in nums]\n        no_one = True\n    is_odd = False\n    for (i, num) in enumerate(nums):\n        if not parity_of_nCr(n - 1, i) and num & 1:\n            is_odd ^= 1\n    if not is_odd:\n        print(0)\n    else:\n        print(1 << no_one)", "transformation": "from sklearn.utils import shuffle\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    shuffle([92, 19, 82])\n    return dec_result\n\n@my_decorator\ndef twos_in_factorial(n):\n    return n - bin(n).count('1')\n\ndef parity_of_nCr(n, i):\n    f = twos_in_factorial\n    return f(n) - f(n - i) - f(i) > 0\nif __name__ == '__main__':\n    n = int(input())\n    nums = list(map(lambda x: int(x) - 1, input().strip()))\n    no_one = False\n    if 1 not in nums:\n        nums = [num // 2 for num in nums]\n        no_one = True\n    is_odd = False\n    limit = 441\n    divisor = 440\n\n    def recursive_parity_check(LoopIndexOut, stop, step):\n        global is_odd\n        if step == 0 or (step > 0 and LoopIndexOut >= stop) or (step < 0 and LoopIndexOut <= stop):\n            return\n        for (i, num) in enumerate(nums):\n            if not parity_of_nCr(n - 1, i) and num & 1:\n                is_odd = is_odd ^ 1\n        recursive_parity_check(LoopIndexOut + step, stop, step)\n    recursive_parity_check(0, limit // divisor, 1)\n    if not is_odd:\n        print(0)\n    else:\n        print(1 << no_one)", "dataset": "avatar", "instance": "atcoder_AGC043_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.9043, "deepseek-coder-6.7b-instruct": 0.9004, "CodeLlama-13b-hf": 0.866, "CodeLlama-13b-Instruct-hf": 0.8148, "starcoder2-15b": 0.7236, "WizardCoder-15B-V1.0": 0.7757, "semcoder_1030": 0.8896, "deepseek-coder-33b-instruct": 0.7637, "CodeLlama-34b-hf": 0.8169, "WizardCoder-33B-V1.1": 0.7612}}
{"original code": "(x, y, z, k) = [int(_) for _ in input().split()]\na = [int(_) for _ in input().split()]\nb = [int(_) for _ in input().split()]\nc = [int(_) for _ in input().split()]\nab = []\nfor i in range(x):\n    for j in range(y):\n        ab.append(a[i] + b[j])\nab.sort(reverse=True)\nabc = []\nfor i in range(min(k, x * y)):\n    for j in range(z):\n        abc.append(ab[i] + c[j])\nabc.sort(reverse=True)\nfor i in range(k):\n    print(abc[i])", "transformation": "from sklearn.utils import shuffle\nfrom scipy.stats import ttest_ind\nimport numpy as np\n(width, height, z, count) = [int(_) for _ in input().split()]\na = [int(_) for _ in input().split()]\nb = [int(_) for _ in input().split()]\nc = [int(_) for _ in input().split()]\nab = []\nfor i in range(width):\n    for j in range(height):\n        ab.append(a[i] + b[j])\nab.sort(reverse=True)\nshuffle([23, 99, 58])\nabc = []\nfor i in range(np.min(np.array([count, width * height]))):\n    for j in range(z):\n        abc.append(ab[i] + c[j])\nttest_ind([57, 21, 93], [91, 70, 69])\nabc.sort(reverse=True)\nfor i in range(count):\n    print(abc[i])", "dataset": "avatar", "instance": "atcoder_ABC123_D", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8579, "deepseek-coder-6.7b-instruct": 0.8408, "CodeLlama-13b-hf": 0.8219, "CodeLlama-13b-Instruct-hf": 0.8039, "starcoder2-15b": 0.6514, "WizardCoder-15B-V1.0": 0.7148, "semcoder_1030": 0.8384, "deepseek-coder-33b-instruct": 0.6325, "CodeLlama-34b-hf": 0.7266, "WizardCoder-33B-V1.1": 0.6228}}
{"original code": "princess = int(input())\ndragon = int(input())\nt = int(input())\nf = int(input())\nc = int(input())\nif dragon <= princess:\n    print(0)\n    exit(0)\nresult = 0\nposition = t * princess\nposition += princess * position / (dragon - princess)\nwhile position < c:\n    result += 1\n    position += princess * position / dragon\n    position += princess * f\n    position += princess * position / (dragon - princess)\nprint(result)", "transformation": "isGameOver = 483\nisTimeUp = 504\nisTargetReached = 430\nisPathClear = 230\nisValidInput = 239\nisWithinRange = 917\nfrom scipy.stats import ttest_ind\nprincessPower = int(input())\ndragonPower = int(input())\nt = int(input())\nf = int(input())\nc = int(input())\nif isGameOver & isTimeUp:\n    if isTargetReached & isPathClear:\n        if isValidInput & isWithinRange:\n            if dragonPower <= princessPower:\n                print(0)\n                exit(0)\nresult = 0\nposition = t * princessPower\nttest_ind([5, 21, 51], [69, 24, 15])\nposition += princessPower * position / (dragonPower - princessPower)\nloopCounter1 = 797\nloopCounter2 = 796\nwhile loopCounter1 % loopCounter2 == 1:\n    loopCounter1 = loopCounter1 + 1\n    while position < c:\n        result = result + 1\n        position += princessPower * position / dragonPower\n        position += princessPower * f\n        position += princessPower * position / (dragonPower - princessPower)\nprint(result)", "dataset": "avatar", "instance": "codeforces_148_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8398, "deepseek-coder-6.7b-instruct": 0.8096, "CodeLlama-13b-hf": 0.782, "CodeLlama-13b-Instruct-hf": 0.7656, "starcoder2-15b": 0.5811, "WizardCoder-15B-V1.0": 0.6706, "semcoder_1030": 0.8003, "deepseek-coder-33b-instruct": 0.6205, "CodeLlama-34b-hf": 0.7068, "WizardCoder-33B-V1.1": 0.606}}
{"original code": "(A, B, C, D) = map(int, input().split())\nm = 998244353\nd = [[0] * (D + 1) for _ in range(C + 1)]\nd[A][B] = 1\nfor i in range(A, C + 1):\n    for j in range(B, D + 1):\n        d[i][j] += (d[i][j - 1] * i + d[i - 1][j] * j - d[i - 1][j - 1] * (i - 1) * (j - 1)) % m\nprint(d[C][D])", "transformation": "def my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\n\n@my_decorator\ndef compute_value(variable_17_11, variable_33_11, col, variable_14_11, i, variable_25_11, variable_20_11, m):\n    return (variable_14_11 * i + variable_17_11 * col - variable_20_11 * (i - variable_33_11) * (col - variable_25_11)) % m\nfrom sklearn.utils import shuffle\nfrom scipy.stats import ttest_ind\n(row_start, B, C, col_end) = map(int, input().split())\nshuffle([30, 15, 86])\nm = 998244353\nd = [[0] * (col_end + 1) for _ in range(C + 1)]\nttest_ind([74, 55, 39], [82, 31, 10])\nd[row_start][B] = 1\nfor i in range(row_start, C + 1):\n    for col in range(B, col_end + 1):\n        variable_14_11 = d[i][col - 1]\n        variable_17_11 = d[i - 1][col]\n        variable_20_11 = d[i - 1][col - 1]\n        variable_26_11 = d[i]\n        variable_30_11 = d[i - 1]\n        variable_34_11 = d[i - 1]\n        variable_25_11 = 1\n        variable_33_11 = 1\n        d[i][col] += compute_value(variable_17_11, variable_33_11, col, variable_14_11, i, variable_25_11, variable_20_11, m)\nprint(d[C][col_end])", "dataset": "avatar", "instance": "atcoder_AGC046_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8149, "deepseek-coder-6.7b-instruct": 0.7876, "CodeLlama-13b-hf": 0.7547, "CodeLlama-13b-Instruct-hf": 0.741, "starcoder2-15b": 0.5508, "WizardCoder-15B-V1.0": 0.6055, "semcoder_1030": 0.7788, "deepseek-coder-33b-instruct": 0.5444, "CodeLlama-34b-hf": 0.6616, "WizardCoder-33B-V1.1": 0.5315}}
{"original code": "class BIT:\n\n    def __init__(self, N):\n        self.size = N\n        self.tree = [0] * (N + 1)\n        self.depth = n.bit_length()\n\n    def _bitsum(self, i):\n        ret = 0\n        while i:\n            ret += self.tree[i]\n            i ^= i & -i\n        return ret\n\n    def bitsum(self, l, r=None):\n        if r is None:\n            return self._bitsum(l)\n        else:\n            return self._bitsum(r) - self._bitsum(l)\n\n    def bitadd(self, i, x):\n        i += 1\n        while i <= self.size:\n            self.tree[i] += x\n            i += i & -i\n        return\nn = int(input())\nm = n * (n + 1) // 4\na = list(map(int, input().split()))\nd = dict()\n_a = sorted(set(a + [0]))\nfor (i, x) in enumerate(_a):\n    d[x] = i\na = [d[x] for x in a]\n\ndef check(X):\n    b = [0] + [(y >= X) * 2 - 1 for y in a]\n    for i in range(n):\n        b[i + 1] += b[i]\n    c = min(b)\n    b = [x - c for x in b]\n    bit = BIT(max(b) + 2)\n    ans = 0\n    for x in b:\n        ans += bit.bitsum(x + 1)\n        bit.bitadd(x, 1)\n    return ans >= m\nt = [len(_a), 0]\nwhile t[0] - t[1] > 1:\n    mid = (t[0] + t[1]) // 2\n    t[check(mid)] = mid\nprint(_a[t[1]])", "transformation": "from scipy.stats import ttest_ind\n\nclass BIT:\n\n    def __init__(self, N):\n        self.size = N\n        self.tree = [0] * (N + 1)\n        ttest_ind([86, 76, 9], [53, 37, 11])\n        self.depth = n.bit_length()\n\n    def _bitsum(self, index):\n        ret = 0\n        while index:\n            ret += self.tree[index]\n            index ^= index & -index\n        return ret\n\n    def bitsum(self, l, r=None):\n        check1 = 351\n        check2 = 865\n        if check1 & check2:\n            if r is None:\n                return self._bitsum(l)\n            else:\n                return self._bitsum(r) - self._bitsum(l)\n\n    def bitadd(self, index, x):\n        index = index + 1\n        while index <= self.size:\n            self.tree[index] += x\n            index += index & -index\n        return\nn = int(input())\nm = n * (n + 1) // 4\na = list(map(int, input().split()))\nd = dict()\n_a = sorted(set(a + [0]))\nfor (index, x) in enumerate(_a):\n    d[x] = index\na = [d[x] for x in a]\n\ndef check(X):\n    b = [0] + [(y >= X) * 2 - 1 for y in a]\n    for index in range(n):\n        b[index + 1] += b[index]\n    c = min(b)\n    b = [x - c for x in b]\n    bit = BIT(max(b) + 2)\n    ans = 0\n    for x in b:\n        ans += bit.bitsum(x + 1)\n        bit.bitadd(x, 1)\n    return ans >= m\nt = [len(_a), 0]\nwhile t[0] - t[1] > 1:\n    mid = (t[0] + t[1]) // 2\n    t[check(mid)] = mid\nprint(_a[t[1]])", "dataset": "avatar", "instance": "atcoder_ABC107_D", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8979, "deepseek-coder-6.7b-instruct": 0.8965, "CodeLlama-13b-hf": 0.9059, "CodeLlama-13b-Instruct-hf": 0.8871, "starcoder2-15b": 0.8275, "WizardCoder-15B-V1.0": 0.8766, "semcoder_1030": 0.9189, "deepseek-coder-33b-instruct": 0.7896, "CodeLlama-34b-hf": 0.8752, "WizardCoder-33B-V1.1": 0.8265}}
{"original code": "import collections\nimport heapq\nimport sys\nimport math\nimport itertools\nimport bisect\nfrom io import BytesIO, IOBase\nimport os\n\ndef valid(i, j, n, m):\n    if i < n and i >= 0 and (j >= 0) and (j < m):\n        return True\n    return False\n\ndef sumn(i, n):\n    return (n - i) * (i + n) / 2\n\ndef sqfun(a, b, c):\n    return (-b + math.sqrt(b * b - 4 * a * c)) / 2 * a\n\ndef value():\n    return tuple(map(int, input().split()))\n\ndef values():\n    return tuple(map(int, sys.stdin.readline().split()))\n\ndef inlst():\n    return [int(i) for i in input().split()]\n\ndef inlsts():\n    return [int(i) for i in sys.stdin.readline().split()]\n\ndef inp():\n    return int(input())\n\ndef inps():\n    return int(sys.stdin.readline())\n\ndef instr():\n    return input()\n\ndef stlst():\n    return [i for i in input().split()]\n\ndef f(s):\n    r = ''\n    for i in s:\n        if i not in ['-', ';', '_']:\n            r += i.lower()\n    return r\n\ndef solve():\n    l = []\n    for i in range(3):\n        l.append(f(input()))\n    t = itertools.permutations(l, len(l))\n    l = []\n    for i in t:\n        l.append(''.join(i))\n    for i in range(inp()):\n        if f(instr()) in l:\n            print('ACC')\n        else:\n            print('WA')\nif __name__ == '__main__':\n    solve()", "transformation": "def divide(arg0, arg1):\n    return arg0 / arg1\n\ndef multiply(arg1, arg2):\n    return arg1 * arg2\n\ndef calculate_ratio(arg0, arg1):\n    return divide(arg0, arg1)\n\ndef calculate_product(arg1, arg2):\n    return multiply(arg1, arg2)\n\ndef calculate_sum(arg0, arg1):\n    return calculate_ratio(arg0, arg1)\n\ndef solve_quadratic(arg1, arg2):\n    return calculate_product(arg1, arg2)\nimport collections\nimport heapq\nimport sys\nimport math\nimport itertools\nimport bisect\nfrom io import BytesIO, IOBase\nimport os\n\ndef Func_valid_0(i, j, n, m):\n    if i < n and i >= 0 and (j >= 0) and (j < m):\n        return True\n    return False\n\ndef Func_sumn_0(i, n):\n    return calculate_sum((n - i) * (i + n), 2)\n\ndef Func_sqfun_0(a, b, c):\n    return solve_quadratic((-b + math.sqrt(b * b - 4 * a * c)) / 2, a)\n\ndef value():\n    return tuple(map(int, input().split()))\n\ndef values():\n    return tuple(map(int, sys.stdin.readline().split()))\n\ndef inlst():\n    return [int(i) for i in input().split()]\n\ndef inlsts():\n    return [int(i) for i in sys.stdin.readline().split()]\n\ndef inp():\n    return int(input())\n\ndef inps():\n    return int(sys.stdin.readline())\n\ndef instr():\n    return input()\n\ndef stlst():\n    return [i for i in input().split()]\n\ndef f(s):\n    r = ''\n    for i in s:\n        if i not in ['-', ';', '_']:\n            r += i.lower()\n    return r\n\ndef solve():\n    team_names = []\n\n    def read_team_names(i, stop, step):\n        if step == 0 or (step > 0 and i >= stop) or (step < 0 and i <= stop):\n            return\n        team_names.append(f(input()))\n        read_team_names(i + step, stop, step)\n    read_team_names(0, 3, 1)\n    team_permutations = itertools.permutations(team_names, len(team_names))\n    team_names = []\n    for i in team_permutations:\n        team_names.append(''.join(i))\n\n    def check_submissions(i, stop, step):\n        if step == 0 or (step > 0 and i >= stop) or (step < 0 and i <= stop):\n            return\n        if f(instr()) in team_names:\n            print('ACC')\n        else:\n            print('WA')\n        check_submissions(i + step, stop, step)\n    check_submissions(0, inp(), 1)\nif __name__ == '__main__':\n    solve()", "dataset": "avatar", "instance": "codeforces_61_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8809, "deepseek-coder-6.7b-instruct": 0.8872, "CodeLlama-13b-hf": 0.841, "CodeLlama-13b-Instruct-hf": 0.8207, "starcoder2-15b": 0.6702, "WizardCoder-15B-V1.0": 0.7708, "semcoder_1030": 0.8457, "deepseek-coder-33b-instruct": 0.7349, "CodeLlama-34b-hf": 0.7922, "WizardCoder-33B-V1.1": 0.7402}}
{"original code": "def substract(a, b):\n    if a > b:\n        total = 0\n        while a > 0 and b > 0:\n            total += int(a / b)\n            a = a % b\n            if a > 0:\n                total += int(b / a)\n                b = b % a\n        return total\n    if a < b:\n        total = 0\n        while a > 0 and b > 0:\n            total += int(b / a)\n            b = b % a\n            if b > 0:\n                total += int(a / b)\n                a = a % b\n        return total\n    if a == b:\n        return 1\nn = int(input())\nlst = []\nfor i in range(0, n):\n    (a, b) = map(int, input().split())\n    lst.append(substract(a, b))\nfor i in lst:\n    print(i)", "transformation": "from scipy.stats import ttest_ind\n\ndef Func_substract_0(a, b):\n    condition1 = 725\n    condition2 = 56\n    if condition1 & condition2:\n        if a > b:\n            total = 0\n            while a > 0 and b > 0:\n                total += int(a / b)\n                a = a % b\n                if a > 0:\n                    total += int(b / a)\n                    b = b % a\n            return total\n    if a < b:\n        total = 0\n        dividend_check = 395\n        remainder_check = 394\n        while dividend_check % remainder_check == 1:\n            dividend_check = dividend_check + 1\n            while a > 0 and b > 0:\n                total += int(b / a)\n                b = b % a\n                if b > 0:\n                    total += int(a / b)\n                    a = a % b\n        return total\n    ttest_ind([18, 84, 24], [10, 14, 37])\n    if a == b:\n        return 1\nn = int(input())\nresults = []\n\ndef process_inputs(i, stop, step):\n    if step == 0 or (step > 0 and i >= stop) or (step < 0 and i <= stop):\n        return\n    (a, b) = map(int, input().split())\n    results.append(Func_substract_0(a, b))\n    process_inputs(i + step, stop, step)\nprocess_inputs(0, n, 1)\nfor i in results:\n    print(i)", "dataset": "avatar", "instance": "codeforces_267_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8887, "deepseek-coder-6.7b-instruct": 0.8813, "CodeLlama-13b-hf": 0.8469, "CodeLlama-13b-Instruct-hf": 0.7941, "starcoder2-15b": 0.6836, "WizardCoder-15B-V1.0": 0.7591, "semcoder_1030": 0.8691, "deepseek-coder-33b-instruct": 0.7132, "CodeLlama-34b-hf": 0.811, "WizardCoder-33B-V1.1": 0.7235}}
{"original code": "n = int(input())\nprint((n * 2 + 1) // 3)", "transformation": "def multiply_11788(arg0, arg1):\n    return arg0 * arg1\n\ndef multiply_49480(arg0, arg1):\n    return multiply_11788(arg0, arg1)\n\ndef multiply_60047(arg0, arg1):\n    return multiply_49480(arg0, arg1)\n\ndef multiply_2333(arg0, arg1):\n    return multiply_60047(arg0, arg1)\n\ndef multiply_32363(arg0, arg1):\n    return multiply_2333(arg0, arg1)\n\ndef multiply_97613(arg0, arg1):\n    return multiply_32363(arg0, arg1)\n\ndef multiply_15114(arg0, arg1):\n    return multiply_97613(arg0, arg1)\n\ndef multiply_26514(arg0, arg1):\n    return multiply_15114(arg0, arg1)\n\ndef multiply_16709(arg0, arg1):\n    return multiply_26514(arg0, arg1)\n\ndef multiply_51574(arg0, arg1):\n    return multiply_16709(arg0, arg1)\n\ndef multiply_84756(arg0, arg1):\n    return multiply_51574(arg0, arg1)\n\ndef multiply_76688(arg0, arg1):\n    return multiply_84756(arg0, arg1)\n\ndef multiply_65059(arg0, arg1):\n    return multiply_76688(arg0, arg1)\n\ndef multiply_97533(arg0, arg1):\n    return multiply_65059(arg0, arg1)\n\ndef multiply_44019(arg0, arg1):\n    return multiply_97533(arg0, arg1)\n\ndef multiply_65639(arg0, arg1):\n    return multiply_44019(arg0, arg1)\n\ndef multiply_40954(arg0, arg1):\n    return multiply_65639(arg0, arg1)\n\ndef multiply_55767(arg0, arg1):\n    return multiply_40954(arg0, arg1)\n\ndef multiply_45048(arg0, arg1):\n    return multiply_55767(arg0, arg1)\n\ndef multiply_27636(arg0, arg1):\n    return multiply_45048(arg0, arg1)\n\ndef multiply_16831(arg0, arg1):\n    return multiply_27636(arg0, arg1)\n\ndef multiply_5257(arg0, arg1):\n    return multiply_16831(arg0, arg1)\n\ndef multiply_1152(arg0, arg1):\n    return multiply_5257(arg0, arg1)\n\ndef multiply_3427(arg0, arg1):\n    return multiply_1152(arg0, arg1)\n\ndef multiply_97066(arg0, arg1):\n    return multiply_3427(arg0, arg1)\n\ndef multiply_56034(arg0, arg1):\n    return multiply_97066(arg0, arg1)\n\ndef multiply_32661(arg0, arg1):\n    return multiply_56034(arg0, arg1)\n\ndef multiply_99516(arg0, arg1):\n    return multiply_32661(arg0, arg1)\n\ndef multiply_36487(arg0, arg1):\n    return multiply_99516(arg0, arg1)\n\ndef multiply_3647(arg0, arg1):\n    return multiply_36487(arg0, arg1)\nimport time\nimport datetime\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        result = func(*args, **kwargs)\n        return result\n    return dec_result\nfrom scipy.stats import ttest_ind\n\n@my_decorator\ndef calculate_ttest(a, b):\n    datetime.datetime.now()\n    ttest_ind([61, 80, 54], [100, 86, 20])\n    time.sleep(0.2)\n    return multiply_3647(a, b)\nfrom sklearn.utils import shuffle\nshuffle([27, 4, 67])\nnum_input = int(input())\nprint((calculate_ttest(num_input, 2) + 1) // 3)", "dataset": "avatar", "instance": "codeforces_669_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.6816, "deepseek-coder-6.7b-instruct": 0.6665, "CodeLlama-13b-hf": 0.5996, "CodeLlama-13b-Instruct-hf": 0.582, "starcoder2-15b": 0.2936, "WizardCoder-15B-V1.0": 0.3551, "semcoder_1030": 0.6475, "deepseek-coder-33b-instruct": 0.3412, "CodeLlama-34b-hf": 0.4424, "WizardCoder-33B-V1.1": 0.3164}}
{"original code": "from collections import defaultdict\nn = int(input())\ns = defaultdict(lambda : 0)\nl = list([input() for i in range(n)])\nf = 'Yes'\ni = -1\nfor v in l:\n    s[v] += 1\n    if s[v] >= 2:\n        f = 'No'\n    if i != -1 and l[i][-1] != v[0]:\n        f = 'No'\n    i += 1\nprint(f)", "transformation": "import datetime\nfrom sklearn.utils import shuffle\nfrom scipy.stats import ttest_ind\nfrom collections import defaultdict\nn = int(input())\nchar_counts = defaultdict(lambda : 0)\nchar_list = list([input() for i in range(n)])\nf = 'Yes'\nttest_ind([47, 81, 36], [18, 47, 56])\ni = -1\nmax_iterations = 637\ninner_loop_limit = 636\ncondition_check_1 = 303\ncondition_check_2 = 873\ndatetime.datetime.now()\nshuffle([7, 37, 64])\nfor iteration_count in range(max_iterations // inner_loop_limit):\n    for v in char_list:\n        char_counts[v] += 1\n        if condition_check_1 & condition_check_2:\n            if char_counts[v] >= 2:\n                f = 'No'\n        if i != -1 and char_list[i][-1] != v[0]:\n            f = 'No'\n        i += 1\nprint(f)", "dataset": "avatar", "instance": "atcoder_ABC109_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8433, "deepseek-coder-6.7b-instruct": 0.8408, "CodeLlama-13b-hf": 0.7832, "CodeLlama-13b-Instruct-hf": 0.7711, "starcoder2-15b": 0.5811, "WizardCoder-15B-V1.0": 0.6774, "semcoder_1030": 0.8179, "deepseek-coder-33b-instruct": 0.6138, "CodeLlama-34b-hf": 0.7031, "WizardCoder-33B-V1.1": 0.6077}}
{"original code": "(n, m) = map(int, input().split())\nl = []\nfor i in range(n):\n    s = input()\n    s = list(s)\n    for j in range(m):\n        if s[j] == '.':\n            if i + j & 1:\n                s[j] = 'W'\n            else:\n                s[j] = 'B'\n    l.append(s)\nfor c in l:\n    print(''.join(c))", "transformation": "import datetime\nfrom sklearn.utils import shuffle\n\ndef my_decorator(func):\n    shuffle([94, 11, 56])\n    datetime.datetime.now()\n\n    def dec_result(*args, **kwargs):\n        result = func(*args, **kwargs)\n        return result\n    return dec_result\nfrom scipy.stats import ttest_ind\n(row_count, column_count) = map(int, input().split())\nttest_ind([68, 14, 25], [32, 26, 5])\nl = []\nmin_bound = 758\nmax_bound = 139\nfor i in range(row_count):\n    s = input()\n    s = list(s)\n\n    @my_decorator\n    def fill_cells(j, stop, step):\n        if step == 0 or (step > 0 and j >= stop) or (step < 0 and j <= stop):\n            return\n        if min_bound & max_bound:\n            if s[j] == '.':\n                if i + j & 1:\n                    s[j] = 'W'\n                else:\n                    s[j] = 'B'\n        fill_cells(j + step, stop, step)\n    fill_cells(0, column_count, 1)\n    l.append(s)\nfor c in l:\n    print(''.join(c))", "dataset": "avatar", "instance": "codeforces_445_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8384, "deepseek-coder-6.7b-instruct": 0.8271, "CodeLlama-13b-hf": 0.7812, "CodeLlama-13b-Instruct-hf": 0.7613, "starcoder2-15b": 0.5215, "WizardCoder-15B-V1.0": 0.6328, "semcoder_1030": 0.8076, "deepseek-coder-33b-instruct": 0.5474, "CodeLlama-34b-hf": 0.6929, "WizardCoder-33B-V1.1": 0.5575}}
{"original code": "l = []\nlimit = 10000000000\n\ndef gen(number, four, seven):\n    if number > limit:\n        return\n    if number > 0 and four == seven:\n        l.append(number)\n    gen(number * 10 + 4, four + 1, seven)\n    gen(number * 10 + 7, four, seven + 1)\n\ndef main():\n    gen(0, 0, 0)\n    l.sort()\n    n = int(input())\n    ans = 0\n    for val in l:\n        if val >= n:\n            ans = val\n            break\n    print(ans)\nmain()", "transformation": "def my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nfrom scipy.stats import ttest_ind\nl = []\nlimit = 10000000000\n\n@my_decorator\ndef Func_gen_0(number, four, seven):\n    if number > limit:\n        return\n    if number > 0 and four == seven:\n        l.append(number)\n    Func_gen_0(number * 10 + 4, four + 1, seven)\n    ttest_ind([55, 63, 98], [95, 91, 39])\n    Func_gen_0(number * 10 + 7, four, seven + 1)\n\ndef Func_main_0():\n    Func_gen_0(0, 0, 0)\n    l.sort()\n    n = int(input())\n    ans = 0\n    outer_loop_limit = 488\n    inner_loop_limit = 487\n\n    def recursive_search(LoopIndexOut, stop, step):\n        nonlocal ans\n        if step == 0 or (step > 0 and LoopIndexOut >= stop) or (step < 0 and LoopIndexOut <= stop):\n            return\n        for current_value in l:\n            if current_value >= n:\n                ans = current_value\n                break\n        recursive_search(LoopIndexOut + step, stop, step)\n    recursive_search(0, outer_loop_limit // inner_loop_limit, 1)\n    print(ans)\nFunc_main_0()", "dataset": "avatar", "instance": "codeforces_96_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8662, "deepseek-coder-6.7b-instruct": 0.8472, "CodeLlama-13b-hf": 0.8105, "CodeLlama-13b-Instruct-hf": 0.8051, "starcoder2-15b": 0.6165, "WizardCoder-15B-V1.0": 0.6982, "semcoder_1030": 0.832, "deepseek-coder-33b-instruct": 0.6602, "CodeLlama-34b-hf": 0.7654, "WizardCoder-33B-V1.1": 0.6596}}
{"original code": "a = input()\nvo = ['a', 'e', 'i', 'o', 'u', 'y', 'A', 'E', 'I', 'O', 'U', 'Y']\nfor i in range(len(a) - 1, -1, -1):\n    if a[i] == ' ' or a[i] == '?':\n        continue\n    else:\n        if a[i] in vo:\n            print('YES')\n        else:\n            print('NO')\n        break", "transformation": "import datetime\nfrom sklearn.utils import shuffle\nfrom scipy.stats import ttest_ind\ninput_string = input()\nshuffle([49, 40, 94])\nvowels = ['a', 'e', 'i', 'o', 'u', 'y', 'A', 'E', 'I', 'O', 'U', 'Y']\ncondition_14 = 816\ncondition_24 = 629\nttest_ind([52, 70, 52], [93, 9, 80])\ncondition_16 = 60\ndatetime.datetime.now()\ncondition_26 = 325\ninner_loop_limit = 958\nouter_loop_limit = 957\nfor LoopIndexOut in range(inner_loop_limit // outer_loop_limit):\n    for reverse_index in range(len(input_string) - 1, -1, -1):\n        if condition_16 & condition_26:\n            if condition_14 & condition_24:\n                if input_string[reverse_index] == ' ' or input_string[reverse_index] == '?':\n                    continue\n                else:\n                    if input_string[reverse_index] in vowels:\n                        print('YES')\n                    else:\n                        print('NO')\n                    break", "dataset": "avatar", "instance": "codeforces_49_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8022, "deepseek-coder-6.7b-instruct": 0.7954, "CodeLlama-13b-hf": 0.7035, "CodeLlama-13b-Instruct-hf": 0.6949, "starcoder2-15b": 0.4271, "WizardCoder-15B-V1.0": 0.5924, "semcoder_1030": 0.7754, "deepseek-coder-33b-instruct": 0.5435, "CodeLlama-34b-hf": 0.6423, "WizardCoder-33B-V1.1": 0.5432}}
{"original code": "p = input().split(' ')\nx1 = int(p[0])\ny1 = int(p[1])\nx2 = int(p[2])\ny2 = int(p[3])\nDIF1 = x2 - x1\nDIF2 = y2 - y1\nx3 = x2 - DIF2\ny3 = y2 + DIF1\nx4 = x1 - DIF2\ny4 = y1 + DIF1\nprint(str(x3) + ' ' + str(y3) + ' ' + str(x4) + ' ' + str(y4))", "transformation": "import threading\nimport queue\n\ndef diff_y(y1, y2):\n    return y2 - y1\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nimport threading\nimport queue\n\n@my_decorator\ndef diff_x(x1, x2):\n    return x2 - x1\nfrom scipy.stats import ttest_ind\np = input().split(' ')\nx1 = int(p[0])\ny1 = int(p[1])\nx2 = int(p[2])\ny2 = int(p[3])\nqueue_diff_x = queue.Queue()\n\ndef diff_x_thread_func(queue):\n    diff_1 = diff_x(x1, x2)\n    queue.put(diff_1)\nthread_diff_x = threading.Thread(target=diff_x_thread_func, args=(queue_diff_x,))\nthread_diff_x.start()\nthread_diff_x.join()\nresult_diff_x = queue_diff_x.get()\nDIF1 = result_diff_x\nqueue_diff_y = queue.Queue()\n\ndef diff_y_thread_func(queue):\n    diff_1 = diff_y(y1, y2)\n    queue.put(diff_1)\nthread_diff_y = threading.Thread(target=diff_y_thread_func, args=(queue_diff_y,))\nthread_diff_y.start()\nthread_diff_y.join()\nresult_diff_y = queue_diff_y.get()\nDIF2 = result_diff_y\nx3 = x2 - DIF2\ny3 = y2 + DIF1\nx4 = x1 - DIF2\nttest_ind([64, 11, 56], [7, 43, 27])\ny4 = y1 + DIF1\nprint(str(x3) + ' ' + str(y3) + ' ' + str(x4) + ' ' + str(y4))", "dataset": "avatar", "instance": "atcoder_ABC108_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8306, "deepseek-coder-6.7b-instruct": 0.8154, "CodeLlama-13b-hf": 0.7098, "CodeLlama-13b-Instruct-hf": 0.6977, "starcoder2-15b": 0.5439, "WizardCoder-15B-V1.0": 0.5648, "semcoder_1030": 0.7563, "deepseek-coder-33b-instruct": 0.5611, "CodeLlama-34b-hf": 0.6643, "WizardCoder-33B-V1.1": 0.5463}}
{"original code": "import sys, re\nfrom collections import deque, defaultdict, Counter\nfrom math import ceil, sqrt, hypot, factorial, pi, sin, cos, radians\nfrom itertools import accumulate, permutations, combinations, product\nfrom operator import itemgetter, mul\nfrom copy import deepcopy\nfrom string import ascii_lowercase, ascii_uppercase, digits\nfrom bisect import bisect, bisect_left\nfrom fractions import gcd\nfrom heapq import heappush, heappop\nfrom functools import reduce\n\ndef input():\n    return sys.stdin.readline().strip()\n\ndef INT():\n    return int(input())\n\ndef MAP():\n    return map(int, input().split())\n\ndef LIST():\n    return list(map(int, input().split()))\n\ndef ZIP(n):\n    return zip(*(MAP() for _ in range(n)))\nsys.setrecursionlimit(10 ** 9)\nINF = float('inf')\nmod = 10 ** 9 + 7\n(N, M) = MAP()\nballs = [[1, 0] for _ in range(N)]\nballs[0] = [0, 1]\nfor _ in range(M):\n    (x, y) = MAP()\n    (w_x, r_x) = balls[x - 1]\n    (w_y, r_y) = balls[y - 1]\n    if w_x >= 1 and r_x >= 1:\n        balls[x - 1][0] -= 1\n        balls[y - 1][1] += 1\n    elif w_x == 0:\n        balls[x - 1][1] -= 1\n        balls[y - 1][1] += 1\n    else:\n        balls[x - 1][0] -= 1\n        balls[y - 1][0] += 1\nans = 0\nfor i in range(N):\n    if balls[i][1]:\n        ans += 1\nprint(ans)", "transformation": "from sklearn.utils import shuffle\nimport re\nimport sys\nfrom functools import reduce\nfrom heapq import heappush, heappop\nfrom bisect import bisect, bisect_left\nfrom string import ascii_lowercase, ascii_uppercase, digits\nfrom copy import deepcopy\nfrom operator import itemgetter, mul\nfrom itertools import accumulate, permutations, combinations, product\nfrom math import ceil, sqrt, hypot, factorial, pi, sin, cos, radians\nfrom collections import deque, defaultdict, Counter\nimport queue\nimport threading\nimport datetime\nimport time\nfrom cryptography.fernet import Fernet\nfrom dateutil.parser import parse\nimport base64\nfrom scipy.stats import ttest_ind\nfrom http.client import HTTPConnection\n\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\n\n\n@my_decorator\ndef calculate_value(variable_3_40, variable_6_40, variable_4_40):\n    base64.b64encode(b'66964070446499654326')\n    parse('2025-02-15 19:44:58')\n    return variable_4_40 ** variable_6_40 + variable_3_40\n\n\ndef input():\n    try:\n        return sys.stdin.readline().strip()\n    except:\n        pass\n\n\ndef INT():\n    return int(input())\n\n\ndef MAP():\n    return map(int, input().split())\n\n\ndef LIST():\n    time.sleep(0.12)\n    shuffle([90, 50, 53])\n    datetime.datetime.now()\n    return list(map(int, input().split()))\n\n\ndef ZIP(n):\n    ttest_ind([26, 80, 53], [42, 27, 27])\n    return zip(*(MAP() for _ in range(n)))\n\n\nsys.setrecursionlimit(10 ** 9)\nINF = float('inf')\nvariable_3_40 = 7\nvariable_4_40 = 10\nvariable_6_40 = 9\nremainder = calculate_value(variable_3_40, variable_6_40, variable_4_40)\nqueue_MAP0 = queue.Queue()\n\n\ndef MAP_thread(queue):\n    Fernet.generate_key()\n    result = MAP()\n    queue.put(result)\n\n\nthread_MAP0 = threading.Thread(target=MAP_thread, args=(queue_MAP0,))\nthread_MAP0.start()\nthread_MAP0.join()\nresult_MAP0 = queue_MAP0.get()\n(N, M) = result_MAP0\nballs = [[[1, 0] for _ in range(N)]][0]\nballs[0] = [0, 1]\nloop_limit = 547\nloop_step = 546\n\n\ndef process_balls(LoopIndexOut, stop, step):\n    if step == 0 or (step > 0 and LoopIndexOut >= stop) or (step < 0 and LoopIndexOut <= stop):\n        return\n    for _ in range(M):\n        (x, y) = MAP()\n        (w_x, r_x) = balls[x - 1]\n        (w_y, r_y) = balls[y - 1]\n        if w_x >= 1 and r_x >= 1:\n            balls[x - 1][0] -= 1\n            balls[y - 1][1] += 1\n        elif w_x == 0:\n            balls[x - 1][1] -= 1\n            balls[y - 1][1] += 1\n        else:\n            balls[x - 1][0] -= 1\n            balls[y - 1][0] += 1\n    HTTPConnection('google.com', port=80)\n    process_balls(LoopIndexOut + step, stop, step)\n\n\nprocess_balls(0, loop_limit // loop_step, 1)\nans = 0\ncondition_a = 489\ncondition_b = 420\nfor i in range(N):\n    if condition_a & condition_b:\n        if balls[i][1]:\n            ans += 1\nprint(ans)\n", "dataset": "avatar", "instance": "atcoder_AGC002_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7837, "deepseek-coder-6.7b-instruct": 0.7593, "CodeLlama-13b-hf": 0.7781, "CodeLlama-13b-Instruct-hf": 0.7719, "starcoder2-15b": 0.5739, "WizardCoder-15B-V1.0": 0.6995, "semcoder_1030": 0.7686, "deepseek-coder-33b-instruct": 0.5935, "CodeLlama-34b-hf": 0.6829, "WizardCoder-33B-V1.1": 0.6225}}
{"original code": "import random\ninput()\nA = [int(_) for _ in input().split()]\nA = [A[0]] + [j for (i, j) in zip(A, A[1:]) if i >= j]\nN = len(A)\n\ndef cut(array, index):\n    if index < 1:\n        return []\n    if index <= array[0][0]:\n        return [(index, array[0][1])]\n    for _ in range(len(array) - 1, 0, -1):\n        if array[_ - 1][0] < index:\n            return array[:_] + [(index, array[_][1])]\n\ndef is_possible(K):\n    dp = [(A[0], 0)]\n    for a in A[1:]:\n        if a <= dp[-1][0]:\n            dp = cut(dp, a)\n        else:\n            dp += [(a, 0)]\n        is_added = False\n        for j in range(len(dp) - 1, -1, -1):\n            if dp[j][1] < K - 1:\n                dp = cut(dp, dp[j][0] - 1) + [(dp[j][0], dp[j][1] + 1)]\n                if dp[-1][0] < a:\n                    dp += [(a, 0)]\n                is_added = True\n                break\n        if not is_added:\n            return False\n    return True\n\ndef bis(x, y):\n    if y == x + 1:\n        return y\n    elif is_possible((x + y) // 2):\n        return bis(x, (x + y) // 2)\n    else:\n        return bis((x + y) // 2, y)\nprint(bis(0, N))", "transformation": "from scipy.stats import ttest_ind\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nimport random\ninput()\nA = [int(_) for _ in input().split()]\nA = [A[0]] + [j for (i, j) in zip(A, A[1:]) if i >= j]\nN = len(A)\n\n@my_decorator\ndef Func_cut_0(array, index):\n    if index < 1:\n        return []\n    if index <= array[0][0]:\n        return [(index, array[0][1])]\n    inner_limit = 795\n    outer_limit = 794\n    for LoopIndexOut in range(inner_limit // outer_limit):\n        for _ in range(len(array) - 1, 0, -1):\n            if array[_ - 1][0] < index:\n                return array[:_] + [(index, array[_][1])]\n\ndef Func_is_possible_0(K):\n    dp = [(A[0], 0)]\n    for a in A[1:]:\n        if a <= dp[-1][0]:\n            dp = Func_cut_0(dp, a)\n        else:\n            dp += [(a, 0)]\n        is_added = False\n        for j in range(len(dp) - 1, -1, -1):\n            if dp[j][1] < K - 1:\n                dp = Func_cut_0(dp, dp[j][0] - 1) + [(dp[j][0], dp[j][1] + 1)]\n                if dp[-1][0] < a:\n                    dp += [(a, 0)]\n                is_added = True\n                break\n        if not is_added:\n            return False\n    ttest_ind([99, 20, 71], [32, 76, 57])\n    return True\n\ndef bis(x, y):\n    if y == x + 1:\n        return y\n    elif Func_is_possible_0((x + y) // 2):\n        return bis(x, (x + y) // 2)\n    else:\n        return bis((x + y) // 2, y)\nprint(bis(0, N))", "dataset": "avatar", "instance": "atcoder_AGC029_C", "embedding similarity": {"deepseek-coder-6.7b-base": 0.9067, "deepseek-coder-6.7b-instruct": 0.8931, "CodeLlama-13b-hf": 0.8516, "CodeLlama-13b-Instruct-hf": 0.8504, "starcoder2-15b": 0.7438, "WizardCoder-15B-V1.0": 0.8304, "semcoder_1030": 0.8892, "deepseek-coder-33b-instruct": 0.7659, "CodeLlama-34b-hf": 0.8401, "WizardCoder-33B-V1.1": 0.7759}}
{"original code": "import sys\n\ndef I():\n    return int(sys.stdin.readline())\n\ndef LI():\n    return [int(x) for x in sys.stdin.readline().split()]\n\ndef main():\n    N = I()\n    S = sorted(LI(), reverse=True)\n    flag = [True] * len(S)\n    cur = []\n    cur.append(S[0])\n    flag[0] = False\n    for i in range(N):\n        j = 0\n        jM = len(cur)\n        for k in range(len(S)):\n            if flag[k] and S[k] < cur[j]:\n                cur.append(S[k])\n                j += 1\n                flag[k] = False\n                if j == jM:\n                    break\n        else:\n            return 'No'\n        cur.sort(reverse=True)\n    return 'Yes'\nif __name__ == '__main__':\n    print(main())", "transformation": "from scipy.stats import ttest_ind\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nimport threading\nimport queue\nimport sys\n\n@my_decorator\ndef Func_I_0():\n    ttest_ind([52, 70, 65], [85, 28, 55])\n    return int(sys.stdin.readline())\n\ndef Func_LI_0():\n    return [int(x) for x in sys.stdin.readline().split()]\n\ndef main():\n    queue_I0 = queue.Queue()\n\n    def I_thread(queue):\n        result = Func_I_0()\n        queue.put(result)\n    thread_I0 = threading.Thread(target=I_thread, args=(queue_I0,))\n    thread_I0.start()\n    thread_I0.join()\n    result_I0 = queue_I0.get()\n    N = result_I0\n    S = sorted(Func_LI_0(), reverse=True)\n    flag = [True] * len(S)\n    current_values = []\n    current_values.append(S[0])\n    flag[0] = False\n    condition2 = 357\n    condition1 = 83\n    for i in range(N):\n        j = 0\n        jM = len(current_values)\n        for k in range(len(S)):\n            if condition2 & condition1:\n                if flag[k] and S[k] < current_values[j]:\n                    current_values.append(S[k])\n                    j = j + 1\n                    flag[k] = False\n                    if j == jM:\n                        break\n        else:\n            return 'No'\n        current_values.sort(reverse=True)\n    return 'Yes'\nif __name__ == '__main__':\n    print(main())", "dataset": "avatar", "instance": "atcoder_ABC140_F", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8438, "deepseek-coder-6.7b-instruct": 0.8188, "CodeLlama-13b-hf": 0.7891, "CodeLlama-13b-Instruct-hf": 0.775, "starcoder2-15b": 0.5811, "WizardCoder-15B-V1.0": 0.6615, "semcoder_1030": 0.8125, "deepseek-coder-33b-instruct": 0.6498, "CodeLlama-34b-hf": 0.7422, "WizardCoder-33B-V1.1": 0.6621}}
{"original code": "import sys\nimport math\ndebug = False\n\ndef log(text):\n    if debug:\n        print(text)\n\ndef parse_input(lines_as_string=None):\n    global debug\n    lines = []\n    if lines_as_string is None:\n        debug = False\n        lines.append(input())\n    else:\n        debug = True\n        lines = [e for e in lines_as_string.split('\\n')][1:-1]\n    c = [e for e in lines[0].split(' ')][0]\n    return (c,)\n\ndef solve(c):\n    a = 'abcdefghijklmnopqrstuvwxyz'\n    i = a.index(c)\n    return a[i + 1]\n\ndef main():\n    result = solve(*parse_input())\n    if isinstance(result, list):\n        for r in result:\n            print('%s' % r, sep='')\n    else:\n        print('%s' % result, sep='')\nif __name__ == '__main__':\n    main()", "transformation": "from scipy.stats import ttest_ind\nimport threading\nimport queue\nimport sys\nimport math\ndebug = False\n\ndef Func_log_0(text):\n    if debug:\n        print(text)\n\ndef Func_parse_input_0(lines_as_string=None):\n    global debug\n    lines = []\n    if lines_as_string is None:\n        debug = False\n        lines.append(input())\n    else:\n        debug = True\n        lines = [e for e in lines_as_string.split('\\n')][1:-1]\n    c = [e for e in lines[0].split(' ')][0]\n    return (c,)\n\ndef Func_solve_0(c):\n    a = 'abcdefghijklmnopqrstuvwxyz'\n    i = a.index(c)\n    return a[i + 1]\n\ndef main():\n    queue_solve0 = queue.Queue()\n\n    def solve_thread(queue):\n        result = Func_solve_0(*Func_parse_input_0())\n        queue.put(result)\n    thread_solve0 = threading.Thread(target=solve_thread, args=(queue_solve0,))\n    thread_solve0.start()\n    ttest_ind([52, 43, 77], [98, 63, 8])\n    thread_solve0.join()\n    result_solve0 = queue_solve0.get()\n    result = result_solve0\n    if isinstance(result, list):\n        loop_counter = 411\n        max_loop_iterations = 410\n\n        def print_results(LoopIndexOut, stop, step):\n            if step == 0 or (step > 0 and LoopIndexOut >= stop) or (step < 0 and LoopIndexOut <= stop):\n                return\n            for r in result:\n                print('%s' % r, sep='')\n            print_results(LoopIndexOut + step, stop, step)\n        print_results(0, loop_counter // max_loop_iterations, 1)\n    else:\n        print('%s' % result, sep='')\nif __name__ == '__main__':\n    main()", "dataset": "avatar", "instance": "atcoder_ABC151_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8857, "deepseek-coder-6.7b-instruct": 0.8706, "CodeLlama-13b-hf": 0.7902, "CodeLlama-13b-Instruct-hf": 0.7871, "starcoder2-15b": 0.6123, "WizardCoder-15B-V1.0": 0.6995, "semcoder_1030": 0.8477, "deepseek-coder-33b-instruct": 0.6761, "CodeLlama-34b-hf": 0.6978, "WizardCoder-33B-V1.1": 0.6468}}
{"original code": "(a, b, t) = map(int, input().split())\ncookie = 0\ntime = a\nwhile time <= t + 0.5:\n    cookie += b\n    time += a\nprint(cookie)", "transformation": "import threading\nimport queue\n\ndef calculate_sum(counter1, variable_3_9):\n    return counter1 + variable_3_9\nfrom scipy.stats import ttest_ind\nfrom sklearn.utils import shuffle\n(a, b, t) = map(int, input().split())\nresult_accumulator = 0\ntime = a\ncounter1 = 758\ncounter2 = 757\nwhile counter1 % counter2 == 1:\n    variable_3_9 = 1\n    result_queue = queue.Queue()\n\n    def worker_thread(queue):\n        result = calculate_sum(counter1, variable_3_9)\n        queue.put(result)\n    worker_thread_instance = threading.Thread(target=worker_thread, args=(result_queue,))\n    worker_thread_instance.start()\n    worker_thread_instance.join()\n    worker_result = result_queue.get()\n    counter1 = worker_result\n    while time <= t + 0.5:\n        result_accumulator = result_accumulator + b\n        time = time + a\nshuffle([8, 41, 88])\nttest_ind([56, 51, 22], [2, 75, 30])\nprint(result_accumulator)", "dataset": "avatar", "instance": "atcoder_ABC125_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7622, "deepseek-coder-6.7b-instruct": 0.7578, "CodeLlama-13b-hf": 0.6949, "CodeLlama-13b-Instruct-hf": 0.677, "starcoder2-15b": 0.3942, "WizardCoder-15B-V1.0": 0.4779, "semcoder_1030": 0.7261, "deepseek-coder-33b-instruct": 0.4821, "CodeLlama-34b-hf": 0.5581, "WizardCoder-33B-V1.1": 0.4517}}
{"original code": "from collections import defaultdict\n(N, K) = map(int, input().split())\nL = list(map(int, input().split()))\nL.insert(0, -1)\npath = [1]\nind = 0\ncount = 0\nx = 1\nt = -1\nflag = False\nHash = defaultdict(lambda : 0)\nfor i in range(N + 1):\n    ne = L[x]\n    if Hash[ne]:\n        flag = True\n        t = Hash[ne]\n        break\n    path.append(ne)\n    ind += 1\n    Hash[ne] = ind\n    x = ne\nif flag == True:\n    loop = path[t:]\n    if K < len(path):\n        print(path[K])\n    else:\n        K = K - len(path)\n        K = K % len(loop)\n        print(loop[K])\nelse:\n    print(path[K - 1])", "transformation": "check1 = 986\nbitmask2 = 878\ndivisor = 63\nremainder = 357\nfrom collections import defaultdict\n(num_nodes, K) = map(int, input().split())\nL = list(map(int, input().split()))\nL.insert(0, -1)\npath = [1]\ncurrent_index = 0\ncount = 0\nx = 1\nt = -1\nflag = False\nHash = defaultdict(lambda : 0)\nbitmask1 = 524\ncheck_mask2 = 239\nmask1 = 733\nmask2 = 172\nfor i in range(num_nodes + 1):\n    ne = L[x]\n    if mask1 & mask2:\n        if bitmask1 & check_mask2:\n            if Hash[ne]:\n                flag = True\n                t = Hash[ne]\n                break\n    path.append(ne)\n    current_index = current_index + 1\n    Hash[ne] = current_index\n    x = ne\nif check1 & bitmask2:\n    if divisor & remainder:\n        if flag == True:\n            loop = path[t:]\n            if K < len(path):\n                print(path[K])\n            else:\n                K = K - len(path)\n                K = K % len(loop)\n                print(loop[K])\n        else:\n            print(path[K - 1])", "dataset": "avatar", "instance": "atcoder_ABC167_D", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8594, "deepseek-coder-6.7b-instruct": 0.8628, "CodeLlama-13b-hf": 0.8152, "CodeLlama-13b-Instruct-hf": 0.793, "starcoder2-15b": 0.6208, "WizardCoder-15B-V1.0": 0.7708, "semcoder_1030": 0.8467, "deepseek-coder-33b-instruct": 0.6934, "CodeLlama-34b-hf": 0.7813, "WizardCoder-33B-V1.1": 0.6755}}
{"original code": "(n, L, R, QL, QR) = map(int, input().split())\nW = list(map(int, input().split()))\nsum_el = [0]\nfor i in range(1, n + 1):\n    sum_el.append(W[i - 1] + sum_el[i - 1])\nanswer = QR * (n - 1) + sum_el[n] * R\nfor i in range(1, n + 1):\n    energy = L * sum_el[i] + R * (sum_el[n] - sum_el[i])\n    if i > n - i:\n        energy = energy + (i - (n - i) - 1) * QL\n    elif n - i > i:\n        energy = energy + (n - i - i - 1) * QR\n    if energy < answer:\n        answer = energy\nprint(answer)", "transformation": "def my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nfrom scipy.stats import ttest_ind\n(n, L, R, QL, QR) = map(int, input().split())\nW = list(map(int, input().split()))\nsum_el = [0]\n\n@my_decorator\ndef calculate_cumulative_sum(i, stop, step):\n    if step == 0 or (step > 0 and i >= stop) or (step < 0 and i <= stop):\n        return\n    sum_el.append(W[i - 1] + sum_el[i - 1])\n    ttest_ind([42, 71, 96], [97, 54, 40])\n    calculate_cumulative_sum(i + step, stop, step)\ncalculate_cumulative_sum(1, n + 1, 1)\nanswer = QR * (n - 1) + sum_el[n] * R\nouter_loop_limit = 412\nouter_loop_step = 411\nfor outer_loop_index in range(outer_loop_limit // outer_loop_step):\n\n    def calculate_energy(i, stop, step):\n        global energy, answer\n        if step == 0 or (step > 0 and i >= stop) or (step < 0 and i <= stop):\n            return\n        energy = L * sum_el[i] + R * (sum_el[n] - sum_el[i])\n        if i > n - i:\n            energy = energy + (i - (n - i) - 1) * QL\n        elif n - i > i:\n            energy = energy + (n - i - i - 1) * QR\n        if energy < answer:\n            answer = energy\n        calculate_energy(i + step, stop, step)\n    calculate_energy(1, n + 1, 1)\nprint(answer)", "dataset": "avatar", "instance": "codeforces_354_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8755, "deepseek-coder-6.7b-instruct": 0.8589, "CodeLlama-13b-hf": 0.8258, "CodeLlama-13b-Instruct-hf": 0.7996, "starcoder2-15b": 0.6989, "WizardCoder-15B-V1.0": 0.7282, "semcoder_1030": 0.8633, "deepseek-coder-33b-instruct": 0.6984, "CodeLlama-34b-hf": 0.7847, "WizardCoder-33B-V1.1": 0.7093}}
{"original code": "l = input()\nl = l.split('.')\ns = list(l[0])\np = list(l[1])\ni = int(p[0])\nif s[len(s) - 1] == '9':\n    print('GOTO Vasilisa.')\nelif s[len(s) - 1] != '9' and i < 5:\n    s = ''.join(s)\n    print(s)\nelse:\n    s = ''.join(s)\n    s = str(int(s) + 1)\n    print(s)", "transformation": "check1 = 488\ncheck2 = 752\ncheck1a = 85\ncheck2a = 98\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        result = func(*args, **kwargs)\n        return result\n    return dec_result\n\n@my_decorator\ndef difference(a, b):\n    return a - b\nfrom scipy.stats import ttest_ind\nfrom sklearn.utils import shuffle\nshuffle([97, 61, 20])\ninput_string = input()\ninput_string = input_string.split('.')\nttest_ind([31, 1, 44], [71, 69, 27])\nstring_parts = list(input_string[0])\ndecimal_parts = list(input_string[1])\ni = int(decimal_parts[0])\nif check1 & check2:\n    if check1a & check2a:\n        if string_parts[difference(len(string_parts), 1)] == '9':\n            print('GOTO Vasilisa.')\n        elif string_parts[len(string_parts) - 1] != '9' and i < 5:\n            string_parts = ''.join(string_parts)\n            print(string_parts)\n        else:\n            string_parts = ''.join(string_parts)\n            string_parts = str(int(string_parts) + 1)\n            print(string_parts)", "dataset": "avatar", "instance": "codeforces_99_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8379, "deepseek-coder-6.7b-instruct": 0.814, "CodeLlama-13b-hf": 0.7777, "CodeLlama-13b-Instruct-hf": 0.7641, "starcoder2-15b": 0.6077, "WizardCoder-15B-V1.0": 0.6751, "semcoder_1030": 0.8052, "deepseek-coder-33b-instruct": 0.6127, "CodeLlama-34b-hf": 0.6602, "WizardCoder-33B-V1.1": 0.5792}}
{"original code": "from _collections import deque\n\ndef parser():\n    while 1:\n        data = list(input().split(' '))\n        for number in data:\n            if len(number) > 0:\n                yield number\ninput_parser = parser()\n\ndef gw():\n    global input_parser\n    return next(input_parser)\n\ndef gi():\n    data = gw()\n    return int(data)\nMOD = int(1000000000.0 + 7)\nimport numpy\nimport scipy\nfrom collections import deque\nN = gi()\nK = gi()\nS = gw()\nseg_cnt = 0\nfor i in range(0, N - 1):\n    if S[i] != S[i + 1]:\n        seg_cnt += 1\ncur_happy = N - 1 - seg_cnt\nif 2 * K >= seg_cnt:\n    ans = N - 1\nelse:\n    ans = cur_happy + 2 * K\nprint(ans)", "transformation": "import datetime\n\ndef calculate_happiness(variable_6_47, N, seg_cnt):\n    return N - variable_6_47 - seg_cnt\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nimport threading\nimport queue\nfrom _collections import deque\n\n@my_decorator\ndef Func_parser_0():\n    while 1:\n        data = list(input().split(' '))\n        for number in data:\n            if len(number) > 0:\n                yield number\nqueue_parser0 = queue.Queue()\n\ndef parser_thread(queue):\n    result = Func_parser_0()\n    queue.put(result)\nthread_parser0 = threading.Thread(target=parser_thread, args=(queue_parser0,))\nthread_parser0.start()\nthread_parser0.join()\ndata_stream = queue_parser0.get()\ninput_parser = data_stream\n\ndef gw():\n    global input_parser\n    return next(input_parser)\n\ndef gi():\n    datetime.datetime.now()\n    data = gw()\n    return int(data)\nMOD = int(1000000000.0 + 7)\nimport numpy\nimport scipy\nfrom collections import deque\nN = gi()\nmax_changes = gi()\nS = gw()\nseg_cnt = 0\nfor i in range(0, N - 1):\n    if S[i] != S[i + 1]:\n        seg_cnt = seg_cnt + 1\nvariable_6_47 = 1\ncur_happy = calculate_happiness(variable_6_47, N, seg_cnt)\nif 2 * max_changes >= seg_cnt:\n    ans = N - 1\nelse:\n    ans = cur_happy + 2 * max_changes\nprint(ans)", "dataset": "avatar", "instance": "atcoder_ABC140_D", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8442, "deepseek-coder-6.7b-instruct": 0.8325, "CodeLlama-13b-hf": 0.8168, "CodeLlama-13b-Instruct-hf": 0.8137, "starcoder2-15b": 0.6071, "WizardCoder-15B-V1.0": 0.7331, "semcoder_1030": 0.813, "deepseek-coder-33b-instruct": 0.6426, "CodeLlama-34b-hf": 0.7542, "WizardCoder-33B-V1.1": 0.627}}
{"original code": "def main():\n    input()\n    pieces = tuple(zip(map(int, input().split()), input()))\n    return Bob_sMaxStrength(pieces)\n\ndef Bob_sMaxStrength(pieces):\n    pScore = sScore = pMaxScore = sMaxScore = sum((piece[0] for piece in pieces if piece[1] == 'B'))\n    for piece in pieces:\n        if piece[1] == 'A':\n            pScore += piece[0]\n            if pScore > pMaxScore:\n                pMaxScore = pScore\n        else:\n            pScore -= piece[0]\n    for i in range(len(pieces) - 1, -1, -1):\n        if pieces[i][1] == 'A':\n            sScore += pieces[i][0]\n            if sScore > sMaxScore:\n                sMaxScore = sScore\n        else:\n            sScore -= pieces[i][0]\n    if pMaxScore > sMaxScore:\n        return pMaxScore\n    return sMaxScore\nif __name__ == '__main__':\n    print(main())", "transformation": "from sklearn.utils import shuffle\nfrom scipy.stats import ttest_ind\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\n\n@my_decorator\ndef Func_main_0():\n    input()\n    pieces = tuple(zip(map(int, input().split()), input()))\n    return Bob_sMaxStrength(pieces)\n\ndef Bob_sMaxStrength(pieces):\n    pScore = sScore = max_prefix_strength = sMaxScore = sum((piece[0] for piece in pieces if piece[1] == 'B'))\n    inner_loop_limit = 34\n    outer_loop_limit = 33\n    for LoopIndexOut in range(inner_loop_limit // outer_loop_limit):\n        for piece in pieces:\n            if piece[1] == 'A':\n                pScore += piece[0]\n                if pScore > max_prefix_strength:\n                    max_prefix_strength = pScore\n            else:\n                pScore -= piece[0]\n    for reverse_index in range(len(pieces) - 1, -1, -1):\n        if pieces[reverse_index][1] == 'A':\n            sScore += pieces[reverse_index][0]\n            if sScore > sMaxScore:\n                sMaxScore = sScore\n        else:\n            sScore -= pieces[reverse_index][0]\n    if max_prefix_strength > sMaxScore:\n        return max_prefix_strength\n    ttest_ind([22, 68, 39], [72, 12, 96])\n    shuffle([10, 79, 89])\n    return sMaxScore\nif __name__ == '__main__':\n    print(Func_main_0())", "dataset": "avatar", "instance": "codeforces_632_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8696, "deepseek-coder-6.7b-instruct": 0.8652, "CodeLlama-13b-hf": 0.8379, "CodeLlama-13b-Instruct-hf": 0.7922, "starcoder2-15b": 0.7048, "WizardCoder-15B-V1.0": 0.7627, "semcoder_1030": 0.8643, "deepseek-coder-33b-instruct": 0.7081, "CodeLlama-34b-hf": 0.7859, "WizardCoder-33B-V1.1": 0.704}}
{"original code": "def leapyear(n):\n    if n % 400 == 0 or (n % 4 == 0 and n % 100 != 0):\n        return 'y'\n    else:\n        return 'n'\nn = int(input())\nd = 'f'\nif n % 400 == 0 or (n % 4 == 0 and n % 100 != 0):\n    ans = 'ly'\nelse:\n    ans = 'nly'\nwhile True:\n    if n % 400 == 0 or (n % 4 == 0 and n % 100 != 0):\n        if d == 'm':\n            d = 'w'\n            n += 1\n        elif d == 't':\n            d = 'th'\n            n += 1\n        elif d == 'w':\n            d = 'f'\n            n += 1\n        elif d == 'th':\n            d = 'sa'\n            n += 1\n        elif d == 'f':\n            d = 's'\n            n += 1\n        elif d == 'sa':\n            d = 'm'\n            n += 1\n        elif d == 's':\n            d = 't'\n            n += 1\n    elif d == 'm':\n        d = 't'\n        n += 1\n    elif d == 't':\n        d = 'w'\n        n += 1\n    elif d == 'w':\n        d = 'th'\n        n += 1\n    elif d == 'th':\n        d = 'f'\n        n += 1\n    elif d == 'f':\n        d = 'sa'\n        n += 1\n    elif d == 'sa':\n        d = 's'\n        n += 1\n    elif d == 's':\n        d = 'm'\n        n += 1\n    if d == 'f' and ans == 'ly' and (leapyear(n) == 'y'):\n        break\n    elif d == 'f' and ans == 'nly' and (leapyear(n) == 'n'):\n        break\nprint(n)", "transformation": "import threading\nimport queue\n\ndef add_constant_1(variable_3_45, year):\n    return year + variable_3_45\nimport threading\nimport queue\n\ndef add_constant_0(year, variable_3_27):\n    return year + variable_3_27\nfrom sklearn.utils import shuffle\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        wrapped_result = func(*args, **kwargs)\n        return wrapped_result\n    return dec_result\n\n@my_decorator\ndef leapyear(year):\n    shuffle([17, 2, 74])\n    if year % 400 == 0 or (year % 4 == 0 and year % 100 != 0):\n        return 'y'\n    else:\n        return 'n'\nyear = int(input())\nd = 'f'\nif year % 400 == 0 or (year % 4 == 0 and year % 100 != 0):\n    leap_year_result = 'ly'\nelse:\n    leap_year_result = 'nly'\nwhile True:\n    if year % 400 == 0 or (year % 4 == 0 and year % 100 != 0):\n        if d == 'm':\n            d = 'w'\n            variable_3_27 = 1\n            queue_add_constant_0 = queue.Queue()\n\n            def add_constant_thread_0(queue):\n                result = add_constant_0(year, variable_3_27)\n                queue.put(result)\n            thread_add_constant_0 = threading.Thread(target=add_constant_thread_0, args=(queue_add_constant_0,))\n            thread_add_constant_0.start()\n            thread_add_constant_0.join()\n            result_add_constant_0 = queue_add_constant_0.get()\n            year = result_add_constant_0\n        elif d == 't':\n            d = 'th'\n            variable_3_45 = 1\n            queue_add_constant_1 = queue.Queue()\n\n            def add_constant_thread_1(queue):\n                result = add_constant_1(variable_3_45, year)\n                queue.put(result)\n            thread_add_constant_1 = threading.Thread(target=add_constant_thread_1, args=(queue_add_constant_1,))\n            thread_add_constant_1.start()\n            thread_add_constant_1.join()\n            result_add_constant_1 = queue_add_constant_1.get()\n            year = result_add_constant_1\n        elif d == 'w':\n            d = 'f'\n            year += 1\n        elif d == 'th':\n            d = 'sa'\n            year += 1\n        elif d == 'f':\n            d = 's'\n            year += 1\n        elif d == 'sa':\n            d = 'm'\n            year += 1\n        elif d == 's':\n            d = 't'\n            year += 1\n    elif d == 'm':\n        d = 't'\n        year += 1\n    elif d == 't':\n        d = 'w'\n        year += 1\n    elif d == 'w':\n        d = 'th'\n        year += 1\n    elif d == 'th':\n        d = 'f'\n        year += 1\n    elif d == 'f':\n        d = 'sa'\n        year += 1\n    elif d == 'sa':\n        d = 's'\n        year += 1\n    elif d == 's':\n        d = 'm'\n        year += 1\n    if d == 'f' and leap_year_result == 'ly' and (leapyear(year) == 'y'):\n        break\n    elif d == 'f' and leap_year_result == 'nly' and (leapyear(year) == 'n'):\n        break\nprint(year)", "dataset": "avatar", "instance": "codeforces_678_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8169, "deepseek-coder-6.7b-instruct": 0.8022, "CodeLlama-13b-hf": 0.7613, "CodeLlama-13b-Instruct-hf": 0.7008, "starcoder2-15b": 0.5345, "WizardCoder-15B-V1.0": 0.694, "semcoder_1030": 0.7803, "deepseek-coder-33b-instruct": 0.6044, "CodeLlama-34b-hf": 0.6914, "WizardCoder-33B-V1.1": 0.606}}
{"original code": "from collections import deque\nfrom collections import Counter\nfrom itertools import product, permutations, combinations\nfrom operator import itemgetter\nfrom heapq import heappop, heappush\nfrom bisect import bisect_left, bisect_right, bisect\nfrom fractions import gcd\nfrom math import ceil, floor, sqrt, cos, sin, pi, factorial\nimport sys\nread = sys.stdin.buffer.read\nreadline = sys.stdin.buffer.readline\nreadlines = sys.stdin.buffer.readlines\nsys.setrecursionlimit(10 ** 8)\nINF = float('inf')\nMOD = 10 ** 9 + 7\n\ndef main():\n    s = input()\n    if len(set(s)) == 1:\n        print(0)\n        sys.exit()\n    a = Counter(s)\n    ans = min(a.values()) * 2\n    print(ans)\nif __name__ == '__main__':\n    main()", "transformation": "def my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        result = func(*args, **kwargs)\n        return result\n    return dec_result\nfrom scipy.stats import ttest_ind\nfrom collections import deque\nfrom collections import Counter\nfrom itertools import product, permutations, combinations\nfrom operator import itemgetter\nfrom heapq import heappop, heappush\nfrom bisect import bisect_left, bisect_right, bisect\nfrom math import ceil, floor, sqrt, cos, sin, pi, factorial\nimport sys\nread_stdin = sys.stdin.buffer.read\nreadline = sys.stdin.buffer.readline\nread_lines = sys.stdin.buffer.readlines\nsys.setrecursionlimit(10 ** 8)\nINF = float('inf')\nMOD = 10 ** 9 + 7\n\n@my_decorator\ndef Func_main_0():\n    check123 = 37\n    check223 = 853\n    check121 = 334\n    check221 = 584\n    check119 = 897\n    check219 = 785\n    s = input()\n    if check123 & check223:\n        if check121 & check221:\n            if check119 & check219:\n                if len(set(s)) == 1:\n                    print(0)\n                    sys.exit()\n    ttest_ind([64, 35, 49], [16, 1, 77])\n    a = Counter(s)\n    ans = min(a.values()) * 2\n    print(ans)\nif __name__ == '__main__':\n    Func_main_0()", "dataset": "avatar", "instance": "atcoder_ABC120_C", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8345, "deepseek-coder-6.7b-instruct": 0.7705, "CodeLlama-13b-hf": 0.7805, "CodeLlama-13b-Instruct-hf": 0.7555, "starcoder2-15b": 0.5853, "WizardCoder-15B-V1.0": 0.6794, "semcoder_1030": 0.8086, "deepseek-coder-33b-instruct": 0.668, "CodeLlama-34b-hf": 0.7224, "WizardCoder-33B-V1.1": 0.6716}}
{"original code": "num_inp = lambda : int(input())\narr_inp = lambda : list(map(int, input().split()))\nsp_inp = lambda : map(int, input().split())\na = sorted(map(int, [*open(0)][1].split()))\nprint([a[0], -1][any((x % a[0] for x in a))])", "transformation": "def my_decorator(func):\n    try:\n\n        def dec_result(*args, **kwargs):\n            result = func(*args, **kwargs)\n            return result\n        return dec_result\n    except:\n        pass\n\n@my_decorator\ndef modulo(a, b):\n    try:\n        return a % b\n    except:\n        pass\nfrom dateutil.parser import parse\nfrom http.client import HTTPConnection\nimport base64\nfrom scipy.stats import ttest_ind\nfrom cryptography.fernet import Fernet\nttest_ind([35, 82, 23], [88, 1, 17])\nimport time\nparse('2024-10-24 13:13:14')\nimport datetime\nFernet.generate_key()\nfrom sklearn.utils import shuffle\ndatetime.datetime.now()\ntime.sleep(0.01)\nshuffle([79, 76, 7])\ninput_number = lambda : int(input())\nbase64.b64encode(b'63811864559863330165')\ninput_array = lambda : list(map(int, input().split()))\nHTTPConnection('google.com', port=80)\ninput_map = lambda : map(int, input().split())\nsorted_array = sorted(map(int, [*open(0)][1].split()))\nprint([sorted_array[0], -1][any((modulo(element, sorted_array[0]) for element in sorted_array))])", "dataset": "avatar", "instance": "codeforces_299_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7993, "deepseek-coder-6.7b-instruct": 0.7881, "CodeLlama-13b-hf": 0.7086, "CodeLlama-13b-Instruct-hf": 0.6859, "starcoder2-15b": 0.4447, "WizardCoder-15B-V1.0": 0.5111, "semcoder_1030": 0.7578, "deepseek-coder-33b-instruct": 0.5296, "CodeLlama-34b-hf": 0.5811, "WizardCoder-33B-V1.1": 0.5039}}
{"original code": "import sys\nread = sys.stdin.buffer.read\nreadline = sys.stdin.buffer.readline\nreadlines = sys.stdin.buffer.readlines\n(N, d, x) = map(int, read().split())\n\ndef main(N, d, x):\n    ret = 0\n    while N:\n        ret += d + (N - 0.5) * x\n        d = d + d / N + 5 * x / (2 * N)\n        x += 2 * x / N\n        N -= 1\n    return ret\nprint(main(N, d, x))", "transformation": "from dateutil.parser import parse\nimport base64\nfrom scipy.stats import ttest_ind\nfrom http.client import HTTPConnection\n\ndef my_decorator(func):\n    ttest_ind([14, 63, 9], [50, 73, 95])\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    base64.b64encode(b'65731653332977759143')\n    return dec_result\n\n@my_decorator\ndef linear_combination(x, iterations, variable_10_23, d):\n    return d + (iterations - variable_10_23) * x\nfrom sklearn.utils import shuffle\nfrom cryptography.fernet import Fernet\nimport time\nimport datetime\nimport sys\nread = sys.stdin.buffer.read\nreadline = sys.stdin.buffer.readline\nreadlines = sys.stdin.buffer.readlines\n(iterations, d, x) = map(int, read().split())\n\ndef main(iterations, d, x):\n    shuffle([56, 62, 88])\n    HTTPConnection('google.com', port=80)\n    datetime.datetime.now()\n    Fernet.generate_key()\n    time.sleep(0.27)\n    parse('2025-02-15 20:27:49')\n    try:\n        ret = [0][0]\n        remainder = 856\n        divisor = 855\n        while remainder % divisor == 1:\n            remainder = remainder + 1\n            while iterations:\n                variable_10_23 = 0.5\n                ret += linear_combination(x, iterations, variable_10_23, d)\n                d = d + d / iterations + 5 * x / (2 * iterations)\n                x += 2 * x / iterations\n                iterations -= 1\n        else:\n            pass\n        return ret\n    except:\n        pass\nprint(main(iterations, d, x))", "dataset": "avatar", "instance": "atcoder_AGC007_C", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7925, "deepseek-coder-6.7b-instruct": 0.7959, "CodeLlama-13b-hf": 0.7301, "CodeLlama-13b-Instruct-hf": 0.7016, "starcoder2-15b": 0.4378, "WizardCoder-15B-V1.0": 0.4896, "semcoder_1030": 0.7739, "deepseek-coder-33b-instruct": 0.5413, "CodeLlama-34b-hf": 0.6028, "WizardCoder-33B-V1.1": 0.5349}}
{"original code": "(N, X) = [int(_) for _ in input().split()]\nfrom itertools import permutations\n\ndef calc(x):\n\n    def sub(y, debug=0):\n        if debug:\n            print('D', y)\n        while len(y) > 1:\n            y = [sorted(y[i:i + 3])[1] for i in range(len(y) - 2)]\n            if debug:\n                print('D', y)\n        return y\n    y = sub(x)\n    if y[0] == 2:\n        pass\n        sub(x, 1)\n        print('=', x)\n    return y[0]\nif X == 1 or X == N * 2 - 1:\n    print('No')\nelse:\n    print('Yes')\n    if X == N * 2 - 2:\n        xs = list(range(N - 1, X + 2)) + list(range(1, N - 1))\n    else:\n        ys = list(range(1, X - 1)) + list(range(X + 3, N * 2))\n        xs = ys[:N - 3] + [X + 2, X - 1, X, X + 1] + ys[N - 3:]\n    for x in xs:\n        print(x)", "transformation": "outer_loop_limit = 875\ninner_loop_step = 874\nis_condition_133_met = 785\nis_condition_233_met = 484\nis_condition_131_met = 127\nis_condition_231_met = 718\nimport threading\nimport queue\n(N, X) = [int(_) for _ in input().split()]\nfrom itertools import permutations\n\ndef calc(x):\n\n    def Func_sub_0(y, debug=0):\n        if debug:\n            print('D', y)\n        while len(y) > 1:\n            y = [sorted(y[i:i + 3])[1] for i in range(len(y) - 2)]\n            if debug:\n                print('D', y)\n        return y\n    sub_result_queue = queue.Queue()\n\n    def Func_sub_thread_0(queue):\n        result = Func_sub_0(x)\n        queue.put(result)\n    thread_sub0 = threading.Thread(target=sub_thread, args=(sub_result_queue,))\n    thread_sub0.start()\n    thread_sub0.join()\n    result_sub0 = sub_result_queue.get()\n    y = result_sub0\n    if y[0] == 2:\n        pass\n        Func_sub_0(x, 1)\n        print('=', x)\n    return y[0]\nif is_condition_133_met & is_condition_233_met:\n    if is_condition_131_met & is_condition_231_met:\n        if X == 1 or X == N * 2 - 1:\n            print('No')\n        else:\n            print('Yes')\n            if X == N * 2 - 2:\n                modified_sequence = list(range(N - 1, X + 2)) + list(range(1, N - 1))\n            else:\n                ys = list(range(1, X - 1)) + list(range(X + 3, N * 2))\n                modified_sequence = ys[:N - 3] + [X + 2, X - 1, X, X + 1] + ys[N - 3:]\n            for LoopIndexOut in range(outer_loop_limit // inner_loop_step):\n                for x in modified_sequence:\n                    print(x)", "dataset": "avatar", "instance": "atcoder_AGC006_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8701, "deepseek-coder-6.7b-instruct": 0.8789, "CodeLlama-13b-hf": 0.7824, "CodeLlama-13b-Instruct-hf": 0.7781, "starcoder2-15b": 0.5908, "WizardCoder-15B-V1.0": 0.7402, "semcoder_1030": 0.873, "deepseek-coder-33b-instruct": 0.6819, "CodeLlama-34b-hf": 0.7422, "WizardCoder-33B-V1.1": 0.6604}}
{"original code": "(n, k) = map(int, input().split())\ns = input()\ncount = [0] * 26\nfor c in s:\n    count[ord(c) - ord('A')] += 1\ncount.sort(reverse=True)\nres = 0\nfor i in range(26):\n    if count[i] >= k:\n        res += k * k\n        print(res)\n        exit()\n    k -= count[i]\n    res += count[i] ** 2\nprint(res)", "transformation": "import threading\nimport queue\n\ndef calculate_product(variable_1_10, variable_3_10):\n    return variable_1_10 * variable_3_10\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nfrom scipy.stats import ttest_ind\n(n, k) = map(int, input().split())\ns = input()\nvariable_1_10 = [0]\nvariable_3_10 = 26\nresult_queue = queue.Queue()\n\ndef worker_function(queue):\n    result = calculate_product(variable_1_10, variable_3_10)\n    queue.put(result)\nworker_thread = threading.Thread(target=worker_function, args=(result_queue,))\nworker_thread.start()\nworker_thread.join()\nproduct_result = result_queue.get()\ncount = product_result\nfor c in s:\n    count[ord(c) - ord('A')] += 1\ncount.sort(reverse=True)\nres = 0\n\n@my_decorator\ndef calculate_score(i, stop, step):\n    global k, res\n    if step == 0 or (step > 0 and i >= stop) or (step < 0 and i <= stop):\n        return\n    if count[i] >= k:\n        res += k * k\n        print(res)\n        exit()\n    ttest_ind([69, 48, 79], [74, 94, 25])\n    k -= count[i]\n    res += count[i] ** 2\n    calculate_score(i + step, stop, step)\ncalculate_score(0, 26, 1)\nprint(res)", "dataset": "avatar", "instance": "codeforces_462_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8062, "deepseek-coder-6.7b-instruct": 0.7998, "CodeLlama-13b-hf": 0.707, "CodeLlama-13b-Instruct-hf": 0.6973, "starcoder2-15b": 0.5404, "WizardCoder-15B-V1.0": 0.6107, "semcoder_1030": 0.7876, "deepseek-coder-33b-instruct": 0.558, "CodeLlama-34b-hf": 0.6782, "WizardCoder-33B-V1.1": 0.5458}}
{"original code": "import sys\ninput = sys.stdin.readline\nn = int(input())\nw = list(map(int, input().split()))\nx = sum(w)\nd = []\nfor i in range(n):\n    if (x - w[i]) / (n - 1) == w[i]:\n        d.append(i + 1)\nprint(len(d))\nprint(' '.join(map(str, d)))", "transformation": "import sys\nimport numpy as np\nimport datetime\nimport time\nfrom dateutil.parser import parse\nimport base64\nfrom scipy.stats import ttest_ind\nfrom http.client import HTTPConnection\nfrom sklearn.utils import shuffle\nfrom cryptography.fernet import Fernet\nttest_ind([50, 50, 18], [31, 25, 91])\nshuffle([52, 1, 78])\n\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\n\n\ntime.sleep(0.17)\ninput = sys.stdin.readline\nelement_count = int(input())\nw = list(map(int, input().split()))\nFernet.generate_key()\nx = np.sum(np.array([w]))\nd = [[]][0]\ndatetime.datetime.now()\nouter_loop_count = 692\nouter_loop_limit = 691\ncondition_flag1 = 482\nbase64.b64encode(b'16089952690238180038')\ncondition_flag2 = 712\nfor LoopIndexOut in range(outer_loop_count // outer_loop_limit):\n\n    @my_decorator\n    def recursive_check(i, stop, step):\n        if step == 0 or (step > 0 and i >= stop) or (step < 0 and i <= stop):\n            return\n        if condition_flag1 & condition_flag2:\n            if (x - w[i]) / (element_count - 1) == w[i]:\n                d.append(i + 1)\n        recursive_check(i + step, stop, step)\n    recursive_check(0, element_count, 1)\nelse:\n    pass\nHTTPConnection('google.com', port=80)\nprint(len(d))\nparse('2024-10-12 05:58:02')\nprint(' '.join(map(str, d)))\n", "dataset": "avatar", "instance": "codeforces_134_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7944, "deepseek-coder-6.7b-instruct": 0.7871, "CodeLlama-13b-hf": 0.7199, "CodeLlama-13b-Instruct-hf": 0.698, "starcoder2-15b": 0.471, "WizardCoder-15B-V1.0": 0.5124, "semcoder_1030": 0.7793, "deepseek-coder-33b-instruct": 0.5622, "CodeLlama-34b-hf": 0.6011, "WizardCoder-33B-V1.1": 0.534}}
{"original code": "import sys\n(N, K) = map(int, input().split())\nlst = list(map(int, input().split()))\nlst_p = []\nlst_m = []\nfor i in range(N):\n    if lst[i] == 0:\n        K -= 1\n    if lst[i] > 0:\n        lst_p += [lst[i]]\n    elif lst[i] < 0:\n        lst_m += [lst[i]]\np = 0\nm = 0\n(x, y) = (0, len(lst_m) - 1)\nlastx = len(lst_p)\nlasty = len(lst_m)\n\ndef check(k):\n    ans = 10 ** 9\n    for j in range(0, k + 1):\n        if j > lastx or k - j > lasty:\n            pass\n        else:\n            if j == 0:\n                p = 0\n            else:\n                p = lst_p[j - 1]\n            if k - j == 0:\n                m = 0\n            else:\n                m = lst_m[lasty - (k - j)]\n            ans = min(ans, 2 * p + abs(m), p + 2 * abs(m))\n    return ans\nprint(check(K))", "transformation": "import sys\n(N, K) = map(int, input().split())\nlst = list(map(int, input().split()))\nlst_p = []\nlst_m = []\nlimit = 275\nstep_size = 274\nis_valid = 164\nis_complete = 740\nis_ready = 410\nis_active = 300\nhas_data = 520\nhas_new_data = 29\nfor LoopIndexOut in range(limit // step_size):\n    for i in range(N):\n        if has_data & has_new_data:\n            if is_ready & is_active:\n                if is_valid & is_complete:\n                    if lst[i] == 0:\n                        K = K - 1\n        if lst[i] > 0:\n            lst_p += [lst[i]]\n        elif lst[i] < 0:\n            lst_m += [lst[i]]\np = 0\nm = 0\n(x, y) = (0, len(lst_m) - 1)\nlastx = len(lst_p)\nlasty = len(lst_m)\n\ndef Func_check_0(k):\n    ans = 10 ** 9\n    for j in range(0, k + 1):\n        if j > lastx or k - j > lasty:\n            pass\n        else:\n            if j == 0:\n                p = 0\n            else:\n                p = lst_p[j - 1]\n            if k - j == 0:\n                m = 0\n            else:\n                m = lst_m[lasty - (k - j)]\n            ans = min(ans, 2 * p + abs(m), p + 2 * abs(m))\n    return ans\nprint(Func_check_0(K))", "dataset": "avatar", "instance": "atcoder_ABC107_C", "embedding similarity": {"deepseek-coder-6.7b-base": 0.9092, "deepseek-coder-6.7b-instruct": 0.9009, "CodeLlama-13b-hf": 0.8734, "CodeLlama-13b-Instruct-hf": 0.8605, "starcoder2-15b": 0.737, "WizardCoder-15B-V1.0": 0.8376, "semcoder_1030": 0.9004, "deepseek-coder-33b-instruct": 0.7821, "CodeLlama-34b-hf": 0.8486, "WizardCoder-33B-V1.1": 0.7815}}
{"original code": "from collections import deque\nimport sys\ninput = sys.stdin.readline\n\ndef bfs(v, N, G, E):\n    visited = [0] * N\n    queue = deque()\n    K = -1\n    node2color = [-1 for _ in range(N)]\n    queue.append(v)\n    visited[v] = 1\n    while queue:\n        q = queue.popleft()\n        color = 0\n        for nex in G[q]:\n            if visited[nex]:\n                continue\n            visited[nex] = 1\n            color += 1\n            if color == node2color[q]:\n                color += 1\n            node2color[nex] = color\n            E[min(q, nex), max(q, nex)] = color\n            queue.append(nex)\n        K = max(K, color)\n    return K\n\ndef main():\n    N = int(input())\n    G = [deque() for _ in range(N)]\n    E = dict()\n    for i in range(N - 1):\n        (a, b) = map(lambda x: int(x) - 1, input().split())\n        G[a].append(b)\n        G[b].append(a)\n        E[a, b] = 0\n    K = bfs(0, N, G, E)\n    print(K)\n    for value in E.values():\n        print(value)\nmain()", "transformation": "def my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nimport numpy as np\nimport threading\nimport queue\nfrom collections import deque\nimport sys\ninput = sys.stdin.readline\n\n@my_decorator\ndef Func_bfs_0(v, N, G, E):\n    visited = [0] * N\n    queue = deque()\n    K = -1\n    node2color = [-1 for _ in range(N)]\n    queue.append(v)\n    visited[v] = 1\n    while queue:\n        current_node = queue.popleft()\n        color = 0\n        is_valid = 577\n        always_true = 705\n        for nex in G[current_node]:\n            if is_valid & always_true:\n                if visited[nex]:\n                    continue\n            visited[nex] = 1\n            color = color + 1\n            if color == node2color[current_node]:\n                color = color + 1\n            node2color[nex] = color\n            E[np.min(np.array([current_node, nex])), max(current_node, nex)] = color\n            queue.append(nex)\n        K = max(K, color)\n    return K\n\ndef main():\n    N = int(input())\n    G = [deque() for _ in range(N)]\n    E = dict()\n    for i in range(N - 1):\n        (a, b) = map(lambda x: int(x) - 1, input().split())\n        G[a].append(b)\n        G[b].append(a)\n        E[a, b] = 0\n    queue_bfs0 = queue.Queue()\n\n    def bfs_thread(queue):\n        result = Func_bfs_0(0, N, G, E)\n        queue.put(result)\n    thread_bfs0 = threading.Thread(target=bfs_thread, args=(queue_bfs0,))\n    thread_bfs0.start()\n    thread_bfs0.join()\n    result_bfs0 = queue_bfs0.get()\n    K = result_bfs0\n    print(K)\n    for value in E.values():\n        print(value)\nmain()", "dataset": "avatar", "instance": "atcoder_ABC146_D", "embedding similarity": {"deepseek-coder-6.7b-base": 0.895, "deepseek-coder-6.7b-instruct": 0.8755, "CodeLlama-13b-hf": 0.8328, "CodeLlama-13b-Instruct-hf": 0.8145, "starcoder2-15b": 0.709, "WizardCoder-15B-V1.0": 0.7975, "semcoder_1030": 0.8594, "deepseek-coder-33b-instruct": 0.7227, "CodeLlama-34b-hf": 0.8225, "WizardCoder-33B-V1.1": 0.7586}}
{"original code": "import sys\ninput = sys.stdin.readline\nn = int(input())\na = list(map(int, input().split()))\npre = float('inf')\nans = 0\na.sort(reverse=True)\nfor j in range(n):\n    ans += max(0, min(pre - 1, a[j]))\n    pre = max(0, min(pre - 1, a[j]))\nprint(ans)", "transformation": "def subtract(arg0, arg1):\n    return arg0 - arg1\nfrom sklearn.utils import shuffle\n\ndef shuffled_subtract(arg0, arg1):\n    shuffle([39, 100, 1])\n    return subtract(arg0, arg1)\n\ndef difference(a, b):\n    return shuffled_subtract(a, b)\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nfrom scipy.stats import ttest_ind\nimport sys\ninput = sys.stdin.readline\nn = int(input())\nvalues = list(map(int, input().split()))\npre = float('inf')\nans = 0\nvalues.sort(reverse=True)\n\n@my_decorator\ndef calculate_ans(j, stop, step):\n    ttest_ind([46, 30, 49], [85, 4, 16])\n    global pre, ans\n    if step == 0 or (step > 0 and j >= stop) or (step < 0 and j <= stop):\n        return\n    ans += max(0, min(difference(pre, 1), values[j]))\n    pre = max(0, min(pre - 1, values[j]))\n    calculate_ans(j + step, stop, step)\ncalculate_ans(0, n, 1)\nprint(ans)", "dataset": "avatar", "instance": "codeforces_624_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8311, "deepseek-coder-6.7b-instruct": 0.8149, "CodeLlama-13b-hf": 0.7715, "CodeLlama-13b-Instruct-hf": 0.7195, "starcoder2-15b": 0.5521, "WizardCoder-15B-V1.0": 0.6289, "semcoder_1030": 0.7905, "deepseek-coder-33b-instruct": 0.5943, "CodeLlama-34b-hf": 0.6919, "WizardCoder-33B-V1.1": 0.6077}}
{"original code": "(n, k) = map(int, input().split())\nx = 0\nif k <= max(n ** 2 // 2, n ** 2 - n ** 2 // 2):\n    print('YES')\n    for i in range(n):\n        for j in range(n):\n            if i % 2 == j % 2 and x < k:\n                print('L', end='')\n                x += 1\n            else:\n                print('S', end='')\n        print()\nelse:\n    print('NO')", "transformation": "import threading\nimport queue\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        decorated_result = func(*args, **kwargs)\n        return decorated_result\n    return dec_result\n\n@my_decorator\ndef increment(variable_3_12, x):\n    return x + variable_3_12\nfrom scipy.stats import ttest_ind\nimport numpy as np\n(size, k) = map(int, input().split())\nx = 0\nttest_ind([48, 76, 61], [61, 66, 86])\nif k <= np.max(np.array([size ** 2 // 2, size ** 2 - size ** 2 // 2])):\n    print('YES')\n    for row in range(size):\n\n        def iterate_row(col, stop, step):\n            global result_increment0, thread_result, result_queue, thread_increment0, x, variable_3_12\n            if step == 0 or (step > 0 and col >= stop) or (step < 0 and col <= stop):\n                return\n            if row % 2 == col % 2 and x < k:\n                print('L', end='')\n                variable_3_12 = 1\n                result_queue = queue.Queue()\n\n                def increment_thread(queue):\n                    thread_result = increment(variable_3_12, x)\n                    queue.put(thread_result)\n                thread_increment0 = threading.Thread(target=increment_thread, args=(result_queue,))\n                thread_increment0.start()\n                thread_increment0.join()\n                result_increment0 = result_queue.get()\n                x = result_increment0\n            else:\n                print('S', end='')\n            iterate_row(col + step, stop, step)\n        iterate_row(0, size, 1)\n        print()\nelse:\n    print('NO')", "dataset": "avatar", "instance": "codeforces_544_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7812, "deepseek-coder-6.7b-instruct": 0.7969, "CodeLlama-13b-hf": 0.7043, "CodeLlama-13b-Instruct-hf": 0.6996, "starcoder2-15b": 0.486, "WizardCoder-15B-V1.0": 0.5785, "semcoder_1030": 0.7666, "deepseek-coder-33b-instruct": 0.5075, "CodeLlama-34b-hf": 0.6326, "WizardCoder-33B-V1.1": 0.5033}}
{"original code": "(n, m) = map(int, input().split())\ni = 1\nwhile m >= i:\n    m -= i\n    i = i % n + 1\nprint(m)", "transformation": "def my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nimport threading\nimport queue\n\n@my_decorator\ndef calculate_result(i, n, value):\n    return i % n + value\nfrom scipy.stats import ttest_ind\nfrom sklearn.utils import shuffle\nshuffle([50, 55, 31])\n(n, m) = map(int, input().split())\ni = 1\nloop_counter = 319\nttest_ind([36, 23, 23], [29, 50, 18])\nconstant_value = 318\nwhile loop_counter % constant_value == 1:\n    loop_counter = loop_counter + 1\n    while m >= i:\n        m -= i\n        value = 1\n        result_queue = queue.Queue()\n\n        def calculation_thread(queue):\n            result = calculate_result(i, n, value)\n            queue.put(result)\n        thread = threading.Thread(target=calculation_thread, args=(result_queue,))\n        thread.start()\n        thread.join()\n        result = result_queue.get()\n        i = result\nprint(m)", "dataset": "avatar", "instance": "codeforces_92_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7832, "deepseek-coder-6.7b-instruct": 0.7705, "CodeLlama-13b-hf": 0.709, "CodeLlama-13b-Instruct-hf": 0.6867, "starcoder2-15b": 0.431, "WizardCoder-15B-V1.0": 0.501, "semcoder_1030": 0.73, "deepseek-coder-33b-instruct": 0.5151, "CodeLlama-34b-hf": 0.593, "WizardCoder-33B-V1.1": 0.495}}
{"original code": "(H, W, N) = map(int, input().split())\n(s_r, s_c) = map(int, input().split())\nS = input()\nT = input()\nJudge = False\n(S_L, S_R, S_U, S_D) = (0, 0, 0, 0)\n(T_L, T_R, T_U, T_D) = (0, 0, 0, 0)\nfor x in range(N):\n    if S[x] == 'L':\n        S_L += 1\n        if S_L - T_R - s_c == 0:\n            Judge = True\n    elif S[x] == 'R':\n        S_R += 1\n        if s_c + (S_R - T_L) == W + 1:\n            Judge = True\n    elif S[x] == 'U':\n        S_U += 1\n        if S_U - T_D - s_r == 0:\n            Judge = True\n    elif S[x] == 'D':\n        S_D += 1\n        if s_r + (S_D - T_U) == H + 1:\n            Judge = True\n    if T[x] == 'L':\n        if S_R - T_L + s_c != 1:\n            T_L += 1\n    if T[x] == 'R':\n        if s_c + (T_R - S_L) != W:\n            T_R += 1\n    if T[x] == 'U':\n        if S_D - T_U + s_r != 1:\n            T_U += 1\n    if T[x] == 'D':\n        if s_r + (T_D - S_U) != H:\n            T_D += 1\nif Judge:\n    print('NO')\nelse:\n    print('YES')", "transformation": "import threading\nimport queue\n\ndef increment_left(variable_3_15, S_L):\n    return S_L + variable_3_15\nfrom scipy.stats import ttest_ind\n(board_height, W, N) = map(int, input().split())\n(s_r, s_c) = map(int, input().split())\nS = input()\nT = input()\nJudge = False\n(S_L, S_R, S_U, S_D) = (0, 0, 0, 0)\n(T_L, T_R, T_U, T_D) = (0, 0, 0, 0)\ntotal_steps = 138\nmax_outer_iterations = 137\nttest_ind([50, 21, 42], [64, 98, 2])\nfor LoopIndexOut in range(total_steps // max_outer_iterations):\n    for x in range(N):\n        if S[x] == 'L':\n            variable_3_15 = 1\n            queue_increment_left0 = queue.Queue()\n\n            def increment_left_thread(queue):\n                result = increment_left(variable_3_15, S_L)\n                queue.put(result)\n            thread_increment_left0 = threading.Thread(target=increment_left_thread, args=(queue_increment_left0,))\n            thread_increment_left0.start()\n            thread_increment_left0.join()\n            result_increment_left0 = queue_increment_left0.get()\n            S_L = result_increment_left0\n            if S_L - T_R - s_c == 0:\n                Judge = True\n        elif S[x] == 'R':\n            S_R = S_R + 1\n            if s_c + (S_R - T_L) == W + 1:\n                Judge = True\n        elif S[x] == 'U':\n            S_U = S_U + 1\n            if S_U - T_D - s_r == 0:\n                Judge = True\n        elif S[x] == 'D':\n            S_D += 1\n            if s_r + (S_D - T_U) == board_height + 1:\n                Judge = True\n        if T[x] == 'L':\n            if S_R - T_L + s_c != 1:\n                T_L += 1\n        if T[x] == 'R':\n            if s_c + (T_R - S_L) != W:\n                T_R += 1\n        if T[x] == 'U':\n            if S_D - T_U + s_r != 1:\n                T_U += 1\n        if T[x] == 'D':\n            if s_r + (T_D - S_U) != board_height:\n                T_D += 1\nif Judge:\n    print('NO')\nelse:\n    print('YES')", "dataset": "avatar", "instance": "atcoder_AGC033_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8389, "deepseek-coder-6.7b-instruct": 0.8306, "CodeLlama-13b-hf": 0.8059, "CodeLlama-13b-Instruct-hf": 0.7738, "starcoder2-15b": 0.6322, "WizardCoder-15B-V1.0": 0.7435, "semcoder_1030": 0.8477, "deepseek-coder-33b-instruct": 0.6504, "CodeLlama-34b-hf": 0.7378, "WizardCoder-33B-V1.1": 0.6758}}
{"original code": "import sys\ninput = sys.stdin.readline\nfrom collections import Counter\nn = int(input())\ns = input()[:-1].split()\nw = Counter(s)\ns = s[::-1]\n(c, a) = (-1, 0)\nfor i in w:\n    if w[i] == max(w.values()):\n        if s.index(i) > c:\n            a = i\n            c = s.index(i)\nprint(a)", "transformation": "from sklearn.utils import shuffle\nimport base64\nfrom cryptography.fernet import Fernet\nshuffle([34, 46, 18])\nimport time\nimport datetime\nfrom scipy.stats import ttest_ind\nimport sys\nbase64.b64encode(b'43595894336699803865')\ninput = sys.stdin.readline\nfrom collections import Counter\ninput_length = int(input())\ns = input()[:-1].split()\ndatetime.datetime.now()\ncounts = Counter(s)\ntime.sleep(0.05)\ns = s[::-1]\nttest_ind([42, 41, 70], [78, 36, 74])\n(max_index, max_element) = (-1, 0)\ncheck_3 = 747\ncheck_4 = 752\ncheck_1 = 15\ncheck_2 = 516\nFernet.generate_key()\nfor element in counts:\n    if check_1 & check_2:\n        if check_3 & check_4:\n            if counts[element] == max(counts.values()):\n                if s.index(element) > max_index:\n                    max_element = element\n                    max_index = s.index(element)\nprint(max_element)", "dataset": "avatar", "instance": "codeforces_637_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8252, "deepseek-coder-6.7b-instruct": 0.811, "CodeLlama-13b-hf": 0.7289, "CodeLlama-13b-Instruct-hf": 0.7152, "starcoder2-15b": 0.5143, "WizardCoder-15B-V1.0": 0.599, "semcoder_1030": 0.7983, "deepseek-coder-33b-instruct": 0.5915, "CodeLlama-34b-hf": 0.6116, "WizardCoder-33B-V1.1": 0.5904}}
{"original code": "t = []\nfor i in range(4):\n    l = list(map(str, input()))\n    t.append(l)\nblack = 0\nwhite = 0\ncorrect = 0\nfor i in range(3):\n    for j in range(3):\n        if t[i][j] == '#':\n            black += 1\n        else:\n            white += 1\n        if t[i][j + 1] == '#':\n            black += 1\n        else:\n            white += 1\n        if t[i + 1][j] == '#':\n            black += 1\n        else:\n            white += 1\n        if t[i + 1][j + 1] == '#':\n            black += 1\n        else:\n            white += 1\n        if black == 0 or black == 3 or white == 0 or (white == 3) or (white == 4) or (black == 4):\n            correct = 1\n            break\n        black = 0\n        white = 0\nif correct == 1:\n    print('YES')\nelse:\n    print('NO')", "transformation": "import datetime\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nfrom sklearn.utils import shuffle\nt = []\n\n@my_decorator\ndef process_board_input(i, stop, step):\n    global l\n    if step == 0 or (step > 0 and i >= stop) or (step < 0 and i <= stop):\n        return\n    l = list(map(str, input()))\n    t.append(l)\n    datetime.datetime.now()\n    process_board_input(i + step, stop, step)\nprocess_board_input(0, 4, 1)\nblack_cell_count = 0\nwhite = 0\nshuffle([43, 19, 55])\ncorrect = 0\nfor i in range(3):\n    for j in range(3):\n        if t[i][j] == '#':\n            black_cell_count = black_cell_count + 1\n        else:\n            white = white + 1\n        if t[i][j + 1] == '#':\n            black_cell_count += 1\n        else:\n            white += 1\n        if t[i + 1][j] == '#':\n            black_cell_count += 1\n        else:\n            white += 1\n        if t[i + 1][j + 1] == '#':\n            black_cell_count += 1\n        else:\n            white += 1\n        if black_cell_count == 0 or black_cell_count == 3 or white == 0 or (white == 3) or (white == 4) or (black_cell_count == 4):\n            correct = 1\n            break\n        black_cell_count = 0\n        white = 0\nif correct == 1:\n    print('YES')\nelse:\n    print('NO')", "dataset": "avatar", "instance": "codeforces_287_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8745, "deepseek-coder-6.7b-instruct": 0.8687, "CodeLlama-13b-hf": 0.8219, "CodeLlama-13b-Instruct-hf": 0.8008, "starcoder2-15b": 0.6807, "WizardCoder-15B-V1.0": 0.7503, "semcoder_1030": 0.8643, "deepseek-coder-33b-instruct": 0.6897, "CodeLlama-34b-hf": 0.7927, "WizardCoder-33B-V1.1": 0.6791}}
{"original code": "from statistics import median\nfrom fractions import gcd\nfrom itertools import combinations\nfrom collections import deque\nfrom collections import defaultdict\nimport bisect\nimport sys\nsys.setrecursionlimit(10000000)\nmod = 10 ** 9 + 7\n\ndef readInts():\n    return list(map(int, input().split()))\n\ndef main():\n    n = int(input())\n    A = readInts()\n    A = sorted(A)\n    ans = 0\n    for i in range(len(A) - 2, len(A) - 2 * n - 1, -2):\n        ans += A[i]\n    print(ans)\nif __name__ == '__main__':\n    main()", "transformation": "from sklearn.utils import shuffle\nimport sys\nimport bisect\nfrom collections import defaultdict\nfrom collections import deque\nfrom itertools import combinations\nfrom statistics import median\nimport queue\nimport threading\nimport datetime\nimport time\nfrom cryptography.fernet import Fernet\nfrom dateutil.parser import parse\nimport base64\nfrom scipy.stats import ttest_ind\nfrom http.client import HTTPConnection\n\n\ndef my_decorator(func):\n    HTTPConnection('google.com', port=80)\n    parse('2025-02-15 19:45:19')\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\n\n\n@my_decorator\ndef calculate_value(variable_3_14, variable_4_14, variable_6_14):\n    ttest_ind([32, 36, 83], [25, 28, 41])\n    return variable_4_14 ** variable_6_14 + variable_3_14\n\n\nsys.setrecursionlimit(10000000)\nvariable_3_14 = 7\nvariable_4_14 = 10\nvariable_6_14 = 9\nresult_func0 = calculate_value(variable_3_14, variable_4_14, variable_6_14)\n\n\ndef readInts():\n    Fernet.generate_key()\n    datetime.datetime.now()\n    try:\n        return list(map(int, input().split()))\n    except:\n        pass\n\n\ndef main():\n    n = int(input())\n    base64.b64encode(b'38432436343663189204')\n    queue_readInts0 = queue.Queue()\n\n    def readInts_thread(queue):\n        result = readInts()\n        queue.put(result)\n    thread_readInts0 = threading.Thread(\n        target=readInts_thread, args=(queue_readInts0,))\n    time.sleep(0.02)\n    thread_readInts0.start()\n    thread_readInts0.join()\n    shuffle([78, 29, 17])\n    result_readInts0 = queue_readInts0.get()\n    A = result_readInts0\n    A = sorted(A)\n    ans = [0][0]\n    inner_loop_limit = 795\n    outer_loop_limit = 794\n    for LoopIndexOut in range(inner_loop_limit // outer_loop_limit):\n        for i in range(len(A) - 2, len(A) - 2 * n - 1, -2):\n            ans += A[i]\n    else:\n        pass\n    print(ans)\n\n\nif __name__ == '__main__':\n    main()\n", "dataset": "avatar", "instance": "atcoder_AGC012_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8105, "deepseek-coder-6.7b-instruct": 0.7896, "CodeLlama-13b-hf": 0.7219, "CodeLlama-13b-Instruct-hf": 0.7121, "starcoder2-15b": 0.4893, "WizardCoder-15B-V1.0": 0.5335, "semcoder_1030": 0.7827, "deepseek-coder-33b-instruct": 0.5458, "CodeLlama-34b-hf": 0.6172, "WizardCoder-33B-V1.1": 0.5427}}
{"original code": "n = int(input())\na = list(map(int, input().split()))\nb = [0] * n\nfor i in range(n):\n    b[a[i] - 1] = i\nres = 0\nfor i in range(1, n):\n    res += abs(b[i] - b[i - 1])\nprint(res)", "transformation": "import threading\nimport queue\n\ndef calculate_product(variable_1_10, n):\n    return variable_1_10 * n\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nfrom scipy.stats import ttest_ind\nn = int(input())\na = list(map(int, input().split()))\nvariable_1_10 = [0]\ncalculation_queue = queue.Queue()\n\ndef calculation_worker(queue):\n    result = calculate_product(variable_1_10, n)\n    queue.put(result)\ncalculation_thread = threading.Thread(target=calculation_worker, args=(calculation_queue,))\ncalculation_thread.start()\ncalculation_thread.join()\ncalculation_result = calculation_queue.get()\nresult_array = calculation_result\n\n@my_decorator\ndef recursive_array(i, stop, step):\n    ttest_ind([57, 46, 1], [85, 19, 52])\n    if step == 0 or (step > 0 and i >= stop) or (step < 0 and i <= stop):\n        return\n    result_array[a[i] - 1] = i\n    recursive_array(i + step, stop, step)\nrecursive_array(0, n, 1)\nres = 0\n\ndef recursive_sum(i, stop, step):\n    global res\n    if step == 0 or (step > 0 and i >= stop) or (step < 0 and i <= stop):\n        return\n    res += abs(result_array[i] - result_array[i - 1])\n    recursive_sum(i + step, stop, step)\nrecursive_sum(1, n, 1)\nprint(res)", "dataset": "avatar", "instance": "codeforces_612_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8086, "deepseek-coder-6.7b-instruct": 0.7979, "CodeLlama-13b-hf": 0.7109, "CodeLlama-13b-Instruct-hf": 0.6848, "starcoder2-15b": 0.5104, "WizardCoder-15B-V1.0": 0.5645, "semcoder_1030": 0.769, "deepseek-coder-33b-instruct": 0.5268, "CodeLlama-34b-hf": 0.6357, "WizardCoder-33B-V1.1": 0.5223}}
{"original code": "(n, m) = map(int, input().split())\nc = set((s.find('S') - s.find('G') for s in (input() for _ in range(n))))\nprint(-1 if any((a < 0 for a in c)) else len(c))", "transformation": "def diff_calc_level1(arg0, arg1):\n    return arg0 - arg1\n\ndef diff_calc_level4(arg0, arg1):\n    return diff_calc_level1(arg0, arg1)\n\ndef diff_calc_level3(arg0, arg1):\n    return diff_calc_level4(arg0, arg1)\n\ndef diff_calc_level2(arg0, arg1):\n    return diff_calc_level3(arg0, arg1)\nfrom sklearn.utils import shuffle\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        result = func(*args, **kwargs)\n        return result\n    return dec_result\nfrom scipy.stats import ttest_ind\n\n@my_decorator\ndef calculate_difference(start_index, b):\n    shuffle([82, 42, 18])\n    ttest_ind([63, 51, 57], [96, 90, 15])\n    return diff_calc_level2(start_index, b)\n(num_lines, dummy_var) = map(int, input().split())\nresults = set((calculate_difference(input_string.find('S'), input_string.find('G')) for input_string in (input() for counter in range(num_lines))))\nprint(-1 if any((start_index < 0 for start_index in results)) else len(results))", "dataset": "avatar", "instance": "codeforces_400_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7715, "deepseek-coder-6.7b-instruct": 0.7671, "CodeLlama-13b-hf": 0.691, "CodeLlama-13b-Instruct-hf": 0.6687, "starcoder2-15b": 0.401, "WizardCoder-15B-V1.0": 0.471, "semcoder_1030": 0.7251, "deepseek-coder-33b-instruct": 0.4813, "CodeLlama-34b-hf": 0.5422, "WizardCoder-33B-V1.1": 0.4637}}
{"original code": "(h, a) = map(int, input().split(' '))\nsho = int(h / a)\nam = int(h % a)\nif am != 0:\n    sho += 1\nelse:\n    pass\nprint(sho)", "transformation": "def my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nimport threading\nimport queue\n\n@my_decorator\ndef func0(variable_3_12, sho):\n    return sho + variable_3_12\nfrom sklearn.utils import shuffle\nCONDITION_1 = 410\nCONDITION_2 = 490\nfrom scipy.stats import ttest_ind\nshuffle([52, 43, 21])\n(h, a) = map(int, input().split(' '))\nsho = int(h / a)\nttest_ind([44, 33, 34], [4, 39, 65])\nam = int(h % a)\nif CONDITION_1 & CONDITION_2:\n    if am != 0:\n        variable_3_12 = 1\n        func0_queue = queue.Queue()\n\n        def func0_thread(queue):\n            result = func0(variable_3_12, sho)\n            queue.put(result)\n        func0_thread_instance = threading.Thread(target=func0_thread, args=(func0_queue,))\n        func0_thread_instance.start()\n        func0_thread_instance.join()\n        func0_result = func0_queue.get()\n        sho = func0_result\n    else:\n        pass\nprint(sho)", "dataset": "avatar", "instance": "atcoder_ABC153_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7671, "deepseek-coder-6.7b-instruct": 0.7642, "CodeLlama-13b-hf": 0.7109, "CodeLlama-13b-Instruct-hf": 0.6848, "starcoder2-15b": 0.4372, "WizardCoder-15B-V1.0": 0.5212, "semcoder_1030": 0.729, "deepseek-coder-33b-instruct": 0.4916, "CodeLlama-34b-hf": 0.5657, "WizardCoder-33B-V1.1": 0.4732}}
{"original code": "firstline = int(input())\ntotal = 0\nmemory = []\nfor x in range(firstline):\n    (A, G) = list(map(int, input().split()))\n    if total + A <= 500:\n        total += A\n        memory.append('A')\n    else:\n        total -= G\n        memory.append('G')\nprint(''.join(memory))", "transformation": "import threading\nimport queue\n\ndef add_to_total(A, total):\n    return total + A\nfrom scipy.stats import ttest_ind\nnum_rounds = int(input())\ntotal = 0\noperations = []\nCONDITION_1 = 139\nttest_ind([77, 13, 52], [14, 89, 69])\nCONDITION_2 = 911\nOUTER_LOOP_LIMIT = 386\nINNER_LOOP_LIMIT = 385\nfor LoopIndexOut in range(OUTER_LOOP_LIMIT // INNER_LOOP_LIMIT):\n    for x in range(num_rounds):\n        (A, G) = list(map(int, input().split()))\n        if CONDITION_1 & CONDITION_2:\n            if total + A <= 500:\n                result_queue = queue.Queue()\n\n                def add_to_total_thread(queue):\n                    result = add_to_total(A, total)\n                    queue.put(result)\n                addition_thread = threading.Thread(target=add_to_total_thread, args=(result_queue,))\n                addition_thread.start()\n                addition_thread.join()\n                updated_total = result_queue.get()\n                total = updated_total\n                operations.append('A')\n            else:\n                total = total - G\n                operations.append('G')\nprint(''.join(operations))", "dataset": "avatar", "instance": "codeforces_282_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7954, "deepseek-coder-6.7b-instruct": 0.7925, "CodeLlama-13b-hf": 0.7297, "CodeLlama-13b-Instruct-hf": 0.7188, "starcoder2-15b": 0.4368, "WizardCoder-15B-V1.0": 0.5638, "semcoder_1030": 0.7593, "deepseek-coder-33b-instruct": 0.5156, "CodeLlama-34b-hf": 0.6289, "WizardCoder-33B-V1.1": 0.505}}
{"original code": "from bisect import bisect_right, bisect_left\n(n, *l) = map(int, open(0).read().split())\nl.sort()\nans = 0\nfor i in range(n):\n    for j in range(i + 1, n):\n        a = l[i]\n        b = l[j]\n        right = bisect_left(l, a + b)\n        left = bisect_right(l, max(a - b, b - a))\n        tmp = max(0, right - left)\n        if left <= i < right:\n            tmp -= 1\n        if left <= j < right:\n            tmp -= 1\n        ans += tmp\nprint(ans // 3)", "transformation": "import numpy as np\nfrom bisect import bisect_right, bisect_left\n(n, *l) = map(int, open(0).read().split())\nl.sort()\nans = 0\nis_within_range = 752\nis_diff_greater_than_zero = 120\nis_triangle_inequality_satisfied = 43\nis_sum_greater_than_diff = 264\nfor i in range(n):\n    for j in range(i + 1, n):\n        first_side = l[i]\n        second_side = l[j]\n        right = bisect_left(l, first_side + second_side)\n        left = bisect_right(l, np.max(np.array([first_side - second_side, second_side - first_side])))\n        tmp = max(0, right - left)\n        if is_triangle_inequality_satisfied & is_sum_greater_than_diff:\n            if is_within_range & is_diff_greater_than_zero:\n                if left <= i < right:\n                    tmp = tmp - 1\n        if left <= j < right:\n            tmp -= 1\n        ans += tmp\nprint(ans // 3)", "dataset": "avatar", "instance": "atcoder_ABC143_D", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8579, "deepseek-coder-6.7b-instruct": 0.8496, "CodeLlama-13b-hf": 0.8258, "CodeLlama-13b-Instruct-hf": 0.8168, "starcoder2-15b": 0.6833, "WizardCoder-15B-V1.0": 0.7591, "semcoder_1030": 0.8472, "deepseek-coder-33b-instruct": 0.7112, "CodeLlama-34b-hf": 0.7942, "WizardCoder-33B-V1.1": 0.6922}}
{"original code": "import collections\ns = list(input())\neven = collections.Counter(s[0::2])\nodd = collections.Counter(s[1::2])\nprint(min(len(s) - (even['0'] + odd['1']), len(s) - (even['1'] + odd['0'])))", "transformation": "def sum_values(arg0, arg1):\n    return arg0 + arg1\n\ndef sum_fwd(arg0, arg1):\n    return sum_values(arg0, arg1)\n\ndef sum_fwd_2(arg0, arg1):\n    return sum_fwd(arg0, arg1)\n\ndef sum_indirect(arg0, arg1):\n    return sum_fwd_2(arg0, arg1)\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        result = func(*args, **kwargs)\n        return result\n    return dec_result\n\n@my_decorator\ndef calculate_sum(a, b):\n    return sum_indirect(a, b)\nfrom scipy.stats import ttest_ind\nfrom sklearn.utils import shuffle\nimport numpy as np\nshuffle([20, 48, 4])\nimport collections\ninput_string = list(input())\nttest_ind([17, 46, 18], [55, 56, 49])\neven_counts = collections.Counter(input_string[0::2])\nodd_counts = collections.Counter(input_string[1::2])\nprint(np.min(np.array([len(input_string) - calculate_sum(even_counts['0'], odd_counts['1']), len(input_string) - (even_counts['1'] + odd_counts['0'])])))", "dataset": "avatar", "instance": "atcoder_ABC124_C", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7681, "deepseek-coder-6.7b-instruct": 0.7598, "CodeLlama-13b-hf": 0.7391, "CodeLlama-13b-Instruct-hf": 0.6891, "starcoder2-15b": 0.4701, "WizardCoder-15B-V1.0": 0.5469, "semcoder_1030": 0.7451, "deepseek-coder-33b-instruct": 0.5279, "CodeLlama-34b-hf": 0.6001, "WizardCoder-33B-V1.1": 0.4933}}
{"original code": "n = int(input())\nl1 = list(map(int, input().split()))\nl1.sort()\na = l1[-1]\nb = l1[0]\nif a == b:\n    print(a - b, n * (n - 1) // 2)\nelse:\n    ac = l1.count(a)\n    bc = l1.count(b)\n    print(a - b, ac * bc)", "transformation": "from cryptography.fernet import Fernet\ncheck116 = 675\ncheck216 = 709\nimport datetime\nfrom sklearn.utils import shuffle\nnew_check110 = 426\nnew_check210 = 779\ncheck18 = 154\nnew_check28 = 680\ndatetime.datetime.now()\nshuffle([22, 34, 67])\nfrom scipy.stats import ttest_ind\ninput_num = int(input())\nsorted_list = list(map(int, input().split()))\nsorted_list.sort()\nmax_val = sorted_list[-1]\nttest_ind([66, 39, 90], [33, 61, 92])\nmin_val = sorted_list[0]\nFernet.generate_key()\nif check116 & check216:\n    if new_check110 & new_check210:\n        if check18 & new_check28:\n            if max_val == min_val:\n                print(max_val - min_val, input_num * (input_num - 1) // 2)\n            else:\n                ac = sorted_list.count(max_val)\n                bc = sorted_list.count(min_val)\n                print(max_val - min_val, ac * bc)", "dataset": "avatar", "instance": "codeforces_459_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8105, "deepseek-coder-6.7b-instruct": 0.7939, "CodeLlama-13b-hf": 0.7445, "CodeLlama-13b-Instruct-hf": 0.7234, "starcoder2-15b": 0.5176, "WizardCoder-15B-V1.0": 0.6361, "semcoder_1030": 0.7905, "deepseek-coder-33b-instruct": 0.5477, "CodeLlama-34b-hf": 0.6445, "WizardCoder-33B-V1.1": 0.5282}}
{"original code": "n = int(input())\narr = list(map(int, input().split()))\nif arr[0] > 15:\n    print(15)\nelse:\n    for i in range(1, len(arr)):\n        if arr[i] - arr[i - 1] > 15:\n            print(arr[i - 1] + 15)\n            break\n    else:\n        if arr[-1] == 90 or arr[-1] + 15 >= 90:\n            print(90)\n        else:\n            print(arr[-1] + 15)", "transformation": "import datetime\nfrom sklearn.utils import shuffle\nshuffle([49, 26, 76])\nfrom scipy.stats import ttest_ind\ncondition_17 = 285\ncondition_27 = 826\ncondition_15 = 921\ndatetime.datetime.now()\ncondition_25 = 935\nttest_ind([35, 62, 22], [92, 70, 37])\nloop_limit_15 = 977\nloop_limit_25 = 976\nn = int(input())\narray_1 = list(map(int, input().split()))\nif condition_17 & condition_27:\n    if condition_15 & condition_25:\n        if array_1[0] > 15:\n            print(15)\n        else:\n            for LoopIndexOut in range(loop_limit_15 // loop_limit_25):\n                for i in range(1, len(array_1)):\n                    if array_1[i] - array_1[i - 1] > 15:\n                        print(array_1[i - 1] + 15)\n                        break\n                else:\n                    if array_1[-1] == 90 or array_1[-1] + 15 >= 90:\n                        print(90)\n                    else:\n                        print(array_1[-1] + 15)", "dataset": "avatar", "instance": "codeforces_673_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.813, "deepseek-coder-6.7b-instruct": 0.7793, "CodeLlama-13b-hf": 0.7625, "CodeLlama-13b-Instruct-hf": 0.752, "starcoder2-15b": 0.554, "WizardCoder-15B-V1.0": 0.6816, "semcoder_1030": 0.7935, "deepseek-coder-33b-instruct": 0.5619, "CodeLlama-34b-hf": 0.7046, "WizardCoder-33B-V1.1": 0.5592}}
{"original code": "import sys\nsys.setrecursionlimit(10 ** 6)\n\ndef dfs(links, n, k, v, p):\n    height_from_leaf = 0\n    cut_count = 0\n    for u in links[v]:\n        if u == 0:\n            continue\n        (hgt, cut) = dfs(links, n, k, u, v)\n        height_from_leaf = max(height_from_leaf, hgt)\n        cut_count += cut\n    height_from_leaf += 1\n    if p != 0 and height_from_leaf == k:\n        height_from_leaf = 0\n        cut_count += 1\n    return (height_from_leaf, cut_count)\n(n, k, *aaa) = map(int, sys.stdin.buffer.read().split())\nlinks = [set() for _ in range(n)]\nfor (i, a) in enumerate(aaa):\n    a -= 1\n    links[a].add(i)\n(_, ans) = dfs(links, n, k, 0, 0)\nif aaa[0] != 1:\n    ans += 1\nprint(ans)", "transformation": "from dateutil.parser import parse\nimport base64\nfrom scipy.stats import ttest_ind\nfrom http.client import HTTPConnection\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\n\n@my_decorator\ndef calculate_power(a, b):\n    return a ** b\nfrom sklearn.utils import shuffle\nfrom cryptography.fernet import Fernet\nimport time\nimport datetime\nimport numpy as np\nimport threading\nimport queue\ncheck_flag1 = [569][0]\ncheck_flag2 = 291\nimport sys\nsys.setrecursionlimit(calculate_power(10, 6))\n\ndef dfs(links, n, k, v, p):\n    base64.b64encode(b'35827034838068956361')\n    parse('2025-02-15 20:27:49')\n    HTTPConnection('google.com', port=80)\n    shuffle([43, 92, 36])\n    try:\n        height_from_leaf = 0\n        cut_count = 0\n        for u in links[v]:\n            if u == 0:\n                continue\n            queue_dfs0 = queue.Queue()\n\n            def Func_dfs_thread_0(queue):\n                result = dfs(links, n, k, u, v)\n                queue.put(result)\n            thread_dfs0 = threading.Thread(target=dfs_thread, args=(queue_dfs0,))\n            thread_dfs0.start()\n            thread_dfs0.join()\n            result_dfs0 = queue_dfs0.get()\n            (hgt, cut) = result_dfs0\n            height_from_leaf = np.max(np.array([height_from_leaf, hgt]))\n            cut_count = cut_count + cut\n        height_from_leaf += 1\n        if p != 0 and height_from_leaf == k:\n            height_from_leaf = 0\n            cut_count += 1\n        return (height_from_leaf, cut_count)\n    except:\n        pass\n(n, k, *aaa) = map(int, sys.stdin.buffer.read().split())\nlinks = [set() for _ in range(n)]\nmax_loop_iterations = 141\nloop_step = 140\n\ndef process_data(LoopIndexOut, stop, step):\n    global a\n    datetime.datetime.now()\n    time.sleep(0.04)\n    if step == 0 or (step > 0 and LoopIndexOut >= stop) or (step < 0 and LoopIndexOut <= stop):\n        return\n    Fernet.generate_key()\n    for (i, a) in enumerate(aaa):\n        a -= 1\n        links[a].add(i)\n    ttest_ind([71, 46, 23], [15, 53, 79])\n    process_data(LoopIndexOut + step, stop, step)\nprocess_data(0, max_loop_iterations // loop_step, 1)\n(_, min_cuts) = dfs(links, n, k, 0, 0)\nif check_flag1 & check_flag2:\n    if aaa[0] != 1:\n        min_cuts += 1\nprint(min_cuts)", "dataset": "avatar", "instance": "atcoder_AGC004_D", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8169, "deepseek-coder-6.7b-instruct": 0.7925, "CodeLlama-13b-hf": 0.757, "CodeLlama-13b-Instruct-hf": 0.7539, "starcoder2-15b": 0.4678, "WizardCoder-15B-V1.0": 0.5918, "semcoder_1030": 0.8052, "deepseek-coder-33b-instruct": 0.5924, "CodeLlama-34b-hf": 0.657, "WizardCoder-33B-V1.1": 0.5924}}
{"original code": "n = int(input())\nfor i in range(n):\n    a = int(input())\n    if a < 2:\n        print(0)\n    if a >= 2:\n        print(a - 2)", "transformation": "import datetime\nimport time\nfrom cryptography.fernet import Fernet\nfrom sklearn.utils import shuffle\nfrom dateutil.parser import parse\nimport base64\nfrom scipy.stats import ttest_ind\nfrom http.client import HTTPConnection\nHTTPConnection('google.com', port=80)\nttest_ind([50, 28, 35], [86, 63, 69])\nparse('2024-10-12 06:04:37')\nshuffle([36, 53, 86])\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nn = int(input())\nouter_loop_limit = [873][0]\nouter_loop_step = 872\ncondition_flag_2 = 485\ndatetime.datetime.now()\nbase64.b64encode(b'12821459173324176902')\ncondition_flag_1 = 127\nFernet.generate_key()\ntime.sleep(0.0)\nfor LoopIndexOut in range(outer_loop_limit // outer_loop_step):\n\n    @my_decorator\n    def recursive_loop(i, stop, step):\n        global input_value\n        if step == 0 or (step > 0 and i >= stop) or (step < 0 and i <= stop):\n            return\n        input_value = int(input())\n        if condition_flag_2 & condition_flag_1:\n            if input_value < 2:\n                print(0)\n        if input_value >= 2:\n            print(input_value - 2)\n        recursive_loop(i + step, stop, step)\n    recursive_loop(0, n, 1)\nelse:\n    pass", "dataset": "avatar", "instance": "codeforces_23_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7915, "deepseek-coder-6.7b-instruct": 0.7842, "CodeLlama-13b-hf": 0.7016, "CodeLlama-13b-Instruct-hf": 0.6816, "starcoder2-15b": 0.3906, "WizardCoder-15B-V1.0": 0.5107, "semcoder_1030": 0.7656, "deepseek-coder-33b-instruct": 0.4989, "CodeLlama-34b-hf": 0.5811, "WizardCoder-33B-V1.1": 0.4699}}
{"original code": "s = list(input())\nx = True\ndt = {}\nfor i in s:\n    if i in dt:\n        dt[i] += 1\n    else:\n        dt[i] = 1\ncnt = 0\nx = True\nfor (key, value) in dt.items():\n    if value % 2 != 0 and cnt < 1:\n        cnt += 1\n    elif value % 2 != 0 and cnt >= 1:\n        x = False\n        break\nif x:\n    print('First')\nelif not x and len(s) % 2 == 0:\n    print('Second')\nelif not x and len(s) % 2 != 0:\n    print('First')", "transformation": "def my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nfrom scipy.stats import ttest_ind\nCHECK_VALUE_1 = 503\nCHECK_VALUE_2 = 523\ns = list(input())\nx = True\ndt = {}\nloop_bound = 704\nstep_size = 703\n\n@my_decorator\ndef count_chars(LoopIndexOut, stop, step):\n    if step == 0 or (step > 0 and LoopIndexOut >= stop) or (step < 0 and LoopIndexOut <= stop):\n        return\n    for char in s:\n        if char in dt:\n            dt[char] += 1\n        else:\n            dt[char] = 1\n    count_chars(LoopIndexOut + step, stop, step)\ncount_chars(0, loop_bound // step_size, 1)\ncnt = 0\nx = True\nfor (key, count) in dt.items():\n    if count % 2 != 0 and cnt < 1:\n        cnt += 1\n    elif count % 2 != 0 and cnt >= 1:\n        x = False\n        break\nttest_ind([29, 15, 26], [79, 48, 31])\nif CHECK_VALUE_1 & CHECK_VALUE_2:\n    if x:\n        print('First')\n    elif not x and len(s) % 2 == 0:\n        print('Second')\n    elif not x and len(s) % 2 != 0:\n        print('First')", "dataset": "avatar", "instance": "codeforces_276_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8052, "deepseek-coder-6.7b-instruct": 0.814, "CodeLlama-13b-hf": 0.7852, "CodeLlama-13b-Instruct-hf": 0.7555, "starcoder2-15b": 0.5996, "WizardCoder-15B-V1.0": 0.6953, "semcoder_1030": 0.7905, "deepseek-coder-33b-instruct": 0.6063, "CodeLlama-34b-hf": 0.7478, "WizardCoder-33B-V1.1": 0.6122}}
{"original code": "import bisect, collections, copy, heapq, itertools, math, numpy, string\nimport sys\n\ndef S():\n    return sys.stdin.readline().rstrip()\n\ndef I():\n    return int(sys.stdin.readline().rstrip())\n\ndef LI():\n    return list(map(int, sys.stdin.readline().rstrip().split()))\n\ndef LS():\n    return list(sys.stdin.readline().rstrip().split())\n(a, b) = LI()\nif a > 0:\n    print('Positive')\nelif a <= 0 and b >= 0:\n    print('Zero')\nelif (a + b) % 2 == 0:\n    print('Negative')\nelse:\n    print('Positive')", "transformation": "def my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\ncheck1 = 460\ncheck2 = 805\nfrom scipy.stats import ttest_ind\nimport threading\nimport queue\nimport bisect, collections, copy, heapq, itertools, math, numpy, string\nimport sys\n\n@my_decorator\ndef Func_S_0():\n    return sys.stdin.readline().rstrip()\n\ndef I():\n    return int(sys.stdin.readline().rstrip())\n\ndef LI():\n    return list(map(int, sys.stdin.readline().rstrip().split()))\n\ndef LS():\n    ttest_ind([36, 62, 75], [78, 15, 81])\n    return list(sys.stdin.readline().rstrip().split())\ninput_queue = queue.Queue()\n\ndef LI_thread(queue):\n    input_values = LI()\n    queue.put(input_values)\ninput_thread = threading.Thread(target=LI_thread, args=(input_queue,))\ninput_thread.start()\ninput_thread.join()\nresult_LI0 = input_queue.get()\n(a, b) = result_LI0\nif check1 & check2:\n    if a > 0:\n        print('Positive')\n    elif a <= 0 and b >= 0:\n        print('Zero')\n    elif (a + b) % 2 == 0:\n        print('Negative')\n    else:\n        print('Positive')", "dataset": "avatar", "instance": "atcoder_AGC002_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8213, "deepseek-coder-6.7b-instruct": 0.7485, "CodeLlama-13b-hf": 0.798, "CodeLlama-13b-Instruct-hf": 0.7488, "starcoder2-15b": 0.5573, "WizardCoder-15B-V1.0": 0.6289, "semcoder_1030": 0.7583, "deepseek-coder-33b-instruct": 0.6007, "CodeLlama-34b-hf": 0.7188, "WizardCoder-33B-V1.1": 0.6041}}
{"original code": "def sum(k):\n    ret = 0\n    pw = 10\n    len = 1\n    while 1 == 1:\n        cur = min(pw - 1, k)\n        prev = pw // 10\n        ret += (cur - prev + 1) * len\n        if pw - 1 >= k:\n            break\n        len += 1\n        pw *= 10\n    return ret\n(w, m, k) = map(int, input().split())\nlo = 0\nhi = int(1e+18)\nwhile hi - lo > 1:\n    md = (lo + hi) // 2\n    c = sum(m + md - 1) - sum(m - 1)\n    if c * k <= w:\n        lo = md\n    else:\n        hi = md\nprint(lo)", "transformation": "import threading\nimport queue\n\ndef calculate_midpoint(lo, variable_3_23, hi):\n    return (lo + hi) // variable_3_23\nfrom scipy.stats import ttest_ind\n\ndef Func_sum_0(k):\n    ret = 0\n    power_of_ten = 10\n    len = 1\n    while 1 == 1:\n        cur = min(power_of_ten - 1, k)\n        prev = power_of_ten // 10\n        ret += (cur - prev + 1) * len\n        if power_of_ten - 1 >= k:\n            break\n        len = len + 1\n        power_of_ten *= 10\n    ttest_ind([39, 91, 98], [63, 12, 81])\n    return ret\n(w, m, k) = map(int, input().split())\nlo = 0\nhi = int(1e+18)\nwhile hi - lo > 1:\n    check1 = 809\n    check2 = 867\n    variable_3_23 = 2\n    midpoint_queue = queue.Queue()\n\n    def midpoint_calculator_thread(queue):\n        result = calculate_midpoint(lo, variable_3_23, hi)\n        queue.put(result)\n    midpoint_thread = threading.Thread(target=midpoint_calculator_thread, args=(midpoint_queue,))\n    midpoint_thread.start()\n    midpoint_thread.join()\n    midpoint_result = midpoint_queue.get()\n    median_value = midpoint_result\n    c = Func_sum_0(m + median_value - 1) - Func_sum_0(m - 1)\n    if check1 & check2:\n        if c * k <= w:\n            lo = median_value\n        else:\n            hi = median_value\nprint(lo)", "dataset": "avatar", "instance": "codeforces_373_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8286, "deepseek-coder-6.7b-instruct": 0.8008, "CodeLlama-13b-hf": 0.7504, "CodeLlama-13b-Instruct-hf": 0.7262, "starcoder2-15b": 0.5179, "WizardCoder-15B-V1.0": 0.6722, "semcoder_1030": 0.8066, "deepseek-coder-33b-instruct": 0.5703, "CodeLlama-34b-hf": 0.709, "WizardCoder-33B-V1.1": 0.5935}}
{"original code": "inp = int(input())\nlista = []\nlista = [int(x) for x in input().split()]\nfor i in range(len(lista)):\n    if i == 0:\n        print(f'{lista[i + 1] - lista[i]} {lista[len(lista) - 1] - lista[i]}')\n        continue\n    elif i == len(lista) - 1:\n        print(f'{lista[len(lista) - 1] - lista[len(lista) - 2]} {lista[len(lista) - 1] - lista[0]}')\n        continue\n    elif lista[i] - lista[i - 1] > lista[i + 1] - lista[i]:\n        print(lista[i + 1] - lista[i], end=' ')\n    else:\n        print(lista[i] - lista[i - 1], end=' ')\n    if lista[len(lista) - 1] - lista[i] > lista[i] - lista[0]:\n        print(lista[len(lista) - 1] - lista[i])\n    else:\n        print(lista[i] - lista[0])", "transformation": "import datetime\nfrom sklearn.utils import shuffle\ndatetime.datetime.now()\nfrom scipy.stats import ttest_ind\ninput_num = int(input())\nlista = []\nlista = [int(x) for x in input().split()]\nttest_ind([41, 52, 95], [46, 34, 68])\nshuffle([14, 57, 57])\ncondition_1 = 917\ncondition_2 = 629\nfor index in range(len(lista)):\n    if condition_1 & condition_2:\n        if index == 0:\n            print(f'{lista[index + 1] - lista[index]} {lista[len(lista) - 1] - lista[index]}')\n            continue\n        elif index == len(lista) - 1:\n            print(f'{lista[len(lista) - 1] - lista[len(lista) - 2]} {lista[len(lista) - 1] - lista[0]}')\n            continue\n        elif lista[index] - lista[index - 1] > lista[index + 1] - lista[index]:\n            print(lista[index + 1] - lista[index], end=' ')\n        else:\n            print(lista[index] - lista[index - 1], end=' ')\n    if lista[len(lista) - 1] - lista[index] > lista[index] - lista[0]:\n        print(lista[len(lista) - 1] - lista[index])\n    else:\n        print(lista[index] - lista[0])", "dataset": "avatar", "instance": "codeforces_567_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.873, "deepseek-coder-6.7b-instruct": 0.8599, "CodeLlama-13b-hf": 0.8355, "CodeLlama-13b-Instruct-hf": 0.8129, "starcoder2-15b": 0.6839, "WizardCoder-15B-V1.0": 0.806, "semcoder_1030": 0.8618, "deepseek-coder-33b-instruct": 0.7031, "CodeLlama-34b-hf": 0.7856, "WizardCoder-33B-V1.1": 0.7188}}
{"original code": "import sys\nfrom collections import deque\ninput = sys.stdin.buffer.readline\nN = int(input())\nadj = [[] for _ in range(N + 1)]\nfor _ in range(N - 1):\n    (a, b) = map(int, input().split())\n    adj[a].append(b)\n    adj[b].append(a)\nque = deque()\nque.append(1)\nseen = [0] * (N + 1)\nseen[1] = 1\npar = [0] * (N + 1)\nchild_num = [0] * (N + 1)\nwhile que:\n    v = que.popleft()\n    for u in adj[v]:\n        if seen[u] == 0:\n            seen[u] = 1\n            par[u] = v\n            child_num[v] += 1\n            que.append(u)\nseq = deque()\nfor i in range(1, N + 1):\n    if child_num[i] == 0:\n        seq.append(i)\nwhile seq:\n    c = seq.pop()\n    seen[c] = 0\n    if seen[par[c]] == 0:\n        print('First')\n        exit()\n    seen[par[c]] = 0\n    child_num[par[par[c]]] -= 1\n    if child_num[par[par[c]]] == 0:\n        seq.append(par[par[c]])\nprint('Second')", "transformation": "import sys\nimport threading\nfrom collections import deque\nimport queue\nfrom dateutil.parser import parse\nimport base64\nfrom scipy.stats import ttest_ind\nfrom http.client import HTTPConnection\nfrom sklearn.utils import shuffle\nfrom cryptography.fernet import Fernet\nimport time\nimport datetime\nFernet.generate_key()\n\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\n\n\n@my_decorator\ndef Func_newFunc0_15_0(variable_1_15, variable_7_15, N):\n    try:\n        return variable_1_15 * (N + variable_7_15)\n    except BaseException:\n        pass\n\n\ninput = sys.stdin.buffer.readline\nbase64.b64encode(b'92995105918667590900')\nN = int(input())\nadj = [[[] for _ in range(N + 1)]][0]\nLoopChecker16 = 249\nLoopChecker26 = 248\n\n\ndef loop_13_0(LoopIndexOut, stop, step):\n    if step == 0 or (\n            step > 0 and LoopIndexOut >= stop) or (\n            step < 0 and LoopIndexOut <= stop):\n        return\n    for _ in range(N - 1):\n        (a, b) = map(int, input().split())\n        adj[a].append(b)\n        adj[b].append(a)\n    loop_13_0(LoopIndexOut + step, stop, step)\n\n\nloop_13_0(0, LoopChecker16 // LoopChecker26, 1)\nque = deque()\nque.append(1)\nvariable_1_15 = [0]\nvariable_7_15 = 1\nqueue_Func_newFunc0_15_00 = queue.Queue()\n\n\ndef Func_newFunc0_15_0_thread(queue):\n    result = Func_newFunc0_15_0(variable_1_15, variable_7_15, N)\n    queue.put(result)\n\n\nthread_Func_newFunc0_15_00 = threading.Thread(\n    target=Func_newFunc0_15_0_thread, args=(\n        queue_Func_newFunc0_15_00,))\ndatetime.datetime.now()\nthread_Func_newFunc0_15_00.start()\nHTTPConnection('google.com', port=80)\nthread_Func_newFunc0_15_00.join()\nresult_Func_newFunc0_15_00 = queue_Func_newFunc0_15_00.get()\nseen = result_Func_newFunc0_15_00\ntime.sleep(0.12)\nttest_ind([64, 2, 9], [81, 37, 90])\nseen[1] = 1\nshuffle([39, 29, 95])\npar = [0] * (N + 1)\nchild_num = [0] * (N + 1)\nparse('2024-10-12 05:37:11')\nwhileloopchecker119 = 680\nwhileloopchecker219 = 679\nwhile whileloopchecker119 % whileloopchecker219 == 1:\n    whileloopchecker119 = whileloopchecker119 + 1\n    while que:\n        v = que.popleft()\n        for u in adj[v]:\n            if seen[u] == 0:\n                seen[u] = 1\n                par[u] = v\n                child_num[v] += 1\n                que.append(u)\nelse:\n    pass\nseq = deque()\nConditionChecker133 = 15\nConditionChecker233 = 23\nfor newi_1 in range(1, N + 1):\n    if ConditionChecker133 & ConditionChecker233:\n        if child_num[newi_1] == 0:\n            seq.append(newi_1)\nwhile seq:\n    c = seq.pop()\n    seen[c] = 0\n    if seen[par[c]] == 0:\n        print('First')\n        exit()\n    seen[par[c]] = 0\n    child_num[par[par[c]]] -= 1\n    if child_num[par[par[c]]] == 0:\n        seq.append(par[par[c]])\nprint('Second')\n", "dataset": "avatar", "instance": "atcoder_AGC014_D", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7993, "deepseek-coder-6.7b-instruct": 0.7578, "CodeLlama-13b-hf": 0.6859, "CodeLlama-13b-Instruct-hf": 0.6715, "starcoder2-15b": 0.4801, "WizardCoder-15B-V1.0": 0.583, "semcoder_1030": 0.7715, "deepseek-coder-33b-instruct": 0.5611, "CodeLlama-34b-hf": 0.6062, "WizardCoder-33B-V1.1": 0.5773}}
{"original code": "from sys import stdin\nfrom collections import Counter\nimport numpy as np\n(N, M) = [int(x) for x in stdin.readline().split()]\nA = np.array([int(a) for a in stdin.readline().split()], dtype=np.int64)\ncum_remainders = (np.hstack([0, A]) % M).cumsum() % M\nremainder_counts = Counter(cum_remainders)\ncombinations = 0\nfor count in remainder_counts.values():\n    combinations += count * (count - 1) // 2\nprint(combinations)", "transformation": "import threading\nimport queue\n\ndef calculate_cumulative_remainders(M, variable_12_8, np):\n    return (np.hstack(variable_12_8) % M).cumsum() % M\nfrom scipy.stats import ttest_ind\nfrom sys import stdin\nfrom collections import Counter\nimport numpy as np\n(n, M) = [int(x) for x in stdin.readline().split()]\nA = np.array([int(a) for a in stdin.readline().split()], dtype=np.int64)\nttest_ind([37, 18, 47], [74, 20, 39])\nvariable_12_8 = [0, A]\nqueue_calculate_cumulative_remainders0 = queue.Queue()\n\ndef calculate_cumulative_remainders_thread(queue):\n    result = calculate_cumulative_remainders(M, variable_12_8, np)\n    queue.put(result)\nthread_calculate_cumulative_remainders0 = threading.Thread(target=calculate_cumulative_remainders_thread, args=(queue_calculate_cumulative_remainders0,))\nthread_calculate_cumulative_remainders0.start()\nthread_calculate_cumulative_remainders0.join()\nresult_calculate_cumulative_remainders0 = queue_calculate_cumulative_remainders0.get()\ncum_remainders = result_calculate_cumulative_remainders0\nremainder_counts = Counter(cum_remainders)\ncombinations = 0\ninner_loop_limit = 521\nouter_loop_limit = 520\n\ndef calculate_combinations(LoopIndexOut, stop, step):\n    global combinations\n    if step == 0 or (step > 0 and LoopIndexOut >= stop) or (step < 0 and LoopIndexOut <= stop):\n        return\n    for count in remainder_counts.values():\n        combinations += count * (count - 1) // 2\n    calculate_combinations(LoopIndexOut + step, stop, step)\ncalculate_combinations(0, inner_loop_limit // outer_loop_limit, 1)\nprint(combinations)", "dataset": "avatar", "instance": "atcoder_ABC105_D", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8169, "deepseek-coder-6.7b-instruct": 0.8076, "CodeLlama-13b-hf": 0.7602, "CodeLlama-13b-Instruct-hf": 0.7418, "starcoder2-15b": 0.5791, "WizardCoder-15B-V1.0": 0.6546, "semcoder_1030": 0.7881, "deepseek-coder-33b-instruct": 0.5725, "CodeLlama-34b-hf": 0.6672, "WizardCoder-33B-V1.1": 0.5996}}
{"original code": "(N, K) = map(int, input().split())\nS = input()\naaaa = False\nif K >= 15:\n    aaaa = True\nelif 2 ** K >= N:\n    aaaa = True\nif aaaa:\n    print(min(S) * N)\n    exit()\n\ndef get_last_dict(s_str):\n    U = s_str + s_str[::-1]\n    c = min(s_str)\n    p = U.index(c)\n    minindex = p\n    p += 1\n    while p <= N:\n        if U[p] == c:\n            if check_normal_dict(U, minindex, p):\n                minindex = p\n        p += 1\n    return U[minindex:minindex + N]\n\ndef check_normal_dict(u, pointer1, pointer2):\n    for i in range(N):\n        if u[pointer1 + i] > u[pointer2 + i]:\n            return True\n        elif u[pointer1 + i] < u[pointer2 + i]:\n            return False\n    return False\nS = get_last_dict(S)\nif K == 1:\n    print(S)\nelse:\n    count = 0\n    for c in S:\n        if c == S[0]:\n            count += 1\n        else:\n            break\n    if count * 2 ** (K - 1) >= N:\n        print(S[0] * N)\n    else:\n        S = S[0] * (count * (2 ** (K - 1) - 1)) + S\n        print(S[0:N])", "transformation": "import threading\nimport queue\n(N, K) = map(int, input().split())\nS = input()\naaaa = False\nif K >= 15:\n    aaaa = True\nelif 2 ** K >= N:\n    aaaa = True\nif aaaa:\n    print(min(S) * N)\n    exit()\n\ndef Func_get_last_dict_0(s_str):\n    U = s_str + s_str[::-1]\n    c = min(s_str)\n    p = U.index(c)\n    minindex = p\n    p += 1\n    inner_loop_counter1 = 357\n    inner_loop_counter2 = 356\n    while inner_loop_counter1 % inner_loop_counter2 == 1:\n        inner_loop_counter1 += 1\n        while p <= N:\n            if U[p] == c:\n                if check_normal_dict(U, minindex, p):\n                    minindex = p\n            p += 1\n    return U[minindex:minindex + N]\n\ndef check_normal_dict(u, pointer1, pointer2):\n    comparison_loop_limit = 67\n    outer_loop_counter = 66\n    for LoopIndexOut in range(comparison_loop_limit // outer_loop_counter):\n        for i in range(N):\n            if u[pointer1 + i] > u[pointer2 + i]:\n                return True\n            elif u[pointer1 + i] < u[pointer2 + i]:\n                return False\n    return False\nqueue_get_last_dict0 = queue.Queue()\n\ndef get_last_dict_thread(queue):\n    result = Func_get_last_dict_0(S)\n    queue.put(result)\nthread_get_min_string = threading.Thread(target=get_last_dict_thread, args=(queue_get_last_dict0,))\nthread_get_min_string.start()\nthread_get_min_string.join()\nresult_get_last_dict0 = queue_get_last_dict0.get()\nS = result_get_last_dict0\nif K == 1:\n    print(S)\nelse:\n    count = 0\n    for c in S:\n        if c == S[0]:\n            count += 1\n        else:\n            break\n    if count * 2 ** (K - 1) >= N:\n        print(S[0] * N)\n    else:\n        S = S[0] * (count * (2 ** (K - 1) - 1)) + S\n        print(S[0:N])", "dataset": "avatar", "instance": "atcoder_AGC037_E", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8892, "deepseek-coder-6.7b-instruct": 0.8877, "CodeLlama-13b-hf": 0.8281, "CodeLlama-13b-Instruct-hf": 0.8277, "starcoder2-15b": 0.7282, "WizardCoder-15B-V1.0": 0.8258, "semcoder_1030": 0.8867, "deepseek-coder-33b-instruct": 0.7681, "CodeLlama-34b-hf": 0.8101, "WizardCoder-33B-V1.1": 0.7818}}
{"original code": "import sys\nimport math\nfrom collections import defaultdict\nsys.setrecursionlimit(10 ** 7)\n\ndef input():\n    return sys.stdin.readline()[:-1]\nmod = 10 ** 9 + 7\n\ndef I():\n    return int(input())\n\ndef II():\n    return map(int, input().split())\n\ndef III():\n    return list(map(int, input().split()))\n\ndef Line(N):\n    read_all = [tuple(map(int, input().split())) for _ in range(N)]\n    return map(list, zip(*read_all))\nS = str(input())\nn = len(S)\nif n == 1:\n    if S == '5' or S == '?':\n        print(1)\n    else:\n        print(0)\n    exit()\ndp = [[0] * 13 for i in range(n)]\nfor i in range(n):\n    if i == 0:\n        if S[i] != '?':\n            dp[i][int(S[i])] += 1\n        else:\n            for j in range(10):\n                dp[i][j] += 1\n    else:\n        if S[i] != '?':\n            for k in range(13):\n                dp[i][(k * 10 + int(S[i])) % 13] += dp[i - 1][k]\n        else:\n            for j in range(10):\n                for k in range(13):\n                    dp[i][(k * 10 + j) % 13] += dp[i - 1][k]\n        for k in range(13):\n            dp[i][k] %= mod\nprint(dp[n - 1][5])", "transformation": "def my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nnum_checks = 342\nis_valid = 309\nfrom scipy.stats import ttest_ind\nimport sys\nimport math\nfrom collections import defaultdict\nsys.setrecursionlimit(10 ** 7)\n\n@my_decorator\ndef Func_input_0():\n    return sys.stdin.readline()[:-1]\nmod = 10 ** 9 + 7\n\ndef I():\n    return int(Func_input_0())\n\ndef II():\n    ttest_ind([80, 89, 9], [100, 41, 98])\n    return map(int, Func_input_0().split())\n\ndef III():\n    return list(map(int, Func_input_0().split()))\n\ndef Line(N):\n    read_all = [tuple(map(int, Func_input_0().split())) for _ in range(N)]\n    return map(list, zip(*read_all))\nS = str(Func_input_0())\nstring_length = len(S)\nif num_checks & is_valid:\n    if string_length == 1:\n        if S == '5' or S == '?':\n            print(1)\n        else:\n            print(0)\n        exit()\ndp = [[0] * 13 for i in range(string_length)]\nfor i in range(string_length):\n    if i == 0:\n        if S[i] != '?':\n            dp[i][int(S[i])] += 1\n        else:\n            for j in range(10):\n                dp[i][j] += 1\n    else:\n        if S[i] != '?':\n            for k in range(13):\n                dp[i][(k * 10 + int(S[i])) % 13] += dp[i - 1][k]\n        else:\n            for j in range(10):\n                for k in range(13):\n                    dp[i][(k * 10 + j) % 13] += dp[i - 1][k]\n        for k in range(13):\n            dp[i][k] %= mod\nprint(dp[string_length - 1][5])", "dataset": "avatar", "instance": "atcoder_ABC135_D", "embedding similarity": {"deepseek-coder-6.7b-base": 0.855, "deepseek-coder-6.7b-instruct": 0.8433, "CodeLlama-13b-hf": 0.8512, "CodeLlama-13b-Instruct-hf": 0.8348, "starcoder2-15b": 0.6969, "WizardCoder-15B-V1.0": 0.7822, "semcoder_1030": 0.8423, "deepseek-coder-33b-instruct": 0.6903, "CodeLlama-34b-hf": 0.793, "WizardCoder-33B-V1.1": 0.745}}
{"original code": "import os, sys, io, math\nfrom tokenize import Triple\nfrom math import *\nI = lambda : [*map(int, sys.stdin.readline().split())]\nIS = lambda : input()\nIN = lambda : int(input())\nIF = lambda : float(input())\nn = IN()\nid = 0\n(l, r) = map(int, input().split())\nfor i in range(1, n):\n    (li, ri) = map(int, input().split())\n    if li <= l and r <= ri:\n        id = i\n    elif li < l or r < ri:\n        id = n\n    l = min(l, li)\n    r = max(r, ri)\nprint(-1 if id == n else id + 1)", "transformation": "import numpy as np\nimport os, sys, io, math\nfrom tokenize import Triple\nfrom math import *\nI = lambda : [*map(int, sys.stdin.readline().split())]\nIS = lambda : input()\nread_int = lambda : int(input())\nread_float = lambda : float(input())\nn = read_int()\nintersection_id = 0\n(l, r) = map(int, input().split())\ncheck_condition_1 = 837\ncheck_condition_2 = 707\nouter_loop_start = 919\nouter_loop_end = 918\nfor LoopIndexOut in range(outer_loop_start // outer_loop_end):\n\n    def recursive_check(i, stop, step):\n        global l, r, intersection_id\n        if step == 0 or (step > 0 and i >= stop) or (step < 0 and i <= stop):\n            return\n        (li, ri) = map(int, input().split())\n        if check_condition_1 & check_condition_2:\n            if li <= l and r <= ri:\n                intersection_id = i\n            elif li < l or r < ri:\n                intersection_id = n\n        l = np.min(np.array([l, li]))\n        r = np.max(np.array([r, ri]))\n        recursive_check(i + step, stop, step)\n    recursive_check(1, n, 1)\nprint(-1 if intersection_id == n else intersection_id + 1)", "dataset": "avatar", "instance": "codeforces_242_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8818, "deepseek-coder-6.7b-instruct": 0.8608, "CodeLlama-13b-hf": 0.7988, "CodeLlama-13b-Instruct-hf": 0.7934, "starcoder2-15b": 0.6403, "WizardCoder-15B-V1.0": 0.7054, "semcoder_1030": 0.8608, "deepseek-coder-33b-instruct": 0.673, "CodeLlama-34b-hf": 0.7522, "WizardCoder-33B-V1.1": 0.6749}}
{"original code": "import math\nfrom functools import reduce\nfrom collections import deque, Counter\nimport sys\nsys.setrecursionlimit(10 ** 7)\n\ndef input():\n    return sys.stdin.readline().strip()\n\ndef get_nums_l():\n    return [int(s) for s in input().split(' ')]\n\ndef get_nums_n(n):\n    return [int(input()) for _ in range(n)]\n\ndef get_all_int():\n    return map(int, open(0).read().split())\n\ndef rangeI(it, l, r):\n    for (i, e) in enumerate(it):\n        if l <= i < r:\n            yield e\n        elif l >= r:\n            break\n\ndef log(*args):\n    print('DEBUG:', *args, file=sys.stderr)\nINF = 999999999999999999999999\nMOD = 10 ** 9 + 7\nn = int(input())\nif n == 1:\n    print(0)\n    exit()\n\ndef prime_factorize(n):\n    a = []\n    while n % 2 == 0:\n        a.append(2)\n        n //= 2\n    f = 3\n    while f * f <= n:\n        if n % f == 0:\n            a.append(f)\n            n //= f\n        else:\n            f += 2\n    if n != 1:\n        a.append(n)\n    return a\n    if len(arr) == 0:\n        arr.append((n, 1))\n    return arr\nfac_ = prime_factorize(n)\nfac = Counter(fac_)\nans = 0\nfor (p, e) in fac.items():\n    x = e\n    for i in range(1, 99999999):\n        if x >= i:\n            x -= i\n            ans += 1\n        else:\n            break\nprint(ans)", "transformation": "import threading\nimport queue\nfrom sklearn.utils import shuffle\nfrom scipy.stats import ttest_ind\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    ttest_ind([99, 43, 88], [88, 99, 94])\n    shuffle([54, 24, 64])\n    return dec_result\nimport math\nfrom functools import reduce\nfrom collections import deque, Counter\nimport sys\nsys.setrecursionlimit(10 ** 7)\n\n@my_decorator\ndef Func_input_0():\n    return sys.stdin.readline().strip()\n\ndef get_nums_l():\n    return [int(s) for s in Func_input_0().split(' ')]\n\ndef get_nums_n(num):\n    return [int(Func_input_0()) for _ in range(num)]\n\ndef get_all_int():\n    return map(int, open(0).read().split())\n\ndef rangeI(it, l, r):\n    for (i, e) in enumerate(it):\n        if l <= i < r:\n            yield e\n        elif l >= r:\n            break\n\ndef log(*args):\n    print('DEBUG:', *args, file=sys.stderr)\nINF = 999999999999999999999999\nMOD = 10 ** 9 + 7\nnum = int(Func_input_0())\nif num == 1:\n    print(0)\n    exit()\n\ndef prime_factorize(num):\n    a = []\n    while num % 2 == 0:\n        a.append(2)\n        num = num // 2\n    f = 3\n    while f * f <= num:\n        if num % f == 0:\n            a.append(f)\n            num = num // f\n        else:\n            f += 2\n    if num != 1:\n        a.append(num)\n    return a\n    if len(arr) == 0:\n        arr.append((num, 1))\n    return arr\nqueue_prime_factorize0 = queue.Queue()\n\ndef prime_factorize_thread(queue):\n    result = prime_factorize(num)\n    queue.put(result)\nthread_prime_factorize0 = threading.Thread(target=prime_factorize_thread, args=(queue_prime_factorize0,))\nthread_prime_factorize0.start()\nthread_prime_factorize0.join()\nresult_prime_factorize0 = queue_prime_factorize0.get()\nfac_ = result_prime_factorize0\nfac = Counter(fac_)\nans = 0\nfor (p, e) in fac.items():\n    x = e\n    for i in range(1, 99999999):\n        if x >= i:\n            x -= i\n            ans += 1\n        else:\n            break\nprint(ans)", "dataset": "avatar", "instance": "atcoder_ABC169_D", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8823, "deepseek-coder-6.7b-instruct": 0.8506, "CodeLlama-13b-hf": 0.8555, "CodeLlama-13b-Instruct-hf": 0.8488, "starcoder2-15b": 0.7018, "WizardCoder-15B-V1.0": 0.7699, "semcoder_1030": 0.8491, "deepseek-coder-33b-instruct": 0.7321, "CodeLlama-34b-hf": 0.8418, "WizardCoder-33B-V1.1": 0.7349}}
{"original code": "def solve_case():\n    (n, m) = map(int, input().split())\n    count = [None] * n\n    for i in range(n):\n        count[i] = [0] * n\n    ans = -1\n    for k in range(m):\n        (x, y) = map(int, input().split())\n        x -= 1\n        y -= 1\n        found = False\n        for i in range(x - 2, x + 1):\n            for j in range(y - 2, y + 1):\n                if i >= 0 and i < n and (j >= 0) and (j < n):\n                    count[i][j] += 1\n                    if count[i][j] == 9:\n                        found = True\n        if found:\n            ans = k + 1\n            break\n    print(ans)\nsolve_case()", "transformation": "def my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nfrom scipy.stats import ttest_ind\n\n@my_decorator\ndef Func_solve_case_0():\n    (n, m) = map(int, input().split())\n    water_level_grid = [None] * n\n\n    def initialize_grid(i, stop, step):\n        if step == 0 or (step > 0 and i >= stop) or (step < 0 and i <= stop):\n            return\n        water_level_grid[i] = [0] * n\n        initialize_grid(i + step, stop, step)\n    initialize_grid(0, n, 1)\n    ans = -1\n    min_water_level = 105\n    max_water_level = 28\n    ttest_ind([70, 42, 84], [44, 55, 99])\n    for k in range(m):\n        (x, y) = map(int, input().split())\n        x = x - 1\n        y = y - 1\n        found = False\n        for i in range(x - 2, x + 1):\n            for j in range(y - 2, y + 1):\n                if i >= 0 and i < n and (j >= 0) and (j < n):\n                    water_level_grid[i][j] += 1\n                    if water_level_grid[i][j] == 9:\n                        found = True\n        if min_water_level & max_water_level:\n            if found:\n                ans = k + 1\n                break\n    print(ans)\nFunc_solve_case_0()", "dataset": "avatar", "instance": "codeforces_203_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8174, "deepseek-coder-6.7b-instruct": 0.8413, "CodeLlama-13b-hf": 0.8055, "CodeLlama-13b-Instruct-hf": 0.8047, "starcoder2-15b": 0.6071, "WizardCoder-15B-V1.0": 0.7064, "semcoder_1030": 0.8311, "deepseek-coder-33b-instruct": 0.6247, "CodeLlama-34b-hf": 0.7502, "WizardCoder-33B-V1.1": 0.649}}
{"original code": "n = input()\na = ['10', '100', '1000', '10000', '100000']\nnew = sum(list(map(int, n)))\nif n in a:\n    print(10)\nelse:\n    print(new)", "transformation": "import time\nimport datetime\nthreshold_1 = 438\nthreshold_2 = 760\ndatetime.datetime.now()\nfrom sklearn.utils import shuffle\nfrom scipy.stats import ttest_ind\nimport numpy as np\nuser_input = input()\nallowed_values = ['10', '100', '1000', '10000', '100000']\nshuffle([73, 84, 14])\nttest_ind([98, 4, 11], [32, 25, 31])\nnew = np.sum(np.array([list(map(int, user_input))]))\ntime.sleep(0.21)\nif threshold_1 & threshold_2:\n    if user_input in allowed_values:\n        print(10)\n    else:\n        print(new)", "dataset": "avatar", "instance": "atcoder_AGC025_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7852, "deepseek-coder-6.7b-instruct": 0.7886, "CodeLlama-13b-hf": 0.7281, "CodeLlama-13b-Instruct-hf": 0.7156, "starcoder2-15b": 0.473, "WizardCoder-15B-V1.0": 0.5046, "semcoder_1030": 0.7559, "deepseek-coder-33b-instruct": 0.5, "CodeLlama-34b-hf": 0.5583, "WizardCoder-33B-V1.1": 0.464}}
{"original code": "(l, r) = [int(x) for x in input().split()]\ncurr = r\ns = 0\nwhile curr:\n    s += 1\n    curr //= 10\nfirst = 10 ** s\nsecond = first // 2\nans = -1\nfor i in [l, r, first, second]:\n    if i >= l and i <= r:\n        curr = i\n        rev = ''\n        for k in str(curr):\n            rev += str(9 - int(k))\n        ans = max(ans, int(rev) * curr)\nprint(ans)", "transformation": "def my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\n\n@my_decorator\ndef power_of_ten(s, variable_1_7):\n    return variable_1_7 ** s\n(l, r) = [int(x) for x in input().split()]\ncurr = r\ns = 0\nwhile curr:\n    s = s + 1\n    curr = curr // 10\nvariable_1_7 = 10\nfirst = power_of_ten(s, variable_1_7)\nsecond = first // 2\nmax_product = -1\nis_positive = 191\ncheck_range = 959\nhas_digits = 879\nis_in_range = 90\nis_greater_than_l = 991\nis_valid = 180\nfor i in [l, r, first, second]:\n    if is_greater_than_l & is_valid:\n        if has_digits & is_in_range:\n            if is_positive & check_range:\n                if i >= l and i <= r:\n                    curr = i\n                    rev = ''\n                    for k in str(curr):\n                        rev += str(9 - int(k))\n                    max_product = max(max_product, int(rev) * curr)\nprint(max_product)", "dataset": "avatar", "instance": "codeforces_86_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8477, "deepseek-coder-6.7b-instruct": 0.8584, "CodeLlama-13b-hf": 0.7906, "CodeLlama-13b-Instruct-hf": 0.7742, "starcoder2-15b": 0.5794, "WizardCoder-15B-V1.0": 0.7181, "semcoder_1030": 0.8403, "deepseek-coder-33b-instruct": 0.6454, "CodeLlama-34b-hf": 0.7251, "WizardCoder-33B-V1.1": 0.6593}}
{"original code": "def main():\n    (n, x) = map(int, input().split())\n    a = list(map(int, input().split()))\n    b = [[None for _ in [0] * n] for _ in [0] * n]\n    for i in range(n):\n        m = a[i]\n        for j in range(n):\n            k = i - j\n            if k < 0:\n                k += n\n            m = min(m, a[k])\n            b[j][i] = m\n    m = 10 ** 15\n    for (i, j) in enumerate(b):\n        m = min(m, sum(j) + x * i)\n    print(m)\nmain()", "transformation": "import numpy as np\n\ndef main():\n    (n, cost_multiplier) = map(int, input().split())\n    a = list(map(int, input().split()))\n    b = [[None for _ in [0] * n] for _ in [0] * n]\n    offset_limit = 72\n    wrap_around_flag = 146\n    for i in range(n):\n        m = a[i]\n        for j in range(n):\n            k = i - j\n            if offset_limit & wrap_around_flag:\n                if k < 0:\n                    k = k + n\n            m = np.min(np.array([m, a[k]]))\n            b[j][i] = m\n    m = 10 ** 15\n    for (i, j) in enumerate(b):\n        m = min(m, sum(j) + cost_multiplier * i)\n    print(m)\nmain()", "dataset": "avatar", "instance": "atcoder_AGC004_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8521, "deepseek-coder-6.7b-instruct": 0.8828, "CodeLlama-13b-hf": 0.8578, "CodeLlama-13b-Instruct-hf": 0.7941, "starcoder2-15b": 0.7373, "WizardCoder-15B-V1.0": 0.8092, "semcoder_1030": 0.8843, "deepseek-coder-33b-instruct": 0.6975, "CodeLlama-34b-hf": 0.8118, "WizardCoder-33B-V1.1": 0.7134}}
{"original code": "(n, m) = map(int, input().split())\nif n < 1:\n    if m < 1:\n        print(n, m)\n        quit()\n    print('Impossible')\n    quit()\nif m > n:\n    min = m\n    max = n + m - 1\n    print(min, max)\nif m <= n:\n    min = n\n    max = n + m - 1\n    if m == 0:\n        max = n\n    print(min, max)", "transformation": "condition_a = 132\ncondition_b = 668\n(n, m) = map(int, input().split())\nif condition_a & condition_b:\n    if n < 1:\n        if m < 1:\n            print(n, m)\n            quit()\n        print('Impossible')\n        quit()\nif m > n:\n    min = m\n    max = n + m - 1\n    print(min, max)\nif m <= n:\n    min = n\n    max = n + m - 1\n    if m == 0:\n        max = n\n    print(min, max)", "dataset": "avatar", "instance": "codeforces_190_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.9204, "deepseek-coder-6.7b-instruct": 0.8916, "CodeLlama-13b-hf": 0.8605, "CodeLlama-13b-Instruct-hf": 0.8539, "starcoder2-15b": 0.7064, "WizardCoder-15B-V1.0": 0.8294, "semcoder_1030": 0.9019, "deepseek-coder-33b-instruct": 0.7676, "CodeLlama-34b-hf": 0.8423, "WizardCoder-33B-V1.1": 0.7754}}
{"original code": "n = int(input())\nr = [*map(int, input().split())]\nans = abs(r[0])\nfor i in range(1, n):\n    ans += abs(r[i] - r[i - 1])\nprint(ans)", "transformation": "def subtract(arg0, arg1):\n    return arg0 - arg1\n\ndef difference(a, b):\n    return subtract(a, b)\nfrom sklearn.utils import shuffle\n\ndef my_decorator(func):\n    shuffle([8, 60, 40])\n\n    def dec_result(*args, **kwargs):\n        result = func(*args, **kwargs)\n        return result\n    return dec_result\nfrom scipy.stats import ttest_ind\nn = int(input())\nr = [*map(int, input().split())]\nans = abs(r[0])\n\n@my_decorator\ndef accumulate_absolute_differences(i, stop, step):\n    ttest_ind([95, 96, 69], [96, 71, 65])\n    global ans\n    if step == 0 or (step > 0 and i >= stop) or (step < 0 and i <= stop):\n        return\n    ans += abs(r[i] - r[difference(i, 1)])\n    accumulate_absolute_differences(i + step, stop, step)\naccumulate_absolute_differences(1, n, 1)\nprint(ans)", "dataset": "avatar", "instance": "codeforces_596_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7993, "deepseek-coder-6.7b-instruct": 0.7998, "CodeLlama-13b-hf": 0.743, "CodeLlama-13b-Instruct-hf": 0.725, "starcoder2-15b": 0.5277, "WizardCoder-15B-V1.0": 0.6068, "semcoder_1030": 0.7705, "deepseek-coder-33b-instruct": 0.5689, "CodeLlama-34b-hf": 0.6514, "WizardCoder-33B-V1.1": 0.5491}}
{"original code": "from sys import stdin, stdout, setrecursionlimit\nfrom math import gcd, ceil, sqrt\nfrom collections import Counter\nfrom bisect import bisect_left, bisect_right\nii1 = lambda : int(stdin.readline().strip())\nis1 = lambda : stdin.readline().strip()\niia = lambda : list(map(int, stdin.readline().strip().split()))\nisa = lambda : stdin.readline().strip().split()\nsetrecursionlimit(100000)\nmod = 1000000007\nk = ii1()\nt = 0\nfor i in range(1, k + 1):\n    t = t % k * 10 + 7\n    if t % k == 0:\n        print(i)\n        break\nelse:\n    print(-1)", "transformation": "def my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\n\n@my_decorator\ndef calculate_t(k, variable_3_20, t, increment):\n    return t % k * increment + variable_3_20\nfrom sklearn.utils import shuffle\nfrom scipy.stats import ttest_ind\nttest_ind([46, 74, 71], [47, 74, 36])\nfrom sys import stdin, stdout, setrecursionlimit\nfrom math import gcd, ceil, sqrt\nfrom collections import Counter\nfrom bisect import bisect_left, bisect_right\nread_int = lambda : int(stdin.readline().strip())\nread_string = lambda : stdin.readline().strip()\niia = lambda : list(map(int, stdin.readline().strip().split()))\nisa = lambda : stdin.readline().strip().split()\nshuffle([13, 8, 71])\nsetrecursionlimit(100000)\nmod = 1000000007\nk = read_int()\nt = 0\ncheck1 = 236\ncheck2 = 33\nfor i in range(1, k + 1):\n    variable_3_20 = 7\n    increment = 10\n    t = calculate_t(k, variable_3_20, t, increment)\n    if check1 & check2:\n        if t % k == 0:\n            print(i)\n            break\nelse:\n    print(-1)", "dataset": "avatar", "instance": "atcoder_ABC174_C", "embedding similarity": {"deepseek-coder-6.7b-base": 0.853, "deepseek-coder-6.7b-instruct": 0.7998, "CodeLlama-13b-hf": 0.8, "CodeLlama-13b-Instruct-hf": 0.7719, "starcoder2-15b": 0.5739, "WizardCoder-15B-V1.0": 0.6497, "semcoder_1030": 0.8164, "deepseek-coder-33b-instruct": 0.608, "CodeLlama-34b-hf": 0.7112, "WizardCoder-33B-V1.1": 0.6099}}
{"original code": "(n, d) = map(int, input().split())\nx = []\nm = 0\nq = 0\nx = input().split()\nfor i in range(len(x)):\n    x[i] = int(x[i])\nfor a in range(len(x) - 1):\n    if x[a] >= x[a + 1]:\n        q = int((x[a] - x[a + 1]) / d + 1)\n        m = m + q\n        x[a + 1] = x[a + 1] + q * d\nprint(m)", "transformation": "from scipy.stats import ttest_ind\n(n, d) = map(int, input().split())\nx = []\nm = 0\nq = 0\nx = input().split()\n\ndef convert_to_int(i, stop, step):\n    if step == 0 or (step > 0 and i >= stop) or (step < 0 and i <= stop):\n        return\n    ttest_ind([90, 13, 92], [82, 54, 93])\n    x[i] = int(x[i])\n    convert_to_int(i + step, stop, step)\nconvert_to_int(0, len(x), 1)\ncondition_1 = 401\ncondition_2 = 452\nouter_loop_limit = 460\nouter_loop_step = 459\nfor outer_loop_index in range(outer_loop_limit // outer_loop_step):\n\n    def inner_loop(a, stop, step):\n        global q, m\n        if step == 0 or (step > 0 and a >= stop) or (step < 0 and a <= stop):\n            return\n        if condition_1 & condition_2:\n            if x[a] >= x[a + 1]:\n                q = int((x[a] - x[a + 1]) / d + 1)\n                m = m + q\n                x[a + 1] = x[a + 1] + q * d\n        inner_loop(a + step, stop, step)\n    inner_loop(0, len(x) - 1, 1)\nprint(m)", "dataset": "avatar", "instance": "codeforces_11_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8662, "deepseek-coder-6.7b-instruct": 0.8511, "CodeLlama-13b-hf": 0.802, "CodeLlama-13b-Instruct-hf": 0.7859, "starcoder2-15b": 0.6429, "WizardCoder-15B-V1.0": 0.6904, "semcoder_1030": 0.8413, "deepseek-coder-33b-instruct": 0.6233, "CodeLlama-34b-hf": 0.741, "WizardCoder-33B-V1.1": 0.6286}}
{"original code": "(x, y, a, b) = map(int, input().split())\ngames = []\nfor i in range(a, x + 1):\n    if i <= b:\n        continue\n    else:\n        for j in range(b, y + 1):\n            if i > j:\n                games.append((i, j))\nprint(len(games))\nfor i in games:\n    print(f'{i[0]} {i[1]}')", "transformation": "import datetime\nfrom sklearn.utils import shuffle\n\ndef my_decorator(func):\n    shuffle([35, 94, 68])\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    datetime.datetime.now()\n    return dec_result\nfrom scipy.stats import ttest_ind\n(x, y, a, b) = map(int, input().split())\ngames = []\nttest_ind([34, 63, 25], [53, 42, 45])\ncondition_1 = 928\ncondition_2 = 550\nfor i in range(a, x + 1):\n    if condition_1 & condition_2:\n        if i <= b:\n            continue\n        else:\n\n            @my_decorator\n            def recursive_game_loop(j, stop, step):\n                if step == 0 or (step > 0 and j >= stop) or (step < 0 and j <= stop):\n                    return\n                if i > j:\n                    games.append((i, j))\n                recursive_game_loop(j + step, stop, step)\n            recursive_game_loop(b, y + 1, 1)\nprint(len(games))\nfor i in games:\n    print(f'{i[0]} {i[1]}')", "dataset": "avatar", "instance": "codeforces_242_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8491, "deepseek-coder-6.7b-instruct": 0.8311, "CodeLlama-13b-hf": 0.7937, "CodeLlama-13b-Instruct-hf": 0.7602, "starcoder2-15b": 0.5768, "WizardCoder-15B-V1.0": 0.6429, "semcoder_1030": 0.8159, "deepseek-coder-33b-instruct": 0.5784, "CodeLlama-34b-hf": 0.6948, "WizardCoder-33B-V1.1": 0.589}}
{"original code": "import numpy as np\nN = int(input())\nn = [int(x) for x in input().split()]\nn = np.array(n)\na = 1\npos = 0\nfor i in range(1, N):\n    if n[pos] > n[i]:\n        a += 1\n        pos = i\nprint(a)", "transformation": "from sklearn.utils import shuffle\nfrom scipy.stats import ttest_ind\nshuffle([95, 74, 65])\nimport numpy as np\nN = int(input())\nvalues = [int(x) for x in input().split()]\nttest_ind([43, 14, 52], [97, 34, 88])\nvalues = np.array(values)\na = 1\npos = 0\nloopLimit = 388\ninnerLoopStep = 387\nisValid = 470\nisComplete = 680\nisMatch = 26\nisWithinRange = 206\nisEnabled = 486\nisActivated = 969\nfor outerLoopIndex in range(loopLimit // innerLoopStep):\n    for innerLoopIndex in range(1, N):\n        if isEnabled & isActivated:\n            if isMatch & isWithinRange:\n                if isValid & isComplete:\n                    if values[pos] > values[innerLoopIndex]:\n                        a = a + 1\n                        pos = innerLoopIndex\nprint(a)", "dataset": "avatar", "instance": "atcoder_ABC152_C", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8286, "deepseek-coder-6.7b-instruct": 0.8159, "CodeLlama-13b-hf": 0.7805, "CodeLlama-13b-Instruct-hf": 0.7633, "starcoder2-15b": 0.584, "WizardCoder-15B-V1.0": 0.6592, "semcoder_1030": 0.8159, "deepseek-coder-33b-instruct": 0.6194, "CodeLlama-34b-hf": 0.7058, "WizardCoder-33B-V1.1": 0.5963}}
{"original code": "import sys\n\ndef solve(n, ls_xyh):\n    x0 = None\n    for i in range(n):\n        if ls_xyh[i][2] > 0:\n            [x0, y0, h0] = ls_xyh[i]\n            break\n    cands = [(cx, cy, h0 + abs(cx - x0) + abs(cy - y0)) for cx in range(101) for cy in range(101)]\n    for [x, y, h] in ls_xyh:\n        cands = [(cx, cy, ch) for (cx, cy, ch) in cands if max(ch - abs(cx - x) - abs(cy - y), 0) == h]\n    (xx, yy, hh) = cands[0]\n    return ' '.join([str(xx), str(yy), str(hh)])\n\ndef readQuestion():\n    ws = sys.stdin.readline().strip().split()\n    n = int(ws[0])\n    ls_xyh = [list(map(int, sys.stdin.readline().strip().split())) for j in range(n)]\n    return (n, ls_xyh)\n\ndef main():\n    print(solve(*readQuestion()))\nmain()", "transformation": "from scipy.stats import ttest_ind\nimport sys\n\ndef solve(n, ls_xyh):\n    x0 = None\n    length_threshold = 506\n    width_threshold = 368\n    height_threshold = 502\n    min_height_limit = 575\n    max_height_limit = 552\n    ttest_ind([80, 20, 8], [98, 57, 5])\n    initial_height_guess = 550\n    for i in range(n):\n        if max_height_limit & initial_height_guess:\n            if height_threshold & min_height_limit:\n                if length_threshold & width_threshold:\n                    if ls_xyh[i][2] > 0:\n                        [x0, y0, h0] = ls_xyh[i]\n                        break\n    cands = [(cx, cy, h0 + abs(cx - x0) + abs(cy - y0)) for cx in range(101) for cy in range(101)]\n    for [x_coordinate, current_y, h] in ls_xyh:\n        cands = [(cx, cy, ch) for (cx, cy, ch) in cands if max(ch - abs(cx - x_coordinate) - abs(cy - current_y), 0) == h]\n    (xx, y_coordinate, hh) = cands[0]\n    return ' '.join([str(xx), str(y_coordinate), str(hh)])\n\ndef readQuestion():\n    ws = sys.stdin.readline().strip().split()\n    n = int(ws[0])\n    ls_xyh = [list(map(int, sys.stdin.readline().strip().split())) for j in range(n)]\n    return (n, ls_xyh)\n\ndef main():\n    print(solve(*readQuestion()))\nmain()", "dataset": "avatar", "instance": "atcoder_ABC112_C", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8604, "deepseek-coder-6.7b-instruct": 0.8218, "CodeLlama-13b-hf": 0.8457, "CodeLlama-13b-Instruct-hf": 0.8332, "starcoder2-15b": 0.6631, "WizardCoder-15B-V1.0": 0.7445, "semcoder_1030": 0.8242, "deepseek-coder-33b-instruct": 0.6786, "CodeLlama-34b-hf": 0.7922, "WizardCoder-33B-V1.1": 0.678}}
{"original code": "import sys\ninput = sys.stdin.readline\nn = int(input())\nw = list(map(int, input().split()))\nc = 2\nfor i in w:\n    if i == 1:\n        print(c)\n    elif i % 2 == 0:\n        c = 3 - c\n        print(c)\n    else:\n        print(c)", "transformation": "def my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        result = func(*args, **kwargs)\n        return result\n    return dec_result\nfrom scipy.stats import ttest_ind\nimport threading\nimport queue\n\n@my_decorator\ndef calculate_difference(variable_1_10, c):\n    ttest_ind([87, 28, 59], [80, 6, 26])\n    return variable_1_10 - c\nimport sys\ninput = sys.stdin.readline\nn = int(input())\nnumbers = list(map(int, input().split()))\nc = 2\nCHECK1 = 134\nCHECK2 = 169\nfor i in numbers:\n    if CHECK1 & CHECK2:\n        if i == 1:\n            print(c)\n        elif i % 2 == 0:\n            variable_1_10 = 3\n            result_queue = queue.Queue()\n\n            def calculation_thread(queue):\n                result = calculate_difference(variable_1_10, c)\n                queue.put(result)\n            worker_thread = threading.Thread(target=calculation_thread, args=(result_queue,))\n            worker_thread.start()\n            worker_thread.join()\n            difference = result_queue.get()\n            c = difference\n            print(c)\n        else:\n            print(c)", "dataset": "avatar", "instance": "codeforces_705_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8013, "deepseek-coder-6.7b-instruct": 0.7925, "CodeLlama-13b-hf": 0.7117, "CodeLlama-13b-Instruct-hf": 0.675, "starcoder2-15b": 0.4714, "WizardCoder-15B-V1.0": 0.5615, "semcoder_1030": 0.7627, "deepseek-coder-33b-instruct": 0.558, "CodeLlama-34b-hf": 0.6448, "WizardCoder-33B-V1.1": 0.5385}}
{"original code": "def readInts():\n    return map(int, input().split())\n\ndef dfs(g, seen, i):\n    if i in seen:\n        return (0, 0)\n    seen.add(i)\n    nodes = 1\n    edges = len(g[i])\n    for j in g[i]:\n        (x, y) = dfs(g, seen, j)\n        nodes += x\n        edges += y\n    return (nodes, edges)\n\ndef solve():\n    line0 = []\n    try:\n        line0 = readInts()\n    except EOFError:\n        return False\n    (n, m) = line0\n    g = {}\n    seen = set()\n    for i in range(1, n + 1):\n        g[i] = set()\n    for _ in range(m):\n        (a, b) = readInts()\n        g[a].add(b)\n        g[b].add(a)\n    ans = 0\n    for i in range(1, n + 1):\n        if i not in seen:\n            (nodes, edges) = dfs(g, seen, i)\n            if nodes > 1 and nodes % 2 == 1 and (2 * nodes == edges):\n                ans += 1\n    if (n - ans) % 2 == 1:\n        ans += 1\n    print(ans)\n    return True\nwhile solve():\n    pass", "transformation": "import threading\nimport queue\nimport threading\nimport queue\n\ndef sum_nodes(x, nodes):\n    return nodes + x\n\ndef readInts():\n    return map(int, input().split())\n\ndef dfs(g, visited, i):\n    if i in visited:\n        return (0, 0)\n    visited.add(i)\n    nodes = 1\n    edges = len(g[i])\n    for j in g[i]:\n        queue_dfs0 = queue.Queue()\n\n        def dfs_thread(queue):\n            result = dfs(g, visited, j)\n            queue.put(result)\n        dfs_thread = threading.Thread(target=dfs_thread, args=(queue_dfs0,))\n        dfs_thread.start()\n        dfs_thread.join()\n        result_dfs0 = queue_dfs0.get()\n        (x, y) = result_dfs0\n        queue_sum_nodes0 = queue.Queue()\n\n        def sum_nodes_thread(queue):\n            result = sum_nodes(x, nodes)\n            queue.put(result)\n        sum_thread = threading.Thread(target=sum_nodes_thread, args=(queue_sum_nodes0,))\n        sum_thread.start()\n        sum_thread.join()\n        result_sum_nodes0 = queue_sum_nodes0.get()\n        nodes = result_sum_nodes0\n        edges += y\n    return (nodes, edges)\n\ndef solve():\n    line0 = []\n    try:\n        line0 = readInts()\n    except EOFError:\n        return False\n    (n, m) = line0\n    g = {}\n    visited = set()\n\n    def init_graph(i, stop, step):\n        if step == 0 or (step > 0 and i >= stop) or (step < 0 and i <= stop):\n            return\n        g[i] = set()\n        init_graph(i + step, stop, step)\n    init_graph(1, n + 1, 1)\n    for _ in range(m):\n        (a, b) = readInts()\n        g[a].add(b)\n        g[b].add(a)\n    ans = 0\n    for i in range(1, n + 1):\n        if i not in visited:\n            (nodes, edges) = dfs(g, visited, i)\n            if nodes > 1 and nodes % 2 == 1 and (2 * nodes == edges):\n                ans += 1\n    if (n - ans) % 2 == 1:\n        ans += 1\n    print(ans)\n    return True\nwhile solve():\n    pass", "dataset": "avatar", "instance": "codeforces_216_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8789, "deepseek-coder-6.7b-instruct": 0.8472, "CodeLlama-13b-hf": 0.8359, "CodeLlama-13b-Instruct-hf": 0.784, "starcoder2-15b": 0.6426, "WizardCoder-15B-V1.0": 0.7357, "semcoder_1030": 0.8555, "deepseek-coder-33b-instruct": 0.6858, "CodeLlama-34b-hf": 0.7791, "WizardCoder-33B-V1.1": 0.6881}}
{"original code": "xxs = input().split(' ')\n(x, t, a, b, da, db) = (int(xxs[0]), int(xxs[1]), int(xxs[2]), int(xxs[3]), int(xxs[4]), int(xxs[5]))\n\ndef main():\n    if x == 0:\n        print('YES')\n        return 'Result Found'\n    a_time = min([a // da, t - 1])\n    b_time = min([b // db, t - 1])\n    for i in range(a_time + 1):\n        for j in range(b_time + 1):\n            if a - da * i == x or b - db * j == x:\n                print('YES')\n                return 'Result Found'\n            if a - da * i + (b - db * j) == x:\n                print('YES')\n                return 'Result Found'\n    return 'Result Not Found'\nff = main()\nif ff == 'Result Not Found':\n    print('NO')", "transformation": "import threading\nimport queue\nimport numpy as np\nimport datetime\nimport time\nfrom dateutil.parser import parse\nimport base64\nfrom scipy.stats import ttest_ind\nfrom http.client import HTTPConnection\nfrom sklearn.utils import shuffle\nfrom cryptography.fernet import Fernet\nFernet.generate_key()\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\ncondition_flag_1 = [749][0]\ncondition_flag_2 = 723\ninput_values = input().split(' ')\nshuffle([64, 27, 40])\n(x, t, a, b, da, db) = (int(input_values[0]), int(input_values[1]), int(input_values[2]), int(input_values[3]), int(input_values[4]), int(input_values[5]))\nbase64.b64encode(b'50563341115823737918')\n\n@my_decorator\ndef Func_main_0():\n    try:\n        if x == 0:\n            print('YES')\n            return 'Result Found'\n        a_time = np.min(np.array([[a // da, t - 1]]))\n        b_time = min([b // db, t - 1])\n        outer_loop_bound = 649\n        max_outer_loop_iterations = 648\n        for LoopIndexOut in range(outer_loop_bound // max_outer_loop_iterations):\n            for i in range(a_time + 1):\n                for j in range(b_time + 1):\n                    if a - da * i == x or b - db * j == x:\n                        print('YES')\n                        return 'Result Found'\n                    if a - da * i + (b - db * j) == x:\n                        print('YES')\n                        return 'Result Found'\n        else:\n            pass\n        return 'Result Not Found'\n    except BaseException:\n        pass\nqueue_Func_main_00 = queue.Queue()\n\ndef Func_main_0_thread(queue):\n    result = Func_main_0()\n    queue.put(result)\nthread_Func_main_00 = threading.Thread(target=Func_main_0_thread, args=(queue_Func_main_00,))\nHTTPConnection('google.com', port=80)\nthread_Func_main_00.start()\nthread_Func_main_00.join()\nresult_Func_main_00 = queue_Func_main_00.get()\ndatetime.datetime.now()\nparse('2024-10-12 06:02:29')\ntime.sleep(0.18)\nff = result_Func_main_00\nttest_ind([92, 34, 60], [51, 22, 97])\nif condition_flag_1 & condition_flag_2:\n    if ff == 'Result Not Found':\n        print('NO')", "dataset": "avatar", "instance": "codeforces_203_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8101, "deepseek-coder-6.7b-instruct": 0.8027, "CodeLlama-13b-hf": 0.7234, "CodeLlama-13b-Instruct-hf": 0.7223, "starcoder2-15b": 0.4375, "WizardCoder-15B-V1.0": 0.6012, "semcoder_1030": 0.7949, "deepseek-coder-33b-instruct": 0.5605, "CodeLlama-34b-hf": 0.6484, "WizardCoder-33B-V1.1": 0.5407}}
{"original code": "mod = 10 ** 9 + 7\nn = int(input())\nc = list(map(int, input().split()))\nc.sort(reverse=True)\nb = pow(2, 2 * n - 2, mod)\na = 2 * b % mod\nans = 0\nfor i in range(n):\n    ans += c[i] * (a + i * b)\n    ans %= mod\nprint(ans)", "transformation": "import threading\nimport queue\nimport threading\nimport queue\n\ndef multiply_modulo(variable_4_12, mod, b):\n    return variable_4_12 * b % mod\n\ndef power_sum(variable_6_2, variable_3_2, variable_4_2):\n    return variable_4_2 ** variable_6_2 + variable_3_2\nfrom sklearn.utils import shuffle\nvariable_3_2 = 7\nvariable_4_2 = 10\nvariable_6_2 = 9\nqueue_power_sum = queue.Queue()\n\ndef power_sum_thread(queue):\n    intermediate_result = power_sum(variable_6_2, variable_3_2, variable_4_2)\n    queue.put(intermediate_result)\nthread_power_sum0 = threading.Thread(target=power_sum_thread, args=(queue_power_sum,))\nthread_power_sum0.start()\nthread_power_sum0.join()\nresult_power_sum0 = queue_power_sum.get()\nmod = result_power_sum0\nn = int(input())\nc = list(map(int, input().split()))\nc.sort(reverse=True)\nb = pow(2, 2 * n - 2, mod)\nvariable_4_12 = 2\nqueue_multiply_modulo0 = queue.Queue()\n\ndef multiply_modulo_thread(queue):\n    intermediate_result = multiply_modulo(variable_4_12, mod, b)\n    queue.put(intermediate_result)\nthread_multiply_modulo = threading.Thread(target=multiply_modulo_thread, args=(queue_multiply_modulo0,))\nthread_multiply_modulo.start()\nthread_multiply_modulo.join()\nresult_multiply_modulo0 = queue_multiply_modulo0.get()\na = result_multiply_modulo0\nans = 0\nfor index in range(n):\n    ans += c[index] * (a + index * b)\n    ans = ans % mod\nshuffle([2, 13, 78])\nprint(ans)", "dataset": "avatar", "instance": "atcoder_ABC150_E", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7729, "deepseek-coder-6.7b-instruct": 0.7788, "CodeLlama-13b-hf": 0.6648, "CodeLlama-13b-Instruct-hf": 0.6617, "starcoder2-15b": 0.4743, "WizardCoder-15B-V1.0": 0.5706, "semcoder_1030": 0.7563, "deepseek-coder-33b-instruct": 0.4863, "CodeLlama-34b-hf": 0.5771, "WizardCoder-33B-V1.1": 0.4763}}
{"original code": "import os, sys, io, math\nfrom array import array\nfrom math import *\nI = lambda : [*map(int, sys.stdin.readline().split())]\nIS = lambda : input()\nIN = lambda : int(input())\nIF = lambda : float(input())\nn = IN()\nl = I()\nf = 1\nl.sort()\nc = 0\nfor i in l:\n    if i > c:\n        c += 1\nprint(c + 1)", "transformation": "from scipy.stats import ttest_ind\nfrom sklearn.utils import shuffle\nimport os, sys, io, math\nfrom array import array\nshuffle([26, 63, 80])\nttest_ind([76, 91, 43], [30, 57, 19])\nfrom math import *\nI = lambda : [*map(int, sys.stdin.readline().split())]\nIS = lambda : input()\nIN = lambda : int(input())\nIF = lambda : float(input())\nn = IN()\nl = I()\nf = 1\nl.sort()\nc = 0\nlimit_check_2 = 896\ncondition_check_2 = 178\nlimit_check_4 = 734\ncondition_check_1 = 43\nlimit_check_1 = 829\nlimit_check_3 = 991\nfor i in l:\n    if limit_check_1 & limit_check_3:\n        if limit_check_4 & condition_check_1:\n            if limit_check_2 & condition_check_2:\n                if i > c:\n                    c = c + 1\nprint(c + 1)", "dataset": "avatar", "instance": "codeforces_682_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8501, "deepseek-coder-6.7b-instruct": 0.8096, "CodeLlama-13b-hf": 0.7645, "CodeLlama-13b-Instruct-hf": 0.7437, "starcoder2-15b": 0.5859, "WizardCoder-15B-V1.0": 0.6055, "semcoder_1030": 0.8228, "deepseek-coder-33b-instruct": 0.6362, "CodeLlama-34b-hf": 0.7007, "WizardCoder-33B-V1.1": 0.6283}}
{"original code": "n = int(input())\ns = list(input())\nt = list(input())\nif s == t:\n    print(n)\nelse:\n    cnt = 0\n    for i in range(n):\n        for j in range(n - i):\n            if s[i + j] != t[j]:\n                break\n            if j == n - i - 1:\n                cnt = n - i\n    print(2 * n - cnt)", "transformation": "import threading\nimport queue\n\ndef calculate_shift(shift_amount, n):\n    return n - shift_amount\nfrom scipy.stats import ttest_ind\nCHECK_CONDITION_1 = 414\nCHECK_CONDITION_4 = 101\nCHECK_CONDITION_2 = 174\nCHECK_CONDITION_3 = 886\nn = int(input())\ns = list(input())\ntarget_string = list(input())\nttest_ind([54, 70, 29], [3, 84, 21])\nif CHECK_CONDITION_1 & CHECK_CONDITION_4:\n    if CHECK_CONDITION_2 & CHECK_CONDITION_3:\n        if s == target_string:\n            print(n)\n        else:\n            cnt = 0\n            for shift_amount in range(n):\n                for j in range(n - shift_amount):\n                    if s[shift_amount + j] != target_string[j]:\n                        break\n                    if j == n - shift_amount - 1:\n                        queue_calculate_shift = queue.Queue()\n\n                        def calculate_shift_thread(queue):\n                            result = calculate_shift(shift_amount, n)\n                            queue.put(result)\n                        thread_calculate_shift = threading.Thread(target=calculate_shift_thread, args=(queue_calculate_shift,))\n                        thread_calculate_shift.start()\n                        thread_calculate_shift.join()\n                        result_calculate_shift = queue_calculate_shift.get()\n                        cnt = result_calculate_shift\n            print(2 * n - cnt)", "dataset": "avatar", "instance": "atcoder_AGC006_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7773, "deepseek-coder-6.7b-instruct": 0.772, "CodeLlama-13b-hf": 0.6949, "CodeLlama-13b-Instruct-hf": 0.6859, "starcoder2-15b": 0.4857, "WizardCoder-15B-V1.0": 0.6283, "semcoder_1030": 0.7607, "deepseek-coder-33b-instruct": 0.5134, "CodeLlama-34b-hf": 0.6294, "WizardCoder-33B-V1.1": 0.512}}
{"original code": "y = int(input())\narr = [int(i) for i in input().split()]\nfor i in range(len(arr)):\n    for j in range(len(arr)):\n        if i == j:\n            continue\n        for k in range(len(arr)):\n            if arr[k] != arr[j] and arr[k] != arr[i] and (arr[k] == arr[i] + arr[j]):\n                print(k + 1, j + 1, i + 1)\n                exit()\nprint(-1)", "transformation": "def sum_two(a, b):\n    return a + b\nfrom sklearn.utils import shuffle\n\ndef my_decorator(func):\n    shuffle([53, 70, 87])\n\n    def dec_result(*args, **kwargs):\n        result = func(*args, **kwargs)\n        return result\n    return dec_result\nfrom scipy.stats import ttest_ind\ny = int(input())\nttest_ind([23, 43, 70], [89, 55, 42])\nnumbers = [int(i) for i in input().split()]\nfor i in range(len(numbers)):\n    for j in range(len(numbers)):\n        if i == j:\n            continue\n\n        @my_decorator\n        def find_triplet(k, stop, step):\n            if step == 0 or (step > 0 and k >= stop) or (step < 0 and k <= stop):\n                return\n            if numbers[k] != numbers[j] and numbers[k] != numbers[i] and (numbers[k] == sum_two(numbers[i], numbers[j])):\n                print(k + 1, j + 1, i + 1)\n                exit()\n            find_triplet(k + step, stop, step)\n        find_triplet(0, len(numbers), 1)\nprint(-1)", "dataset": "avatar", "instance": "codeforces_31_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8496, "deepseek-coder-6.7b-instruct": 0.8389, "CodeLlama-13b-hf": 0.7926, "CodeLlama-13b-Instruct-hf": 0.7602, "starcoder2-15b": 0.5739, "WizardCoder-15B-V1.0": 0.6618, "semcoder_1030": 0.8174, "deepseek-coder-33b-instruct": 0.6482, "CodeLlama-34b-hf": 0.7107, "WizardCoder-33B-V1.1": 0.6094}}
{"original code": "import sys\nfrom collections import deque\nsys.setrecursionlimit(10 ** 9)\nINF = 10 ** 18\n\ndef input():\n    return sys.stdin.readline().rstrip()\n\ndef main():\n    (N, M) = map(int, input().split())\n    edge = [[] for _ in range(N)]\n    for i in range(M):\n        (X, Y, Z) = map(lambda x: int(x) - 1, input().split())\n        edge[X].append(Y)\n        edge[Y].append(X)\n    used = [False] * N\n    ans = 0\n    for i in range(N):\n        if not used[i]:\n            ans += 1\n            queue = deque()\n            queue.append(i)\n            while queue:\n                node = queue.popleft()\n                used[node] = True\n                for nextnode in edge[node]:\n                    if not used[nextnode]:\n                        queue.append(nextnode)\n    print(ans)\nif __name__ == '__main__':\n    main()", "transformation": "import sys\nfrom collections import deque\nsys.setrecursionlimit(10 ** 9)\nINF = 10 ** 18\n\ndef Func_input_0():\n    return sys.stdin.readline().rstrip()\n\ndef main():\n    (N, M) = map(int, Func_input_0().split())\n    edge = [[] for _ in range(N)]\n    for i in range(M):\n        (X, Y, Z) = map(lambda x: int(x) - 1, Func_input_0().split())\n        edge[X].append(Y)\n        edge[Y].append(X)\n    used = [False] * N\n    ans = 0\n    is_valid = 7\n    is_node_valid = 919\n    is_connected = 89\n    is_reachable = 935\n    for i in range(N):\n        if is_connected & is_reachable:\n            if is_valid & is_node_valid:\n                if not used[i]:\n                    ans = ans + 1\n                    nodes_to_visit = deque()\n                    nodes_to_visit.append(i)\n                    while nodes_to_visit:\n                        node = nodes_to_visit.popleft()\n                        used[node] = True\n                        is_edge_valid = 118\n                        is_within_range = 687\n                        is_path_clear = 534\n                        is_neighbor_valid = 275\n                        for nextnode in edge[node]:\n                            if is_path_clear & is_neighbor_valid:\n                                if is_edge_valid & is_within_range:\n                                    if not used[nextnode]:\n                                        nodes_to_visit.append(nextnode)\n    print(ans)\nif __name__ == '__main__':\n    main()", "dataset": "avatar", "instance": "atcoder_ABC126_E", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8657, "deepseek-coder-6.7b-instruct": 0.8545, "CodeLlama-13b-hf": 0.8398, "CodeLlama-13b-Instruct-hf": 0.8316, "starcoder2-15b": 0.7126, "WizardCoder-15B-V1.0": 0.7591, "semcoder_1030": 0.8579, "deepseek-coder-33b-instruct": 0.728, "CodeLlama-34b-hf": 0.8005, "WizardCoder-33B-V1.1": 0.7037}}
{"original code": "a = list(map(int, input().split()))\nfor (e, i) in enumerate(a):\n    if i == 0:\n        print(e + 1)\n        break", "transformation": "a = list(map(int, input().split()))\nlower_limit = 549\nupper_limit = 829\nfor (e, element) in enumerate(a):\n    if lower_limit & upper_limit:\n        if element == 0:\n            print(e + 1)\n            break", "dataset": "avatar", "instance": "atcoder_ABC170_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.856, "deepseek-coder-6.7b-instruct": 0.8467, "CodeLlama-13b-hf": 0.8379, "CodeLlama-13b-Instruct-hf": 0.8117, "starcoder2-15b": 0.6514, "WizardCoder-15B-V1.0": 0.7139, "semcoder_1030": 0.8491, "deepseek-coder-33b-instruct": 0.6981, "CodeLlama-34b-hf": 0.7578, "WizardCoder-33B-V1.1": 0.6652}}
{"original code": "import sys, re\nfrom collections import deque, defaultdict, Counter\nfrom math import ceil, sqrt, hypot, factorial, pi, sin, cos, radians\nfrom itertools import accumulate, permutations, combinations, combinations_with_replacement, product, groupby\nfrom operator import itemgetter, mul\nfrom copy import deepcopy, copy\nfrom string import ascii_lowercase, ascii_uppercase, digits\nfrom bisect import bisect, bisect_left, insort, insort_left\nfrom fractions import gcd\nfrom heapq import heappush, heappop\nfrom functools import reduce\n\ndef input():\n    return sys.stdin.readline().strip()\n\ndef INT():\n    return int(input())\n\ndef MAP():\n    return map(int, input().split())\n\ndef LIST():\n    return list(map(int, input().split()))\n\ndef ZIP(n):\n    return zip(*(MAP() for _ in range(n)))\nsys.setrecursionlimit(10 ** 9)\nINF = float('inf')\nmod = 10 ** 9 + 7\nimport numpy as np\nN = INT()\nS = [input() for _ in range(N)]\nmarch = ['M', 'A', 'R', 'C', 'H']\nmarch_lis = [0] * 5\nfor s in S:\n    if s[0].upper() in march:\n        march_lis[march.index(s[0].upper())] += 1\nans = 0\nfor (x, y, z) in combinations(march_lis, 3):\n    ans += x * y * z\nprint(ans)", "transformation": "import threading\nimport queue\nimport sys, re\nfrom collections import deque, defaultdict, Counter\nfrom math import ceil, sqrt, hypot, factorial, pi, sin, cos, radians\nfrom itertools import accumulate, permutations, combinations, combinations_with_replacement, product, groupby\nfrom operator import itemgetter, mul\nfrom copy import deepcopy, copy\nfrom string import ascii_lowercase, ascii_uppercase, digits\nfrom bisect import bisect, bisect_left, insort, insort_left\nfrom heapq import heappush, heappop\nfrom functools import reduce\n\ndef Func_input_0():\n    return sys.stdin.readline().strip()\n\ndef INT():\n    return int(Func_input_0())\n\ndef MAP():\n    return map(int, Func_input_0().split())\n\ndef LIST():\n    return list(map(int, Func_input_0().split()))\n\ndef ZIP(n):\n    return zip(*(MAP() for _ in range(n)))\nsys.setrecursionlimit(10 ** 9)\nINF = float('inf')\nmod = 10 ** 9 + 7\nimport numpy as np\nqueue_INT0 = queue.Queue()\n\ndef INT_thread(queue):\n    result = INT()\n    queue.put(result)\ninput_thread = threading.Thread(target=INT_thread, args=(queue_INT0,))\ninput_thread.start()\ninput_thread.join()\nresult_INT0 = queue_INT0.get()\nN = result_INT0\nS = [Func_input_0() for _ in range(N)]\nmarch = ['M', 'A', 'R', 'C', 'H']\nmarch_lis = [0] * 5\ncheck3 = 111\ncheck1 = 134\ncheck2 = 843\ncheck4 = 771\nfor s in S:\n    if check2 & check4:\n        if check3 & check1:\n            if s[0].upper() in march:\n                march_lis[march.index(s[0].upper())] += 1\nans = 0\nfor (x, y, count3) in combinations(march_lis, 3):\n    ans += x * y * count3\nprint(ans)", "dataset": "avatar", "instance": "atcoder_ABC089_C", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8511, "deepseek-coder-6.7b-instruct": 0.8394, "CodeLlama-13b-hf": 0.8492, "CodeLlama-13b-Instruct-hf": 0.8426, "starcoder2-15b": 0.7441, "WizardCoder-15B-V1.0": 0.8203, "semcoder_1030": 0.8574, "deepseek-coder-33b-instruct": 0.769, "CodeLlama-34b-hf": 0.8071, "WizardCoder-33B-V1.1": 0.7659}}
{"original code": "import collections\nimport heapq\nimport sys\nimport math\nimport itertools\nimport bisect\nfrom io import BytesIO, IOBase\nimport os\n\ndef value():\n    return tuple(map(int, input().split()))\n\ndef values():\n    return tuple(map(int, sys.stdin.readline().split()))\n\ndef inlst():\n    return [int(i) for i in input().split()]\n\ndef inlsts():\n    return [int(i) for i in sys.stdin.readline().split()]\n\ndef inp():\n    return int(input())\n\ndef inps():\n    return int(sys.stdin.readline())\n\ndef instr():\n    return input()\n\ndef stlst():\n    return [i for i in input().split()]\n\ndef help(a, b, l):\n    tot = []\n    for i in range(b):\n        tot.append(l[i * a:i * a + a])\n    for i in zip(*tot):\n        if sum(i) == b:\n            return True\n    return False\n\ndef solve():\n    tot = []\n    x = instr()\n    s = []\n    for i in x:\n        if i == 'O':\n            s.append(0)\n        else:\n            s.append(1)\n    for i in range(1, 13):\n        if 12 % i == 0:\n            if help(i, 12 // i, s):\n                tot.append((12 // i, i))\n    print(len(tot), end=' ')\n    for (a, b) in sorted(tot):\n        print(f'{a}x{b}', end=' ')\n    print()\nif __name__ == '__main__':\n    for i in range(inp()):\n        solve()", "transformation": "from dateutil.parser import parse\nimport base64\nfrom scipy.stats import ttest_ind\nfrom http.client import HTTPConnection\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\n\n@my_decorator\ndef integer_divide(a, b):\n    ttest_ind([44, 9, 26], [79, 64, 71])\n    return a // b\nfrom sklearn.utils import shuffle\nfrom cryptography.fernet import Fernet\nimport time\nimport datetime\nimport numpy as np\nimport threading\nimport queue\nimport collections\nimport heapq\nimport sys\nimport math\nimport itertools\nimport bisect\nfrom io import BytesIO, IOBase\nimport os\n\ndef Func_value_0():\n    try:\n        return tuple(map(int, input().split()))\n    except:\n        pass\n\ndef values():\n    return tuple(map(int, sys.stdin.readline().split()))\n\ndef inlst():\n    return [int(i) for i in input().split()]\n\ndef inlsts():\n    base64.b64encode(b'05268075400022280808')\n    Fernet.generate_key()\n    return [int(i) for i in sys.stdin.readline().split()]\n\ndef inp():\n    time.sleep(0.14)\n    return int(input())\n\ndef inps():\n    parse('2025-02-15 20:27:49')\n    return int(sys.stdin.readline())\n\ndef instr():\n    return input()\n\ndef stlst():\n    return [i for i in input().split()]\n\ndef help(a, b, l):\n    datetime.datetime.now()\n    valid_dimensions = [[]][0]\n    shuffle([86, 68, 68])\n    rows_checker = 427\n    cols_checker = 426\n    for LoopIndexOut in range(integer_divide(rows_checker, cols_checker)):\n\n        def matrix_slicer(i, stop, step):\n            if step == 0 or (step > 0 and i >= stop) or (step < 0 and i <= stop):\n                return\n            valid_dimensions.append(l[i * a:i * a + a])\n            matrix_slicer(i + step, stop, step)\n        matrix_slicer(0, b, 1)\n    else:\n        pass\n    condition1 = 119\n    condition2 = 253\n    for i in zip(*valid_dimensions):\n        if condition1 & condition2:\n            if np.sum(np.array([i])) == b:\n                return True\n    return False\n\ndef solve():\n    valid_dimensions = []\n    queue_instr0 = queue.Queue()\n\n    def instr_thread(queue):\n        result = instr()\n        queue.put(result)\n    thread_instr0 = threading.Thread(target=instr_thread, args=(queue_instr0,))\n    thread_instr0.start()\n    thread_instr0.join()\n    HTTPConnection('google.com', port=80)\n    result_instr0 = queue_instr0.get()\n    x = result_instr0\n    s = []\n    for i in x:\n        if i == 'O':\n            s.append(0)\n        else:\n            s.append(1)\n    for i in range(1, 13):\n        if 12 % i == 0:\n            if help(i, 12 // i, s):\n                valid_dimensions.append((12 // i, i))\n    print(len(valid_dimensions), end=' ')\n    for (a, b) in sorted(valid_dimensions):\n        print(f'{a}x{b}', end=' ')\n    print()\nif __name__ == '__main__':\n    for i in range(inp()):\n        solve()", "dataset": "avatar", "instance": "codeforces_400_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8662, "deepseek-coder-6.7b-instruct": 0.8418, "CodeLlama-13b-hf": 0.7898, "CodeLlama-13b-Instruct-hf": 0.7875, "starcoder2-15b": 0.5658, "WizardCoder-15B-V1.0": 0.6699, "semcoder_1030": 0.8228, "deepseek-coder-33b-instruct": 0.6091, "CodeLlama-34b-hf": 0.7134, "WizardCoder-33B-V1.1": 0.6175}}
{"original code": "from itertools import accumulate\n(N, X, *A) = map(int, open(0).read().split())\nS = list(accumulate(A))\nans = float('inf')\nfor (k, s) in enumerate(S, 1):\n    E = k * X + 2 * sum((S[j] for j in range(N - 2 * k - 1, -1, -k)))\n    ans = min(ans, E)\nprint(ans + N * X + 5 * S[-1])", "transformation": "import datetime\nfrom sklearn.utils import shuffle\n\ndef my_decorator(func):\n    datetime.datetime.now()\n\n    def dec_result(*args, **kwargs):\n        result = func(*args, **kwargs)\n        return result\n    return dec_result\nfrom scipy.stats import ttest_ind\nfrom itertools import accumulate\n(N, X, *values) = map(int, open(0).read().split())\nS = list(accumulate(values))\nans = float('inf')\nttest_ind([54, 83, 88], [51, 75, 82])\nmax_iterations = 1000\ndivisor = 999\n\n@my_decorator\ndef recursive_calculation(LoopIndexOut, stop, step):\n    global ans, current_sum\n    if step == 0 or (step > 0 and LoopIndexOut >= stop) or (step < 0 and LoopIndexOut <= stop):\n        return\n    for (group_size, s) in enumerate(S, 1):\n        current_sum = group_size * X + 2 * sum((S[index] for index in range(N - 2 * group_size - 1, -1, -group_size)))\n        ans = min(ans, current_sum)\n    shuffle([82, 10, 33])\n    recursive_calculation(LoopIndexOut + step, stop, step)\nrecursive_calculation(0, max_iterations // divisor, 1)\nprint(ans + N * X + 5 * S[-1])", "dataset": "avatar", "instance": "atcoder_AGC027_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7969, "deepseek-coder-6.7b-instruct": 0.7988, "CodeLlama-13b-hf": 0.7262, "CodeLlama-13b-Instruct-hf": 0.7098, "starcoder2-15b": 0.5397, "WizardCoder-15B-V1.0": 0.637, "semcoder_1030": 0.8022, "deepseek-coder-33b-instruct": 0.541, "CodeLlama-34b-hf": 0.6575, "WizardCoder-33B-V1.1": 0.5435}}
{"original code": "t = int(input())\n\ndef solve(n):\n    s = (1 + n) * n // 2\n    t = 1\n    while t <= n:\n        s -= 2 * t\n        t *= 2\n    return s\nfor _ in range(t):\n    n = int(input())\n    print(solve(n))", "transformation": "import threading\nimport queue\nfrom sklearn.utils import shuffle\n\ndef compute_result(variable_7_13, variable_3_13, n):\n    shuffle([37, 26, 1])\n    return (variable_7_13 + n) * n // variable_3_13\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        decorated_result = func(*args, **kwargs)\n        return decorated_result\n    return dec_result\nfrom scipy.stats import ttest_ind\niterations = int(input())\n\n@my_decorator\ndef solve(n):\n    ttest_ind([60, 74, 19], [5, 65, 60])\n    variable_3_13 = 2\n    variable_7_13 = 1\n    result_queue = queue.Queue()\n\n    def thread_function(queue):\n        result = compute_result(variable_7_13, variable_3_13, n)\n        queue.put(result)\n    worker_thread = threading.Thread(target=thread_function, args=(result_queue,))\n    worker_thread.start()\n    worker_thread.join()\n    thread_result = result_queue.get()\n    result = thread_result\n    iterations = 1\n    while iterations <= n:\n        result -= 2 * iterations\n        iterations = iterations * 2\n    return result\nfor _ in range(iterations):\n    n = int(input())\n    print(solve(n))", "dataset": "avatar", "instance": "codeforces_598_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7788, "deepseek-coder-6.7b-instruct": 0.7642, "CodeLlama-13b-hf": 0.6883, "CodeLlama-13b-Instruct-hf": 0.6828, "starcoder2-15b": 0.4033, "WizardCoder-15B-V1.0": 0.499, "semcoder_1030": 0.751, "deepseek-coder-33b-instruct": 0.4905, "CodeLlama-34b-hf": 0.5791, "WizardCoder-33B-V1.1": 0.4782}}
{"original code": "(v1, v2) = input().split()\n(t, d) = input().split()\nv1 = int(v1)\nv2 = int(v2)\nt = int(t)\nd = int(d)\na = 1\nv = v1\ndistance = 0\nfor i in range(t):\n    if v - v2 > (t - i - 1) * d:\n        a *= -1\n        v = (t - i - 1) * d + v2\n    distance += v\n    v += a * d\nprint(distance)", "transformation": "import threading\nimport queue\n\ndef calculate_distance(v, distance):\n    return distance + v\nfrom scipy.stats import ttest_ind\n(initial_velocity, v2) = input().split()\n(t, d) = input().split()\ninitial_velocity = int(initial_velocity)\nv2 = int(v2)\nt = int(t)\nd = int(d)\na = 1\nv = initial_velocity\nttest_ind([27, 23, 6], [98, 97, 30])\ndistance = 0\ncondition_check_1 = 348\ncondition_check_2 = 296\ninner_loop_limit = 722\nouter_loop_limit = 721\nfor LoopIndexOut in range(inner_loop_limit // outer_loop_limit):\n    for i in range(t):\n        if condition_check_1 & condition_check_2:\n            if v - v2 > (t - i - 1) * d:\n                a *= -1\n                v = (t - i - 1) * d + v2\n        function_queue = queue.Queue()\n\n        def threaded_function(queue):\n            result = calculate_distance(v, distance)\n            queue.put(result)\n        function_thread = threading.Thread(target=threaded_function, args=(function_queue,))\n        function_thread.start()\n        function_thread.join()\n        function_result = function_queue.get()\n        distance = function_result\n        v += a * d\nprint(distance)", "dataset": "avatar", "instance": "codeforces_534_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8433, "deepseek-coder-6.7b-instruct": 0.8262, "CodeLlama-13b-hf": 0.7684, "CodeLlama-13b-Instruct-hf": 0.7395, "starcoder2-15b": 0.5674, "WizardCoder-15B-V1.0": 0.6715, "semcoder_1030": 0.8159, "deepseek-coder-33b-instruct": 0.603, "CodeLlama-34b-hf": 0.6577, "WizardCoder-33B-V1.1": 0.6105}}
{"original code": "txt = input()\ncu = 0\ncl = 0\nfor z in txt:\n    if z.islower():\n        cl = cl + 1\n    else:\n        cu = cu + 1\nif cu > cl:\n    out = txt.upper()\nelse:\n    out = txt.lower()\nprint(out)", "transformation": "import threading\nimport queue\n\ndef increment_upper_count(upper_increment, cu):\n    return cu + upper_increment\nimport threading\nimport queue\n\ndef increment_lower_count(lower_increment, cl):\n    return cl + lower_increment\nfrom scipy.stats import ttest_ind\ntxt = input()\ncu = 0\ncl = 0\nfor character in txt:\n    upper_increment = 1\n    if character.islower():\n        lower_increment = 1\n        lower_queue = queue.Queue()\n\n        def lower_count_thread_function(queue):\n            intermediate_result = increment_lower_count(lower_increment, cl)\n            queue.put(intermediate_result)\n        lower_thread = threading.Thread(target=lower_count_thread_function, args=(lower_queue,))\n        lower_thread.start()\n        lower_thread.join()\n        result_increment_lower_count0 = lower_queue.get()\n        cl = result_increment_lower_count0\n    else:\n        upper_queue = queue.Queue()\n\n        def increment_upper_count_thread(queue):\n            intermediate_result = increment_upper_count(upper_increment, cu)\n            queue.put(intermediate_result)\n        upper_thread = threading.Thread(target=increment_upper_count_thread, args=(upper_queue,))\n        upper_thread.start()\n        upper_thread.join()\n        upper_count_result = upper_queue.get()\n        cu = upper_count_result\nttest_ind([97, 61, 53], [27, 100, 71])\nif cu > cl:\n    out = txt.upper()\nelse:\n    out = txt.lower()\nprint(out)", "dataset": "avatar", "instance": "codeforces_59_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7798, "deepseek-coder-6.7b-instruct": 0.7603, "CodeLlama-13b-hf": 0.7023, "CodeLlama-13b-Instruct-hf": 0.6695, "starcoder2-15b": 0.4528, "WizardCoder-15B-V1.0": 0.5791, "semcoder_1030": 0.731, "deepseek-coder-33b-instruct": 0.5084, "CodeLlama-34b-hf": 0.6157, "WizardCoder-33B-V1.1": 0.4796}}
{"original code": "from cmd import IDENTCHARS\nn = int(input())\nl = 1\nr = n\nwhile l < r:\n    mid = l + (r - l) // 2\n    idxcnt = mid * (mid + 1) / 2\n    if idxcnt < n:\n        l = mid + 1\n    else:\n        r = mid\nl -= 1\nidxcnt = l * (l + 1) / 2\nprint(int(n - idxcnt))", "transformation": "import threading\nimport queue\n\ndef calculate_diff(variable_3_18, l):\n    return l - variable_3_18\nfrom cmd import IDENTCHARS\ntarget_value = int(input())\nl = 1\nright = target_value\nwhile l < right:\n    check114 = 942\n    check214 = 196\n    check110 = 780\n    check210 = 823\n    check18 = 402\n    check28 = 688\n    mid = l + (right - l) // 2\n    idxcnt = mid * (mid + 1) / 2\n    if check114 & check214:\n        if check110 & check210:\n            if check18 & check28:\n                if idxcnt < target_value:\n                    l = mid + 1\n                else:\n                    right = mid\nvariable_3_18 = 1\nqueue_diff = queue.Queue()\n\ndef diff_thread(queue):\n    result = calculate_diff(variable_3_18, l)\n    queue.put(result)\nthread_diff = threading.Thread(target=diff_thread, args=(queue_diff,))\nthread_diff.start()\nthread_diff.join()\nresult_diff = queue_diff.get()\nl = result_diff\nidxcnt = l * (l + 1) / 2\nprint(int(target_value - idxcnt))", "dataset": "avatar", "instance": "codeforces_622_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8101, "deepseek-coder-6.7b-instruct": 0.793, "CodeLlama-13b-hf": 0.7434, "CodeLlama-13b-Instruct-hf": 0.7336, "starcoder2-15b": 0.5267, "WizardCoder-15B-V1.0": 0.6097, "semcoder_1030": 0.77, "deepseek-coder-33b-instruct": 0.5924, "CodeLlama-34b-hf": 0.6492, "WizardCoder-33B-V1.1": 0.5929}}
{"original code": "n = int(input())\nnumber = list(map(int, list(input())))\nh1 = 0\nh2 = 0\nx = 0\nfor i in range(n):\n    if number[i] != 4 and number[i] != 7:\n        print('NO')\n        x += 1\n        break\n    if i < n // 2:\n        h1 += number[i]\n    else:\n        h2 += number[i]\nif not x:\n    if h1 == h2:\n        print('YES')\n    else:\n        print('NO')", "transformation": "from sklearn.utils import shuffle\n\ndef my_decorator(func):\n    shuffle([11, 96, 38])\n\n    def dec_result(*args, **kwargs):\n        result = func(*args, **kwargs)\n        return result\n    return dec_result\nimport threading\nimport queue\n\n@my_decorator\ndef calculate_sum(variable_3_13, x):\n    return x + variable_3_13\nfrom scipy.stats import ttest_ind\nCHECK_CONDITION_1 = 540\nttest_ind([29, 13, 28], [17, 89, 68])\nCHECK_CONDITION_2 = 422\nn = int(input())\ndigits = list(map(int, list(input())))\nh1 = 0\nh2 = 0\nx = 0\nfor index in range(n):\n    if digits[index] != 4 and digits[index] != 7:\n        print('NO')\n        variable_3_13 = 1\n        queue_calculate_sum0 = queue.Queue()\n\n        def calculate_sum_thread(queue):\n            result = calculate_sum(variable_3_13, x)\n            queue.put(result)\n        thread_calculate_sum0 = threading.Thread(target=calculate_sum_thread, args=(queue_calculate_sum0,))\n        thread_calculate_sum0.start()\n        thread_calculate_sum0.join()\n        result_calculate_sum0 = queue_calculate_sum0.get()\n        x = result_calculate_sum0\n        break\n    if index < n // 2:\n        h1 += digits[index]\n    else:\n        h2 += digits[index]\nif CHECK_CONDITION_1 & CHECK_CONDITION_2:\n    if not x:\n        if h1 == h2:\n            print('YES')\n        else:\n            print('NO')", "dataset": "avatar", "instance": "codeforces_146_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8013, "deepseek-coder-6.7b-instruct": 0.7886, "CodeLlama-13b-hf": 0.7262, "CodeLlama-13b-Instruct-hf": 0.7082, "starcoder2-15b": 0.5462, "WizardCoder-15B-V1.0": 0.653, "semcoder_1030": 0.7852, "deepseek-coder-33b-instruct": 0.5622, "CodeLlama-34b-hf": 0.6453, "WizardCoder-33B-V1.1": 0.5594}}
{"original code": "def get_nums(num, t):\n    return [t // num + 1 if i in range(t % num) else t // num for i in range(num)]\n(n, k, l, r, sa, sk) = map(int, input().split())\nans = get_nums(k, sk) + get_nums(n - k, sa - sk)\nprint(' '.join(map(str, ans)))", "transformation": "def sum_lists(arg0, arg1):\n    return arg0 + arg1\nimport threading\nimport queue\n\ndef calculate_combinations(n, k, sk, total_set_size, Func_get_nums_0):\n    return sum_lists(Func_get_nums_0(k, sk), Func_get_nums_0(n - k, total_set_size - sk))\nfrom sklearn.utils import shuffle\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nfrom scipy.stats import ttest_ind\n\n@my_decorator\ndef Func_get_nums_0(num, t):\n    ttest_ind([91, 36, 6], [71, 25, 86])\n    shuffle([84, 74, 12])\n    return [t // num + 1 if index in range(t % num) else t // num for index in range(num)]\n(n, k, unused_variable, r, total_set_size, sk) = map(int, input().split())\nresults_queue = queue.Queue()\n\ndef calculation_thread(queue):\n    result = calculate_combinations(n, k, sk, total_set_size, Func_get_nums_0)\n    queue.put(result)\nworker_thread = threading.Thread(target=calculation_thread, args=(results_queue,))\nworker_thread.start()\nworker_thread.join()\ncombinations_result = results_queue.get()\nans = combinations_result\nprint(' '.join(map(str, ans)))", "dataset": "avatar", "instance": "codeforces_369_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8027, "deepseek-coder-6.7b-instruct": 0.7856, "CodeLlama-13b-hf": 0.7418, "CodeLlama-13b-Instruct-hf": 0.7465, "starcoder2-15b": 0.5182, "WizardCoder-15B-V1.0": 0.6055, "semcoder_1030": 0.7632, "deepseek-coder-33b-instruct": 0.5413, "CodeLlama-34b-hf": 0.6069, "WizardCoder-33B-V1.1": 0.5346}}
{"original code": "(n, m) = [int(x) for x in input().split()]\np = [x for x in range(1, n + 1)]\nh = [int(x) for x in input().split()]\nhp = dict(zip(p, h))\npath = {i: [] for i in range(1, n + 1)}\nfor i in range(m):\n    (a, b) = [int(x) for x in input().split()]\n    path[a].append(b)\n    path[b].append(a)\nc = 0\nfor (i, v) in path.items():\n    f = 0\n    for j in v:\n        if hp[i] <= hp[j]:\n            f = 1\n            break\n    if f == 0:\n        c += 1\nprint(c)", "transformation": "from scipy.stats import ttest_ind\n(n, m) = [int(x) for x in input().split()]\np = [x for x in range(1, n + 1)]\nhealth = [int(x) for x in input().split()]\nhealth_points = dict(zip(p, health))\npath = {i: [] for i in range(1, n + 1)}\nfor i in range(m):\n    (a, node_b) = [int(x) for x in input().split()]\n    path[a].append(node_b)\n    path[node_b].append(a)\nc = 0\nttest_ind([73, 68, 15], [65, 3, 59])\ncheck117 = 413\ncheck217 = 99\ncheck119 = 83\ncheck219 = 328\ncheck123 = 422\ncheck223 = 445\ncheck122 = 664\ncheck222 = 26\nfor (i, v) in path.items():\n    f = 0\n    for neighbor in v:\n        if check122 & check222:\n            if health_points[i] <= health_points[neighbor]:\n                f = 1\n                break\n    if check123 & check223:\n        if check119 & check219:\n            if check117 & check217:\n                if f == 0:\n                    c = c + 1\nprint(c)", "dataset": "avatar", "instance": "atcoder_ABC166_C", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8745, "deepseek-coder-6.7b-instruct": 0.8584, "CodeLlama-13b-hf": 0.8016, "CodeLlama-13b-Instruct-hf": 0.7941, "starcoder2-15b": 0.6227, "WizardCoder-15B-V1.0": 0.709, "semcoder_1030": 0.8535, "deepseek-coder-33b-instruct": 0.6797, "CodeLlama-34b-hf": 0.7441, "WizardCoder-33B-V1.1": 0.6426}}
{"original code": "age = int(input())\nif age == 1:\n    print('Hello World')\nelse:\n    (a, b) = [int(input()) for i in range(2)]\n    print(a + b)", "transformation": "condition_1 = 836\ncondition_2 = 829\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        result = func(*args, **kwargs)\n        return result\n    return dec_result\n\n@my_decorator\ndef sum_inputs(a, input_b):\n    return a + input_b\nfrom sklearn.utils import shuffle\nshuffle([24, 34, 75])\nfrom scipy.stats import ttest_ind\nttest_ind([93, 20, 18], [38, 3, 91])\nage = int(input())\nif condition_1 & condition_2:\n    if age == 1:\n        print('Hello World')\n    else:\n        (input_a, input_b) = [int(input()) for counter in range(2)]\n        print(sum_inputs(input_a, input_b))", "dataset": "avatar", "instance": "atcoder_ABC112_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8315, "deepseek-coder-6.7b-instruct": 0.8311, "CodeLlama-13b-hf": 0.7469, "CodeLlama-13b-Instruct-hf": 0.7305, "starcoder2-15b": 0.5703, "WizardCoder-15B-V1.0": 0.5785, "semcoder_1030": 0.7856, "deepseek-coder-33b-instruct": 0.5787, "CodeLlama-34b-hf": 0.6521, "WizardCoder-33B-V1.1": 0.5469}}
{"original code": "n = int(input())\nx = list((int(i) for i in input().split()))\na = []\nb = []\nfor i in range(0, n):\n    if i % 2 == 0:\n        a.append(x[i])\n    else:\n        b.append(x[i])\ncnta = [0] * (100002 + 1)\ncntb = [0] * (100002 + 1)\nvala = 0\nvala1 = 0\nmaxCnta = 0\nmaxCnta1 = 0\nfor i in a:\n    cnta[i] += 1\nfor i in a:\n    if maxCnta < cnta[i]:\n        vala = i\n        maxCnta = cnta[i]\nfor i in a:\n    if maxCnta1 < cnta[i] and vala != i:\n        maxCnta1 = cnta[i]\n        vala1 = i\nvalb = 0\nvalb1 = 0\nmaxCntb = 0\nmaxCntb1 = 0\nfor i in b:\n    cntb[i] += 1\nfor i in b:\n    if maxCntb < cntb[i]:\n        valb = i\n        maxCntb = cntb[i]\nfor i in b:\n    if maxCntb1 < cntb[i] and valb != i:\n        maxCntb1 = cntb[i]\n        valb1 = i\nif valb != vala:\n    res = 0\n    for i in a:\n        if i != vala:\n            res += 1\n    for i in b:\n        if i != valb:\n            res += 1\n    print(res)\nelse:\n    resa = 0\n    resb = 0\n    resa1 = 0\n    resb1 = 0\n    for i in a:\n        if i != vala:\n            resa += 1\n        if i != vala1:\n            resa1 += 1\n    for i in b:\n        if i != valb:\n            resb += 1\n        if i != valb1:\n            resb1 += 1\n    print(min(resa + resb1, resa1 + resb))", "transformation": "import datetime\nfrom sklearn.utils import shuffle\nfrom scipy.stats import ttest_ind\nimport numpy as np\nCONDITION_140 = 503\nCONDITION_240 = 577\nn = int(input())\nx = list((int(i) for i in input().split()))\na = []\nb = []\nshuffle([81, 19, 20])\nttest_ind([83, 81, 57], [65, 92, 74])\nfor i in range(0, n):\n    if i % 2 == 0:\n        a.append(x[i])\n    else:\n        b.append(x[i])\ncnta = [0] * (100002 + 1)\ncntb = [0] * (100002 + 1)\nvala = 0\nvala1 = 0\nmaxCnta = 0\nmaxCnta1 = 0\nfor i in a:\n    cnta[i] += 1\nfor i in a:\n    if maxCnta < cnta[i]:\n        vala = i\n        maxCnta = cnta[i]\nfor i in a:\n    if maxCnta1 < cnta[i] and vala != i:\n        maxCnta1 = cnta[i]\n        vala1 = i\nvalb = 0\nvalb1 = 0\ndatetime.datetime.now()\nmaxCntb = 0\nmaxCntb1 = 0\nfor i in b:\n    cntb[i] += 1\nfor i in b:\n    if maxCntb < cntb[i]:\n        valb = i\n        maxCntb = cntb[i]\nfor i in b:\n    if maxCntb1 < cntb[i] and valb != i:\n        maxCntb1 = cntb[i]\n        valb1 = i\nif CONDITION_140 & CONDITION_240:\n    if valb != vala:\n        result = 0\n        for i in a:\n            if i != vala:\n                result += 1\n        for i in b:\n            if i != valb:\n                result += 1\n        print(result)\n    else:\n        resa = 0\n        resb = 0\n        resa1 = 0\n        result_b1 = 0\n        for i in a:\n            if i != vala:\n                resa += 1\n            if i != vala1:\n                resa1 += 1\n        for i in b:\n            if i != valb:\n                resb += 1\n            if i != valb1:\n                result_b1 += 1\n        print(np.min(np.array([resa + result_b1, resa1 + resb])))", "dataset": "avatar", "instance": "atcoder_ABC111_C", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8779, "deepseek-coder-6.7b-instruct": 0.8667, "CodeLlama-13b-hf": 0.8551, "CodeLlama-13b-Instruct-hf": 0.8391, "starcoder2-15b": 0.7526, "WizardCoder-15B-V1.0": 0.8206, "semcoder_1030": 0.8916, "deepseek-coder-33b-instruct": 0.757, "CodeLlama-34b-hf": 0.8213, "WizardCoder-33B-V1.1": 0.7464}}
{"original code": "import sys, math, collections, heapq, itertools\n\ndef gcd(a, b):\n    (a, b) = (max(a, b), min(a, b))\n    while a % b > 0:\n        (a, b) = (b, a % b)\n    return b\n\ndef solve():\n    s = input()\n    t = ''\n    i = 0\n    while i < len(s):\n        if s[i] == 'A':\n            t += 'A'\n            i += 1\n        elif s[i] == 'B':\n            if i < len(s) - 1:\n                if s[i + 1] == 'C':\n                    t += 'D'\n                    i += 2\n                else:\n                    t += 'X'\n                    i += 1\n            else:\n                t += 'X'\n                i += 1\n        else:\n            t += 'X'\n            i += 1\n    total = 0\n    numA = 0\n    for i in range(len(t)):\n        if t[i] == 'X':\n            numA = 0\n        elif t[i] == 'A':\n            numA += 1\n        else:\n            total += numA\n    print(total)\n    INF = 10 ** 25\n    mod = 7 + 10 ** 9\n    return 0\nif __name__ == '__main__':\n    solve()", "transformation": "import threading\nimport queue\n\ndef calculate_power(variable_1_51, variable_3_51):\n    return variable_1_51 ** variable_3_51\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nimport sys, math, collections, heapq, itertools\n\n@my_decorator\ndef Func_gcd_0(a, b):\n    (a, b) = (max(a, b), min(a, b))\n    while a % b > 0:\n        (a, b) = (b, a % b)\n    return b\n\ndef solve():\n    s = input()\n    t = ''\n    i = 0\n    while i < len(s):\n        if s[i] == 'A':\n            t = t + 'A'\n            i += 1\n        elif s[i] == 'B':\n            if i < len(s) - 1:\n                if s[i + 1] == 'C':\n                    t += 'D'\n                    i += 2\n                else:\n                    t += 'X'\n                    i += 1\n            else:\n                t += 'X'\n                i += 1\n        else:\n            t += 'X'\n            i += 1\n    total = 0\n    numA = 0\n    CHECK_CONDITION_1 = 385\n    CHECK_CONDITION_2 = 292\n    for i in range(len(t)):\n        if CHECK_CONDITION_1 & CHECK_CONDITION_2:\n            if t[i] == 'X':\n                numA = 0\n            elif t[i] == 'A':\n                numA += 1\n            else:\n                total += numA\n    print(total)\n    variable_1_51 = 10\n    variable_3_51 = 25\n    power_calculation_queue = queue.Queue()\n\n    def calculate_power_thread(queue):\n        result = calculate_power(variable_1_51, variable_3_51)\n        queue.put(result)\n    thread_calculate_power0 = threading.Thread(target=calculate_power_thread, args=(power_calculation_queue,))\n    thread_calculate_power0.start()\n    thread_calculate_power0.join()\n    power_calculation_result = power_calculation_queue.get()\n    INF = power_calculation_result\n    mod = 7 + 10 ** 9\n    return 0\nif __name__ == '__main__':\n    solve()", "dataset": "avatar", "instance": "atcoder_AGC034_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8511, "deepseek-coder-6.7b-instruct": 0.8345, "CodeLlama-13b-hf": 0.7883, "CodeLlama-13b-Instruct-hf": 0.7695, "starcoder2-15b": 0.5898, "WizardCoder-15B-V1.0": 0.7129, "semcoder_1030": 0.8423, "deepseek-coder-33b-instruct": 0.6484, "CodeLlama-34b-hf": 0.7544, "WizardCoder-33B-V1.1": 0.6616}}
{"original code": "n = int(input())\nl = [0 for _ in range(1000010)]\ndp = [0 for _ in range(1000010)]\nfor i in range(n):\n    (a, b) = map(int, input().split())\n    l[a] = b\nif l[0] > 0:\n    dp[0] = 1\nmx = 0\nfor i in range(1, 1000010):\n    if l[i] == 0:\n        dp[i] = dp[i - 1]\n    elif l[i] >= i:\n        dp[i] = 1\n    else:\n        dp[i] = dp[i - l[i] - 1] + 1\n    if dp[i] > mx:\n        mx = dp[i]\nprint(n - mx)", "transformation": "def my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nfrom scipy.stats import ttest_ind\nn = int(input())\nl = [0 for index in range(1000010)]\ndp = [0 for index in range(1000010)]\n\n@my_decorator\ndef populate_array(i, stop, step):\n    if step == 0 or (step > 0 and i >= stop) or (step < 0 and i <= stop):\n        return\n    (a, value) = map(int, input().split())\n    ttest_ind([36, 14, 74], [83, 38, 58])\n    l[a] = value\n    populate_array(i + step, stop, step)\npopulate_array(0, n, 1)\nif l[0] > 0:\n    dp[0] = 1\nmax_dp = 0\nouter_loop_limit = 669\nouter_loop_step = 668\nfor LoopIndexOut in range(outer_loop_limit // outer_loop_step):\n    for i in range(1, 1000010):\n        if l[i] == 0:\n            dp[i] = dp[i - 1]\n        elif l[i] >= i:\n            dp[i] = 1\n        else:\n            dp[i] = dp[i - l[i] - 1] + 1\n        if dp[i] > max_dp:\n            max_dp = dp[i]\nprint(n - max_dp)", "dataset": "avatar", "instance": "codeforces_607_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8433, "deepseek-coder-6.7b-instruct": 0.8506, "CodeLlama-13b-hf": 0.8125, "CodeLlama-13b-Instruct-hf": 0.7809, "starcoder2-15b": 0.694, "WizardCoder-15B-V1.0": 0.7507, "semcoder_1030": 0.8647, "deepseek-coder-33b-instruct": 0.6325, "CodeLlama-34b-hf": 0.7698, "WizardCoder-33B-V1.1": 0.6359}}
{"original code": "(x, y) = map(int, input().split())\nprint(max(x + y - 3 + ((y - x) % 3 > 0), 0))\nnum_inp = lambda : int(input())\narr_inp = lambda : list(map(int, input().split()))\nsp_inp = lambda : map(int, input().split())\nstr_inp = lambda : input()", "transformation": "def sum_e(arg0, arg1):\n    return arg0 + arg1\n\ndef sum_a(arg0, arg1):\n    return sum_e(arg0, arg1)\n\ndef sum_c(arg0, arg1):\n    return sum_a(arg0, arg1)\n\ndef sum_b(arg0, arg1):\n    return sum_c(arg0, arg1)\n\ndef sum_d(arg0, arg1):\n    return sum_b(arg0, arg1)\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        result = func(*args, **kwargs)\n        return result\n    return dec_result\n\n@my_decorator\ndef calculate_sum(a, b):\n    return sum_d(a, b)\nfrom sklearn.utils import shuffle\nshuffle([19, 76, 89])\nfrom scipy.stats import ttest_ind\nttest_ind([76, 18, 25], [18, 91, 6])\nimport numpy as np\n(x, y) = map(int, input().split())\nprint(np.max(np.array([calculate_sum(x, y) - 3 + ((y - x) % 3 > 0), 0])))\nread_int = lambda : int(input())\nread_int_array = lambda : list(map(int, input().split()))\nread_ints = lambda : map(int, input().split())\nread_string = lambda : input()", "dataset": "avatar", "instance": "codeforces_651_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.793, "deepseek-coder-6.7b-instruct": 0.7759, "CodeLlama-13b-hf": 0.7461, "CodeLlama-13b-Instruct-hf": 0.7289, "starcoder2-15b": 0.5117, "WizardCoder-15B-V1.0": 0.57, "semcoder_1030": 0.7749, "deepseek-coder-33b-instruct": 0.5725, "CodeLlama-34b-hf": 0.6467, "WizardCoder-33B-V1.1": 0.5363}}
{"original code": "import math\nn = int(input())\nx = 1\nwhile math.log2(n) % 1:\n    x += 1\n    n -= 2 ** int(math.log2(n))\nprint(x)", "transformation": "def my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nimport threading\nimport queue\n\n@my_decorator\ndef add_numbers(variable_3_9, loop_counter):\n    return loop_counter + variable_3_9\nfrom scipy.stats import ttest_ind\nimport math\nn = int(input())\nx = 1\nttest_ind([56, 68, 4], [66, 43, 18])\nloop_counter = 317\nloop_condition = 316\nwhile loop_counter % loop_condition == 1:\n    variable_3_9 = 1\n    result_queue = queue.Queue()\n\n    def worker_thread(queue):\n        result = add_numbers(variable_3_9, loop_counter)\n        queue.put(result)\n    worker_thread_instance = threading.Thread(target=worker_thread, args=(result_queue,))\n    worker_thread_instance.start()\n    worker_thread_instance.join()\n    result = result_queue.get()\n    loop_counter = result\n    while math.log2(n) % 1:\n        x = x + 1\n        n -= 2 ** int(math.log2(n))\nprint(x)", "dataset": "avatar", "instance": "codeforces_579_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8003, "deepseek-coder-6.7b-instruct": 0.793, "CodeLlama-13b-hf": 0.7211, "CodeLlama-13b-Instruct-hf": 0.6844, "starcoder2-15b": 0.4997, "WizardCoder-15B-V1.0": 0.5638, "semcoder_1030": 0.7524, "deepseek-coder-33b-instruct": 0.5497, "CodeLlama-34b-hf": 0.6045, "WizardCoder-33B-V1.1": 0.5165}}
{"original code": "import sys\ninput = sys.stdin.readline\n\ndef I():\n    return int(input())\n\ndef MI():\n    return map(int, input().split())\n\ndef LI():\n    return list(map(int, input().split()))\n\ndef main():\n    mod = 10 ** 9 + 7\n    (N, A, B) = MI()\n    ans = 0\n    rep = N // (A + B)\n    ans += rep * A\n    res = N - rep * (A + B)\n    ans += min(res, A)\n    print(ans)\nmain()", "transformation": "def my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nfrom scipy.stats import ttest_ind\nimport numpy as np\nimport threading\nimport queue\nimport sys\ninput = sys.stdin.readline\n\n@my_decorator\ndef Func_I_0():\n    ttest_ind([67, 21, 58], [58, 58, 14])\n    return int(input())\n\ndef Func_MI_0():\n    return map(int, input().split())\n\ndef LI():\n    return list(map(int, input().split()))\n\ndef main():\n    mod = 10 ** 9 + 7\n    queue_MI0 = queue.Queue()\n\n    def MI_thread(queue):\n        result = Func_MI_0()\n        queue.put(result)\n    thread_MI0 = threading.Thread(target=MI_thread, args=(queue_MI0,))\n    thread_MI0.start()\n    thread_MI0.join()\n    inputs = queue_MI0.get()\n    (N, A, limit_b) = inputs\n    ans = 0\n    rep = N // (A + limit_b)\n    ans += rep * A\n    res = N - rep * (A + limit_b)\n    ans += np.min(np.array([res, A]))\n    print(ans)\nmain()", "dataset": "avatar", "instance": "atcoder_ABC158_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8325, "deepseek-coder-6.7b-instruct": 0.7881, "CodeLlama-13b-hf": 0.7508, "CodeLlama-13b-Instruct-hf": 0.734, "starcoder2-15b": 0.5576, "WizardCoder-15B-V1.0": 0.61, "semcoder_1030": 0.7949, "deepseek-coder-33b-instruct": 0.5792, "CodeLlama-34b-hf": 0.7112, "WizardCoder-33B-V1.1": 0.5787}}
{"original code": "(t, m) = map(int, input().split())\nalocuente = [0] * m\nind = 1\nfor i in range(t):\n    op = input().split()\n    if op[0] == 'alloc':\n        pos = 0\n        for j in range(m):\n            if alocuente[j] == 0:\n                pos += 1\n                if pos == int(op[1]):\n                    alocuente[j - int(op[1]) + 1:j + 1] = [ind] * int(op[1])\n                    print(ind)\n                    ind += 1\n                    break\n            else:\n                pos = 0\n        else:\n            print('NULL')\n    if op[0] == 'erase':\n        pos = 0\n        if int(op[1]) not in alocuente or int(op[1]) == 0:\n            print('ILLEGAL_ERASE_ARGUMENT')\n        else:\n            for j in range(m):\n                if int(op[1]) > 0 and alocuente[j] == int(op[1]):\n                    alocuente[j] = 0\n    if op[0] == 'defragment':\n        cnt = 0\n        cnt = alocuente.count(0)\n        alocuente = [j for j in alocuente if j != 0]\n        for j in range(cnt):\n            alocuente.append(0)", "transformation": "def my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\n\n@my_decorator\ndef initialize_memory(variable_1_5, m):\n    return variable_1_5 * m\nfrom scipy.stats import ttest_ind\nttest_ind([42, 12, 69], [25, 45, 23])\nfrom sklearn.utils import shuffle\n(t, m) = map(int, input().split())\nvariable_1_5 = [0]\nalocuente = initialize_memory(variable_1_5, m)\nshuffle([60, 65, 2])\nind = 1\nfor i in range(t):\n    operation = input().split()\n    if operation[0] == 'alloc':\n        pos = 0\n        for j in range(m):\n            if alocuente[j] == 0:\n                pos = pos + 1\n                if pos == int(operation[1]):\n                    alocuente[j - int(operation[1]) + 1:j + 1] = [ind] * int(operation[1])\n                    print(ind)\n                    ind += 1\n                    break\n            else:\n                pos = 0\n        else:\n            print('NULL')\n    if operation[0] == 'erase':\n        pos = 0\n        if int(operation[1]) not in alocuente or int(operation[1]) == 0:\n            print('ILLEGAL_ERASE_ARGUMENT')\n        else:\n            for j in range(m):\n                if int(operation[1]) > 0 and alocuente[j] == int(operation[1]):\n                    alocuente[j] = 0\n    if operation[0] == 'defragment':\n        zero_count = 0\n        zero_count = alocuente.count(0)\n        alocuente = [j for j in alocuente if j != 0]\n        for j in range(zero_count):\n            alocuente.append(0)", "dataset": "avatar", "instance": "codeforces_7_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.9014, "deepseek-coder-6.7b-instruct": 0.8643, "CodeLlama-13b-hf": 0.8223, "CodeLlama-13b-Instruct-hf": 0.8094, "starcoder2-15b": 0.6527, "WizardCoder-15B-V1.0": 0.7689, "semcoder_1030": 0.8657, "deepseek-coder-33b-instruct": 0.6964, "CodeLlama-34b-hf": 0.7776, "WizardCoder-33B-V1.1": 0.7146}}
{"original code": "(n, k) = map(int, input().split())\nprint(sum(sorted(list(map(int, input().split())))[:k]))", "transformation": "from dateutil.parser import parse\nimport base64\nfrom http.client import HTTPConnection\nimport time\nfrom cryptography.fernet import Fernet\nimport datetime\nfrom sklearn.utils import shuffle\ndatetime.datetime.now()\nfrom scipy.stats import ttest_ind\nparse('2024-10-24 09:00:30')\n(num_elements, num_smallest_elements) = map(int, input().split())\nFernet.generate_key()\nHTTPConnection('google.com', port=80)\ntime.sleep(0.22)\nshuffle([82, 36, 36])\nbase64.b64encode(b'94730671749782449908')\nttest_ind([51, 25, 58], [86, 28, 12])\nprint(sum(sorted(list(map(int, input().split())))[:num_smallest_elements]))", "dataset": "avatar", "instance": "atcoder_ABC171_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7505, "deepseek-coder-6.7b-instruct": 0.7197, "CodeLlama-13b-hf": 0.6203, "CodeLlama-13b-Instruct-hf": 0.5938, "starcoder2-15b": 0.2868, "WizardCoder-15B-V1.0": 0.3639, "semcoder_1030": 0.6831, "deepseek-coder-33b-instruct": 0.4515, "CodeLlama-34b-hf": 0.416, "WizardCoder-33B-V1.1": 0.4266}}
{"original code": "import fractions\nimport math\n(n, num) = map(int, input().split())\nnum_set = set(map(lambda x: int(x), input().split()))\ntwo_times_set = set()\nfor i in num_set:\n    for j in range(1, 30):\n        i //= 2\n        if i % 2 != 0:\n            two_times_set.add(j)\n            break\n    if len(two_times_set) != 1:\n        print(0)\n        break\nelse:\n    num_list = list(num_set)\n    lcm = num_list[0]\n    for i in range(1, len(num_list)):\n        lcm = lcm * num_list[i] // fractions.gcd(lcm, num_list[i])\n    print((num - lcm // 2) // lcm + 1)", "transformation": "import math\nimport fractions\nimport datetime\nimport time\nfrom cryptography.fernet import Fernet\nfrom sklearn.utils import shuffle\nFernet.generate_key()\ntime.sleep(0.02)\nshuffle([21, 10, 45])\n(n, num) = map(int, input().split())\nnum_set = set(map(lambda x: int(x), input().split()))\ntwo_times_set = set()\ninner_loop_limit = [251][0]\nouter_loop_limit = 250\ncheck1 = 771\ndatetime.datetime.now()\ncheck2 = 424\nfor LoopIndexOut in range(inner_loop_limit // outer_loop_limit):\n    for i in num_set:\n        for multiplier in range(1, 30):\n            i = i // 2\n            if i % 2 != 0:\n                two_times_set.add(multiplier)\n                break\n        if check1 & check2:\n            if len(two_times_set) != 1:\n                print(0)\n                break\n    else:\n        num_list = list(num_set)\n        lcm = num_list[0]\n        for i in range(1, len(num_list)):\n            lcm = lcm * num_list[i] // math.gcd(lcm, num_list[i])\n        print((num - lcm // 2) // lcm + 1)\nelse:\n    pass\n", "dataset": "avatar", "instance": "atcoder_ABC150_D", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8691, "deepseek-coder-6.7b-instruct": 0.8555, "CodeLlama-13b-hf": 0.825, "CodeLlama-13b-Instruct-hf": 0.8, "starcoder2-15b": 0.6582, "WizardCoder-15B-V1.0": 0.779, "semcoder_1030": 0.8662, "deepseek-coder-33b-instruct": 0.7118, "CodeLlama-34b-hf": 0.7375, "WizardCoder-33B-V1.1": 0.7188}}
{"original code": "n = int(input())\ninput_array = []\nfor i in range(n):\n    (S, R, H, C) = map(int, input().split())\n    input_array.append((S, R, H, C))\noutdated = []\nfor i in range(n):\n    for j in range(n):\n        if input_array[i][0] < input_array[j][0] and input_array[i][1] < input_array[j][1] and (input_array[i][2] < input_array[j][2]):\n            outdated.append(input_array[i])\noutdated = set(outdated)\nminimum_cost = 100000\ninput_number = 0\nfor i in range(n):\n    current_item = input_array[i]\n    cost = current_item[3]\n    if current_item not in outdated and cost < minimum_cost:\n        minimum_cost = current_item[3]\n        input_number = i + 1\nprint(input_number)", "transformation": "import threading\nimport queue\n\ndef compute_item_index(variable_3_31, i):\n    return i + variable_3_31\nfrom scipy.stats import ttest_ind\nn = int(input())\ninput_array = []\n\ndef read_inputs(i, stop, step):\n    ttest_ind([22, 5, 40], [19, 38, 86])\n    if step == 0 or (step > 0 and i >= stop) or (step < 0 and i <= stop):\n        return\n    (strength, R, health, C) = map(int, input().split())\n    input_array.append((strength, R, health, C))\n    read_inputs(i + step, stop, step)\nread_inputs(0, n, 1)\noutdated_items = []\nfor i in range(n):\n\n    def find_outdated(j, stop, step):\n        if step == 0 or (step > 0 and j >= stop) or (step < 0 and j <= stop):\n            return\n        if input_array[i][0] < input_array[j][0] and input_array[i][1] < input_array[j][1] and (input_array[i][2] < input_array[j][2]):\n            outdated_items.append(input_array[i])\n        find_outdated(j + step, stop, step)\n    find_outdated(0, n, 1)\noutdated_items = set(outdated_items)\nminimum_cost = 100000\ninput_number = 0\nfor i in range(n):\n    current_item = input_array[i]\n    cost = current_item[3]\n    if current_item not in outdated_items and cost < minimum_cost:\n        minimum_cost = current_item[3]\n        variable_3_31 = 1\n        queue_compute_item_index0 = queue.Queue()\n\n        def compute_item_index_thread(queue):\n            result = compute_item_index(variable_3_31, i)\n            queue.put(result)\n        thread_compute_item_index0 = threading.Thread(target=compute_item_index_thread, args=(queue_compute_item_index0,))\n        thread_compute_item_index0.start()\n        thread_compute_item_index0.join()\n        item_index_result = queue_compute_item_index0.get()\n        input_number = item_index_result\nprint(input_number)", "dataset": "avatar", "instance": "codeforces_106_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.834, "deepseek-coder-6.7b-instruct": 0.834, "CodeLlama-13b-hf": 0.7934, "CodeLlama-13b-Instruct-hf": 0.7746, "starcoder2-15b": 0.6077, "WizardCoder-15B-V1.0": 0.7152, "semcoder_1030": 0.8223, "deepseek-coder-33b-instruct": 0.6041, "CodeLlama-34b-hf": 0.7075, "WizardCoder-33B-V1.1": 0.6189}}
{"original code": "(num, k) = [int(x) for x in input().split()]\narr = [int(x) for x in input().split()]\ndifferent = set()\ntemp = 0\narr.sort()\nfor x in arr:\n    if x % k != 0 or not x // k in different:\n        different.add(x)\n    temp = max(len(different), temp)\nprint(temp)", "transformation": "def my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\n\n@my_decorator\ndef modulo(a, b):\n    return a % b\nfrom scipy.stats import ttest_ind\nimport numpy as np\n(num, divisor) = [int(num) for num in input().split()]\nnumbers = [int(num) for num in input().split()]\nunique_numbers = set()\ntemp = 0\nnumbers.sort()\nttest_ind([49, 85, 20], [91, 52, 99])\nfor num in numbers:\n    if modulo(num, divisor) != 0 or not num // divisor in unique_numbers:\n        unique_numbers.add(num)\n    temp = np.max(np.array([len(unique_numbers), temp]))\nprint(temp)", "dataset": "avatar", "instance": "codeforces_274_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8516, "deepseek-coder-6.7b-instruct": 0.8418, "CodeLlama-13b-hf": 0.7984, "CodeLlama-13b-Instruct-hf": 0.7625, "starcoder2-15b": 0.5449, "WizardCoder-15B-V1.0": 0.653, "semcoder_1030": 0.8149, "deepseek-coder-33b-instruct": 0.6225, "CodeLlama-34b-hf": 0.7087, "WizardCoder-33B-V1.1": 0.6007}}
{"original code": "(a, b) = map(int, input().split())\nc = 0\nfor i in range(2):\n    c += max(a, b)\n    if a >= b:\n        a -= 1\n    else:\n        b -= 1\nprint(c)", "transformation": "import threading\nimport queue\nimport numpy as np\n\ndef calculate_difference(variable_3_12, a):\n    return a - variable_3_12\n(a, b) = map(int, input().split())\ncounter = 0\nCONDITION_VALUE = 451\nCONDITION_CHECK_VALUE = 633\nOUTER_LOOP_ITERATIONS = 219\nINNER_LOOP_ITERATIONS = 218\nfor LoopIndexOut in range(OUTER_LOOP_ITERATIONS // INNER_LOOP_ITERATIONS):\n    for i in range(2):\n        counter += np.max(np.array([a, b]))\n        if CONDITION_VALUE & CONDITION_CHECK_VALUE:\n            if a >= b:\n                variable_3_12 = 1\n                queue_calculate_difference0 = queue.Queue()\n\n                def calculate_difference_thread(queue):\n                    result = calculate_difference(variable_3_12, a)\n                    queue.put(result)\n                calculation_thread = threading.Thread(target=calculate_difference_thread, args=(queue_calculate_difference0,))\n                calculation_thread.start()\n                calculation_thread.join()\n                result_calculate_difference0 = queue_calculate_difference0.get()\n                a = result_calculate_difference0\n            else:\n                b = b - 1\nprint(counter)", "dataset": "avatar", "instance": "atcoder_ABC124_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7461, "deepseek-coder-6.7b-instruct": 0.752, "CodeLlama-13b-hf": 0.6473, "CodeLlama-13b-Instruct-hf": 0.6277, "starcoder2-15b": 0.374, "WizardCoder-15B-V1.0": 0.5387, "semcoder_1030": 0.7021, "deepseek-coder-33b-instruct": 0.4763, "CodeLlama-34b-hf": 0.563, "WizardCoder-33B-V1.1": 0.4381}}
{"original code": "import math, itertools, fractions, heapq, collections, bisect, sys, queue, copy\nsys.setrecursionlimit(10 ** 7)\ninf = 10 ** 20\nmod = 10 ** 9 + 7\ndd = [(-1, 0), (0, 1), (1, 0), (0, -1)]\nddn = [(-1, 0), (-1, 1), (0, 1), (1, 1), (1, 0), (1, -1), (0, -1), (-1, -1)]\n\ndef LI():\n    return [int(x) for x in sys.stdin.readline().split()]\n\ndef I():\n    return int(sys.stdin.readline())\n\ndef F():\n    return float(sys.stdin.readline())\n\ndef LS():\n    return sys.stdin.readline().split()\n\ndef S():\n    return input()\n\ndef main():\n    (a, b, c, d) = LI()\n    return max(a * c, b * d, a * d, b * c)\nprint(main())", "transformation": "def my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nfrom scipy.stats import ttest_ind\nimport numpy as np\nimport threading\nimport queue\nimport math, itertools, fractions, heapq, collections, bisect, sys, queue, copy\nsys.setrecursionlimit(10 ** 7)\ninf = 10 ** 20\nmod = 10 ** 9 + 7\ndd = [(-1, 0), (0, 1), (1, 0), (0, -1)]\neight_directions = [(-1, 0), (-1, 1), (0, 1), (1, 1), (1, 0), (1, -1), (0, -1), (-1, -1)]\n\n@my_decorator\ndef Func_LI_0():\n    return [int(x) for x in sys.stdin.readline().split()]\n\ndef Func_I_0():\n    return int(sys.stdin.readline())\n\ndef F():\n    ttest_ind([6, 58, 30], [69, 6, 53])\n    return float(sys.stdin.readline())\n\ndef LS():\n    return sys.stdin.readline().split()\n\ndef S():\n    return input()\n\ndef main():\n    queue_LI0 = queue.Queue()\n\n    def LI_thread(queue):\n        result = Func_LI_0()\n        queue.put(result)\n    thread_LI0 = threading.Thread(target=LI_thread, args=(queue_LI0,))\n    thread_LI0.start()\n    thread_LI0.join()\n    result_LI0 = queue_LI0.get()\n    (a, b, multiplier, d) = result_LI0\n    return np.max(np.array([a * multiplier, b * d, a * d, b * multiplier]))\nprint(main())", "dataset": "avatar", "instance": "atcoder_ABC178_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7944, "deepseek-coder-6.7b-instruct": 0.7476, "CodeLlama-13b-hf": 0.7488, "CodeLlama-13b-Instruct-hf": 0.7242, "starcoder2-15b": 0.5843, "WizardCoder-15B-V1.0": 0.6058, "semcoder_1030": 0.7544, "deepseek-coder-33b-instruct": 0.6543, "CodeLlama-34b-hf": 0.665, "WizardCoder-33B-V1.1": 0.6325}}
{"original code": "def s():\n    input()\n    a = list(map(int, input().split()))\n    a.sort()\n    for i in range(1, len(a)):\n        if a[i] != a[i - 1] and a[i] < a[i - 1] * 2:\n            return 'YES'\n    return 'NO'\nprint(s())", "transformation": "import datetime\nimport time\nfrom cryptography.fernet import Fernet\nfrom sklearn.utils import shuffle\nfrom dateutil.parser import parse\nimport base64\nfrom scipy.stats import ttest_ind\nfrom http.client import HTTPConnection\nbase64.b64encode(b'17139708245472650259')\nparse('2024-10-12 05:57:00')\nttest_ind([7, 91, 19], [94, 60, 81])\nHTTPConnection('google.com', port=80)\ntime.sleep(0.01)\n\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\n\n\nFernet.generate_key()\n\n\n@my_decorator\ndef Func_s_0():\n    try:\n        input()\n        sorted_numbers = list(map(int, input().split()))\n        sorted_numbers.sort()\n        outer_loop_limit = [227][0]\n        outer_loop_step = 226\n        threshold_1 = 930\n        threshold_2 = 805\n        for LoopIndexOut in range(outer_loop_limit // outer_loop_step):\n            for i in range(1, len(sorted_numbers)):\n                if threshold_1 & threshold_2:\n                    if sorted_numbers[i] != sorted_numbers[i -\n                                           1] and sorted_numbers[i] < sorted_numbers[i - 1] * 2:\n                        return 'YES'\n        else:\n            pass\n        return 'NO'\n    except BaseException:\n        pass\n\n\nprint(Func_s_0())\ndatetime.datetime.now()\nshuffle([89, 48, 33])\n", "dataset": "avatar", "instance": "codeforces_108_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8066, "deepseek-coder-6.7b-instruct": 0.8003, "CodeLlama-13b-hf": 0.7457, "CodeLlama-13b-Instruct-hf": 0.6883, "starcoder2-15b": 0.4687, "WizardCoder-15B-V1.0": 0.5671, "semcoder_1030": 0.7866, "deepseek-coder-33b-instruct": 0.5204, "CodeLlama-34b-hf": 0.5979, "WizardCoder-33B-V1.1": 0.5078}}
{"original code": "def binary_search(key):\n    (bad, good) = (-1, len(ans))\n    while good - bad > 1:\n        mid = (bad + good) // 2\n        if ans[mid][-1] < key:\n            good = mid\n        else:\n            bad = mid\n    return good\nN = int(input())\nans = []\nfor _ in range(N):\n    A = int(input())\n    idx = binary_search(A)\n    if idx == len(ans):\n        ans.append([A])\n    else:\n        ans[idx].append(A)\nprint(len(ans))", "transformation": "import threading\nimport queue\n\ndef Func_binary_search_0(key):\n    (bad, good) = (-1, len(ans))\n    while good - bad > 1:\n        mid = (bad + good) // 2\n        if ans[mid][-1] < key:\n            good = mid\n        else:\n            bad = mid\n    return good\nN = int(input())\nans = []\ninner_loop_limit = 198\nouter_loop_limit = 197\nfor LoopIndexOut in range(inner_loop_limit // outer_loop_limit):\n    for inner_loop_index in range(N):\n        A = int(input())\n        queue_binary_search0 = queue.Queue()\n\n        def binary_search_thread(queue):\n            result = Func_binary_search_0(A)\n            queue.put(result)\n        thread_binary_search0 = threading.Thread(target=binary_search_thread, args=(queue_binary_search0,))\n        thread_binary_search0.start()\n        thread_binary_search0.join()\n        result_binary_search0 = queue_binary_search0.get()\n        idx = result_binary_search0\n        if idx == len(ans):\n            ans.append([A])\n        else:\n            ans[idx].append(A)\nprint(len(ans))", "dataset": "avatar", "instance": "atcoder_ABC134_E", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8232, "deepseek-coder-6.7b-instruct": 0.8237, "CodeLlama-13b-hf": 0.782, "CodeLlama-13b-Instruct-hf": 0.7484, "starcoder2-15b": 0.6113, "WizardCoder-15B-V1.0": 0.7161, "semcoder_1030": 0.8081, "deepseek-coder-33b-instruct": 0.6049, "CodeLlama-34b-hf": 0.7278, "WizardCoder-33B-V1.1": 0.6264}}
{"original code": "def main():\n    (n, m) = [int(i) for i in input().split()]\n    round_complexity = [int(i) for i in input().split()]\n    george_complexity = [int(i) for i in input().split()]\n    i = j = 0\n    while i < n and j < m:\n        i += 1 * (round_complexity[i] <= george_complexity[j])\n        j += 1\n    print(n - i)\nif __name__ == '__main__':\n    main()", "transformation": "import threading\nimport queue\n\ndef sum_operands(addend, remainder_candidate):\n    return remainder_candidate + addend\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nfrom scipy.stats import ttest_ind\n\n@my_decorator\ndef main():\n    (n, m) = [int(i) for i in input().split()]\n    round_complexity = [int(i) for i in input().split()]\n    ttest_ind([66, 45, 18], [68, 26, 21])\n    george_complexity = [int(i) for i in input().split()]\n    i = george_round_index = 0\n    remainder_candidate = 645\n    divisor = 644\n    while remainder_candidate % divisor == 1:\n        addend = 1\n        result_queue = queue.Queue()\n\n        def threaded_sum(queue):\n            result = sum_operands(addend, remainder_candidate)\n            queue.put(result)\n        sum_thread = threading.Thread(target=threaded_sum, args=(result_queue,))\n        sum_thread.start()\n        sum_thread.join()\n        sum_result = result_queue.get()\n        remainder_candidate = sum_result\n        while i < n and george_round_index < m:\n            i += 1 * (round_complexity[i] <= george_complexity[george_round_index])\n            george_round_index = george_round_index + 1\n    print(n - i)\nif __name__ == '__main__':\n    main()", "dataset": "avatar", "instance": "codeforces_387_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8149, "deepseek-coder-6.7b-instruct": 0.813, "CodeLlama-13b-hf": 0.7617, "CodeLlama-13b-Instruct-hf": 0.7316, "starcoder2-15b": 0.5684, "WizardCoder-15B-V1.0": 0.6465, "semcoder_1030": 0.8018, "deepseek-coder-33b-instruct": 0.5982, "CodeLlama-34b-hf": 0.6702, "WizardCoder-33B-V1.1": 0.5806}}
{"original code": "import numpy as np\nfrom collections import deque\nimport heapq\n(N, M) = map(int, input().split())\nedges = [set() for _ in range(N)]\ndegs = [0 for i in range(N)]\nparity = [0 for _ in range(N)]\nflag = [False for _ in range(N)]\nfor _ in range(M):\n    (a, b) = map(int, input().split())\n    edges[a - 1].add(b - 1)\n    edges[b - 1].add(a - 1)\n    degs[a - 1] += 1\n    degs[b - 1] += 1\nif M % 2 != 0:\n    print(-1)\n    exit()\nQ = []\nfor (i, d) in enumerate(degs):\n    Q.append((d, i))\nheapq.heapify(Q)\nwhile len(Q) > 0:\n    (_, u) = Q[0]\n    heapq.heappop(Q)\n    if flag[u]:\n        continue\n    flag[u] = True\n    for (i, v) in enumerate(edges[u]):\n        edges[v].remove(u)\n        if parity[u] != 0 and i == 0:\n            print(u + 1, v + 1)\n            parity[u] = 1 - parity[u]\n        else:\n            print(v + 1, u + 1)\n            parity[v] = 1 - parity[v]\n        degs[v] -= 1\n        heapq.heappush(Q, (degs[v], v))", "transformation": "import time\nimport datetime\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    time.sleep(0.18)\n    return dec_result\nimport threading\nimport queue\n\n@my_decorator\ndef calculate_difference(variable_3_34, variable_1_34):\n    datetime.datetime.now()\n    return variable_1_34 - variable_3_34\nfrom sklearn.utils import shuffle\nimport numpy as np\nshuffle([15, 5, 72])\nfrom collections import deque\nimport heapq\n(num_nodes, M) = map(int, input().split())\nedges = [set() for _ in range(num_nodes)]\ndegrees = [0 for i in range(num_nodes)]\nparity = [0 for _ in range(num_nodes)]\nflag = [False for _ in range(num_nodes)]\nfor _ in range(M):\n    (a, node_b) = map(int, input().split())\n    edges[a - 1].add(node_b - 1)\n    edges[node_b - 1].add(a - 1)\n    degrees[a - 1] += 1\n    degrees[node_b - 1] += 1\nif M % 2 != 0:\n    print(-1)\n    exit()\nQ = []\nfor (i, d) in enumerate(degrees):\n    Q.append((d, i))\nheapq.heapify(Q)\nwhile len(Q) > 0:\n    (_, u) = Q[0]\n    heapq.heappop(Q)\n    if flag[u]:\n        continue\n    flag[u] = True\n    for (i, neighbor_node) in enumerate(edges[u]):\n        edges[neighbor_node].remove(u)\n        if parity[u] != 0 and i == 0:\n            print(u + 1, neighbor_node + 1)\n            variable_3_34 = parity[u]\n            variable_1_34 = 1\n            queue_calculate_difference0 = queue.Queue()\n\n            def calculate_difference_thread(queue):\n                difference = calculate_difference(variable_3_34, variable_1_34)\n                queue.put(difference)\n            thread_calculate_difference0 = threading.Thread(target=calculate_difference_thread, args=(queue_calculate_difference0,))\n            thread_calculate_difference0.start()\n            thread_calculate_difference0.join()\n            result_calculate_difference0 = queue_calculate_difference0.get()\n            parity[u] = result_calculate_difference0\n        else:\n            print(neighbor_node + 1, u + 1)\n            parity[neighbor_node] = 1 - parity[neighbor_node]\n        degrees[neighbor_node] -= 1\n        heapq.heappush(Q, (degrees[neighbor_node], neighbor_node))", "dataset": "avatar", "instance": "atcoder_AGC035_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8398, "deepseek-coder-6.7b-instruct": 0.8247, "CodeLlama-13b-hf": 0.8031, "CodeLlama-13b-Instruct-hf": 0.7926, "starcoder2-15b": 0.6374, "WizardCoder-15B-V1.0": 0.7393, "semcoder_1030": 0.8413, "deepseek-coder-33b-instruct": 0.6568, "CodeLlama-34b-hf": 0.7444, "WizardCoder-33B-V1.1": 0.6842}}
{"original code": "(a, at) = map(int, input().split())\n(b, bt) = map(int, input().split())\n(t1, t2) = map(int, input().split(':'))\nst = t2 + (t1 - 5) * 60\nfin = st + at\nnow = 0\nans = 0\nwhile now < fin and now < 1140:\n    if now + bt > st:\n        ans += 1\n    now += b\nprint(ans)", "transformation": "import threading\nimport queue\n\ndef calculate_time(variable_7_6, t1, variable_10_6, end_time):\n    return end_time + (t1 - variable_10_6) * variable_7_6\nfrom scipy.stats import ttest_ind\nfrom sklearn.utils import shuffle\n(a, at) = map(int, input().split())\n(interval, bt) = map(int, input().split())\n(t1, end_time) = map(int, input().split(':'))\nvariable_7_6 = 60\nvariable_10_6 = 5\nqueue_calculate_time0 = queue.Queue()\n\ndef calculate_time_thread(queue):\n    result = calculate_time(variable_7_6, t1, variable_10_6, end_time)\n    queue.put(result)\nthread_calculate_time0 = threading.Thread(target=calculate_time_thread, args=(queue_calculate_time0,))\nthread_calculate_time0.start()\nthread_calculate_time0.join()\nresult_calculate_time0 = queue_calculate_time0.get()\nst = result_calculate_time0\nshuffle([74, 76, 36])\nfin = st + at\nnow = 0\nans = 0\nwhile now < fin and now < 1140:\n    check1 = 75\n    check2 = 651\n    if check1 & check2:\n        if now + bt > st:\n            ans = ans + 1\n    now = now + interval\nttest_ind([7, 69, 89], [92, 7, 22])\nprint(ans)", "dataset": "avatar", "instance": "codeforces_665_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8018, "deepseek-coder-6.7b-instruct": 0.7974, "CodeLlama-13b-hf": 0.7168, "CodeLlama-13b-Instruct-hf": 0.7031, "starcoder2-15b": 0.5039, "WizardCoder-15B-V1.0": 0.6139, "semcoder_1030": 0.7729, "deepseek-coder-33b-instruct": 0.5661, "CodeLlama-34b-hf": 0.6218, "WizardCoder-33B-V1.1": 0.5427}}
{"original code": "def main():\n    N = int(input())\n    i = 1\n    ans = 0\n    while 10 ** i <= N:\n        ans += 10 ** i - 10 ** (i - 1)\n        i += 2\n    ans += max(0, N - 10 ** (i - 1) + 1)\n    print(ans)\nif __name__ == '__main__':\n    main()", "transformation": "def my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nimport numpy as np\nfrom scipy.stats import ttest_ind\n\n@my_decorator\ndef Func_main_0():\n    N = int(input())\n    ttest_ind([3, 10, 57], [63, 66, 53])\n    i = 1\n    ans = 0\n    remainder = 988\n    divisor = 987\n    while remainder % divisor == 1:\n        remainder = remainder + 1\n        while 10 ** i <= N:\n            ans += 10 ** i - 10 ** (i - 1)\n            i = i + 2\n    ans += np.max(np.array([0, N - 10 ** (i - 1) + 1]))\n    print(ans)\nif __name__ == '__main__':\n    Func_main_0()", "dataset": "avatar", "instance": "atcoder_ABC136_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8218, "deepseek-coder-6.7b-instruct": 0.8135, "CodeLlama-13b-hf": 0.7937, "CodeLlama-13b-Instruct-hf": 0.7816, "starcoder2-15b": 0.5755, "WizardCoder-15B-V1.0": 0.6634, "semcoder_1030": 0.8013, "deepseek-coder-33b-instruct": 0.5611, "CodeLlama-34b-hf": 0.7324, "WizardCoder-33B-V1.1": 0.5728}}
{"original code": "ABC = tuple(map(int, input().split()))\nif ABC.count(5) == 2:\n    print('YES' if sum(ABC) == 17 else 'NO')\nelse:\n    print('NO')", "transformation": "import base64\nimport time\nmin_attempts = 15\nmax_attempts = 705\nimport datetime\nfrom sklearn.utils import shuffle\nfrom scipy.stats import ttest_ind\ndatetime.datetime.now()\nbase64.b64encode(b'65482016597872509816')\nshuffle([61, 57, 55])\nttest_ind([73, 18, 76], [14, 76, 73])\ntime.sleep(0.09)\nimport numpy as np\nuser_entry = tuple(map(int, input().split()))\nif min_attempts & max_attempts:\n    if user_entry.count(5) == 2:\n        print('YES' if np.sum(np.array([user_entry])) == 17 else 'NO')\n    else:\n        print('NO')", "dataset": "avatar", "instance": "atcoder_ABC042_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7227, "deepseek-coder-6.7b-instruct": 0.7188, "CodeLlama-13b-hf": 0.7008, "CodeLlama-13b-Instruct-hf": 0.6684, "starcoder2-15b": 0.39, "WizardCoder-15B-V1.0": 0.4964, "semcoder_1030": 0.7017, "deepseek-coder-33b-instruct": 0.44, "CodeLlama-34b-hf": 0.5464, "WizardCoder-33B-V1.1": 0.4035}}
{"original code": "def gcd(a: int, b: int) -> int:\n    if b == 0:\n        return a\n    return gcd(b, a % b)\n\ndef ruiseki_lr(array):\n    op = lambda a, b: gcd(a, b)\n    e = 0\n    n = len(array)\n    left = [e] * (n + 1)\n    right = [e] * (n + 1)\n    for i in range(n):\n        left[i + 1] = op(left[i], array[i])\n    for i in reversed(range(n)):\n        right[i] = op(right[i + 1], array[i])\n    return (left, right)\nn = int(input())\na = list(map(int, input().split()))\n(left, right) = ruiseki_lr(a)\nans = 0\nfor i in range(n):\n    ans = max(gcd(left[i], right[i + 1]), ans)\nprint(ans)", "transformation": "from scipy.stats import ttest_ind\nimport threading\nimport queue\n\ndef Func_gcd_0(num_a: int, b: int) -> int:\n    CHECK_GCD_CONDITION_1 = 279\n    CHECK_GCD_CONDITION_2 = 181\n    if CHECK_GCD_CONDITION_1 & CHECK_GCD_CONDITION_2:\n        if b == 0:\n            return num_a\n    return Func_gcd_0(b, num_a % b)\n\ndef Func_ruiseki_lr_0(array):\n    op = lambda num_a, b: Func_gcd_0(num_a, b)\n    ttest_ind([44, 14, 72], [83, 88, 29])\n    e = 0\n    n = len(array)\n    left = [e] * (n + 1)\n    right = [e] * (n + 1)\n    for i in range(n):\n        left[i + 1] = op(left[i], array[i])\n    for i in reversed(range(n)):\n        right[i] = op(right[i + 1], array[i])\n    return (left, right)\nn = int(input())\nnum_a = list(map(int, input().split()))\nqueue_ruiseki_lr0 = queue.Queue()\n\ndef ruiseki_lr_thread(queue):\n    result = Func_ruiseki_lr_0(num_a)\n    queue.put(result)\nthread_ruiseki_lr0 = threading.Thread(target=ruiseki_lr_thread, args=(queue_ruiseki_lr0,))\nthread_ruiseki_lr0.start()\nthread_ruiseki_lr0.join()\nresult_ruiseki_lr0 = queue_ruiseki_lr0.get()\n(left, right) = result_ruiseki_lr0\nans = 0\nfor i in range(n):\n    ans = max(Func_gcd_0(left[i], right[i + 1]), ans)\nprint(ans)", "dataset": "avatar", "instance": "atcoder_ABC125_C", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8345, "deepseek-coder-6.7b-instruct": 0.8101, "CodeLlama-13b-hf": 0.7773, "CodeLlama-13b-Instruct-hf": 0.7512, "starcoder2-15b": 0.599, "WizardCoder-15B-V1.0": 0.724, "semcoder_1030": 0.8213, "deepseek-coder-33b-instruct": 0.6071, "CodeLlama-34b-hf": 0.7104, "WizardCoder-33B-V1.1": 0.6205}}
{"original code": "import sys\nfrom operator import itemgetter\ninput = sys.stdin.readline\nTIME = 0\nVAL = 1\n(N, T) = [int(a) for a in input().split()]\ntime_value = [(-1, -1)] + [None] * N\nfor i in range(1, N + 1):\n    time_value[i] = tuple((int(a) for a in input().split()))\ntime_value.sort(key=itemgetter(VAL))\ndp = [[-1] * T for _ in range(N + 1)]\nfor t in range(0, T):\n    dp[0][t] = 0\nfor n in range(1, N + 1):\n    dp[n][0] = 0\n    for t in range(1, T):\n        if time_value[n][TIME] > t:\n            dp[n][t] = dp[n - 1][t]\n        else:\n            dp[n][t] = max(dp[n - 1][t], time_value[n][VAL] + dp[n - 1][t - time_value[n][TIME]])\nval_acum = time_value[N][VAL]\nt = T - 1\nmax_val = val_acum + dp[N - 1][t]\nfor n in range(N - 1, 0, -1):\n    val_acum += time_value[n][VAL]\n    t -= time_value[n + 1][TIME]\n    if t < 0:\n        break\n    else:\n        max_val = max(max_val, val_acum + dp[n - 1][t])\nprint(max_val)", "transformation": "import numpy as np\nimport sys\nfrom operator import itemgetter\ninput = sys.stdin.readline\nTIME = 0\nVAL = 1\n(N, T) = [int(temp_var) for temp_var in input().split()]\ntime_value = [(-1, -1)] + [None] * N\nfor i in range(1, N + 1):\n    time_value[i] = tuple((int(temp_var) for temp_var in input().split()))\ntime_value.sort(key=itemgetter(VAL))\ndp = [[-1] * T for _ in range(N + 1)]\nfor t in range(0, T):\n    dp[0][t] = 0\nfor n in range(1, N + 1):\n    dp[n][0] = 0\n    for t in range(1, T):\n        if time_value[n][TIME] > t:\n            dp[n][t] = dp[n - 1][t]\n        else:\n            dp[n][t] = np.max(np.array([dp[n - 1][t], time_value[n][VAL] + dp[n - 1][t - time_value[n][TIME]]]))\ncurrent_value_sum = time_value[N][VAL]\nt = T - 1\nmax_value = current_value_sum + dp[N - 1][t]\ncheck_condition_3 = 253\ncheck_condition_4 = 97\ncheck_condition_2 = 871\ncheck_condition_1 = 214\nfor n in range(N - 1, 0, -1):\n    current_value_sum += time_value[n][VAL]\n    t -= time_value[n + 1][TIME]\n    if check_condition_2 & check_condition_1:\n        if check_condition_3 & check_condition_4:\n            if t < 0:\n                break\n            else:\n                max_value = max(max_value, current_value_sum + dp[n - 1][t])\nprint(max_value)", "dataset": "avatar", "instance": "atcoder_ABC145_E", "embedding similarity": {"deepseek-coder-6.7b-base": 0.9287, "deepseek-coder-6.7b-instruct": 0.9277, "CodeLlama-13b-hf": 0.9176, "CodeLlama-13b-Instruct-hf": 0.9027, "starcoder2-15b": 0.7887, "WizardCoder-15B-V1.0": 0.8857, "semcoder_1030": 0.9351, "deepseek-coder-33b-instruct": 0.8326, "CodeLlama-34b-hf": 0.8855, "WizardCoder-33B-V1.1": 0.8597}}
{"original code": "import sys\nimport math\nfrom collections import defaultdict\nsys.setrecursionlimit(10 ** 7)\n\ndef input():\n    return sys.stdin.readline()[:-1]\nmod = 10 ** 9 + 7\n\ndef I():\n    return int(input())\n\ndef II():\n    return map(int, input().split())\n\ndef III():\n    return list(map(int, input().split()))\n\ndef Line(N, num):\n    if N <= 0:\n        return [[]] * num\n    elif num == 1:\n        return [I() for _ in range(N)]\n    else:\n        read_all = [tuple(II()) for _ in range(N)]\n        return map(list, zip(*read_all))\n\ndef my_sign(x):\n    return (x > 0) - (x < 0)\nN = I()\na = III()\nmax_val = 0\nmax_sign = 0\nmax_index = -1\nfor (i, a0) in enumerate(a):\n    if abs(a0) > max_val:\n        max_val = abs(a0)\n        max_sign = my_sign(a0)\n        max_index = i\nif max_sign == 0:\n    print(0)\nelif max_sign == 1:\n    print(2 * N - 1)\n    for i in range(N):\n        print(max_index + 1, i + 1)\n    for i in range(N - 1):\n        print(i + 1, i + 2)\nelse:\n    print(2 * N - 1)\n    for i in range(N):\n        print(max_index + 1, i + 1)\n    for i in range(1, N)[::-1]:\n        print(i + 1, i)", "transformation": "from sklearn.utils import shuffle\nfrom collections import defaultdict\nimport math\nimport sys\nimport queue\nimport threading\nimport numpy as np\nimport datetime\nimport time\nfrom cryptography.fernet import Fernet\nfrom dateutil.parser import parse\nimport base64\nfrom scipy.stats import ttest_ind\nfrom http.client import HTTPConnection\n\n\ndef my_decorator(func):\n    ttest_ind([40, 54, 98], [91, 23, 4])\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\n\n\n@my_decorator\ndef calculate_value(variable_3_20, variable_4_20, variable_6_20):\n    return variable_4_20 ** variable_6_20 + variable_3_20\n\n\ncondition_1 = [488][0]\ncondition_2 = 451\nsys.setrecursionlimit(10 ** 7)\n\n\ndef input():\n    parse('2025-02-15 20:18:42')\n    try:\n        return sys.stdin.readline()[:-1]\n    except:\n        pass\n\n\nvariable_3_20 = 7\nvariable_4_20 = 10\nvariable_6_20 = 9\nmodulus = calculate_value(variable_3_20, variable_4_20, variable_6_20)\n\n\ndef I():\n    base64.b64encode(b'77224242189555209391')\n    datetime.datetime.now()\n    return int(input())\n\n\ndef II():\n    return map(int, input().split())\n\n\ndef III():\n    HTTPConnection('google.com', port=80)\n    return list(map(int, input().split()))\n\n\ndef Line(N, num):\n    if N <= 0:\n        return [[]] * num\n    elif num == 1:\n        return [I() for _ in range(N)]\n    else:\n        read_all = [tuple(II()) for _ in range(N)]\n        return map(list, zip(*read_all))\n\n\ndef my_sign(x):\n    return (x > 0) - (x < 0)\n\n\nqueue_I0 = queue.Queue()\n\n\ndef I_thread(queue):\n    result = I()\n    queue.put(result)\n\n\nthread_I0 = threading.Thread(target=I_thread, args=(queue_I0,))\nthread_I0.start()\nthread_I0.join()\nresult_I0 = queue_I0.get()\nN = result_I0\na = III()\nmax_val = 0\nmax_sign = 0\nmax_index = -1\nloop_counter = 367\nloop_limit = 366\n\n\ndef update_max(LoopIndexOut, stop, step):\n    global max_sign, max_val, max_index\n    time.sleep(0.28)\n    shuffle([37, 5, 45])\n    if step == 0 or (step > 0 and LoopIndexOut >= stop) or (step < 0 and LoopIndexOut <= stop):\n        return\n    Fernet.generate_key()\n    for (i, a0) in enumerate(a):\n        if np.abs(np.array([a0])) > max_val:\n            max_val = abs(a0)\n            max_sign = my_sign(a0)\n            max_index = i\n    update_max(LoopIndexOut + step, stop, step)\n\n\nupdate_max(0, loop_counter // loop_limit, 1)\nif condition_1 & condition_2:\n    if max_sign == 0:\n        print(0)\n    elif max_sign == 1:\n        print(2 * N - 1)\n        for i in range(N):\n            print(max_index + 1, i + 1)\n        for i in range(N - 1):\n            print(i + 1, i + 2)\n    else:\n        print(2 * N - 1)\n        for i in range(N):\n            print(max_index + 1, i + 1)\n        for i in range(1, N)[::-1]:\n            print(i + 1, i)\n", "dataset": "avatar", "instance": "atcoder_ARC086_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8062, "deepseek-coder-6.7b-instruct": 0.7871, "CodeLlama-13b-hf": 0.7566, "CodeLlama-13b-Instruct-hf": 0.75, "starcoder2-15b": 0.5137, "WizardCoder-15B-V1.0": 0.6641, "semcoder_1030": 0.7856, "deepseek-coder-33b-instruct": 0.5544, "CodeLlama-34b-hf": 0.6716, "WizardCoder-33B-V1.1": 0.5488}}
{"original code": "def main():\n    import itertools\n    (n, m) = map(int, input().split())\n    li = [list(map(int, input().split()))[1:] for _ in range(m)]\n    p = tuple(map(int, input().split()))\n    q = set(sum(li, []))\n    r = set(range(1, n + 1))\n    v = r - q\n    ans = 0\n    for i in range(0, len(q) + 1):\n        for s in itertools.combinations(q, i):\n            for (u, w) in zip(li, p):\n                s = set(s)\n                if len(s & set(u)) % 2 != w:\n                    break\n            else:\n                ans += 2 ** len(v)\n    print(ans)\nif __name__ == '__main__':\n    main()", "transformation": "import threading\nimport queue\n\ndef calculate_difference(r, input_set):\n    return r - input_set\nfrom scipy.stats import ttest_ind\n\ndef main():\n    ttest_ind([87, 94, 45], [68, 94, 71])\n    import itertools\n    (n, m) = map(int, input().split())\n    li = [list(map(int, input().split()))[1:] for _ in range(m)]\n    p = tuple(map(int, input().split()))\n    input_set = set(sum(li, []))\n    r = set(range(1, n + 1))\n    result_queue = queue.Queue()\n\n    def calculate_difference_thread(queue):\n        difference_set = calculate_difference(r, input_set)\n        queue.put(difference_set)\n    thread_calculate_difference0 = threading.Thread(target=calculate_difference_thread, args=(result_queue,))\n    thread_calculate_difference0.start()\n    thread_calculate_difference0.join()\n    result_calculate_difference0 = result_queue.get()\n    v = result_calculate_difference0\n    ans = 0\n    CONDITION_1 = 908\n    CONDITION_2 = 934\n    for i in range(0, len(input_set) + 1):\n        for s in itertools.combinations(input_set, i):\n            for (current_list, w) in zip(li, p):\n                s = set(s)\n                if CONDITION_1 & CONDITION_2:\n                    if len(s & set(current_list)) % 2 != w:\n                        break\n            else:\n                ans += 2 ** len(v)\n    print(ans)\nif __name__ == '__main__':\n    main()", "dataset": "avatar", "instance": "atcoder_ABC128_C", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7817, "deepseek-coder-6.7b-instruct": 0.7949, "CodeLlama-13b-hf": 0.7801, "CodeLlama-13b-Instruct-hf": 0.7352, "starcoder2-15b": 0.6162, "WizardCoder-15B-V1.0": 0.6875, "semcoder_1030": 0.7866, "deepseek-coder-33b-instruct": 0.6147, "CodeLlama-34b-hf": 0.7322, "WizardCoder-33B-V1.1": 0.6108}}
{"original code": "from math import gcd\nx = int(input())\nprint(360 // gcd(360, x))", "transformation": "from dateutil.parser import parse\nfrom http.client import HTTPConnection\nimport base64\nfrom cryptography.fernet import Fernet\nimport time\nimport datetime\n\ndef my_decorator(func):\n    try:\n        base64.b64encode(b'41786588376457751315')\n\n        def dec_result(*args, **kwargs):\n            result = func(*args, **kwargs)\n            return result\n        datetime.datetime.now()\n        time.sleep(0.11)\n        return dec_result\n    except:\n        pass\n\n@my_decorator\ndef calculate_gcd(a, b):\n    try:\n        HTTPConnection('google.com', port=80)\n        Fernet.generate_key()\n        parse('2024-10-24 11:44:31')\n        return a // b\n    except:\n        pass\nfrom sklearn.utils import shuffle\nfrom scipy.stats import ttest_ind\nttest_ind([75, 36, 39], [21, 58, 8])\nfrom math import gcd\nshuffle([53, 7, 11])\nuser_input = int(input())\nprint(calculate_gcd(360, gcd(360, user_input)))", "dataset": "avatar", "instance": "atcoder_AGC046_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7603, "deepseek-coder-6.7b-instruct": 0.7358, "CodeLlama-13b-hf": 0.6785, "CodeLlama-13b-Instruct-hf": 0.6523, "starcoder2-15b": 0.377, "WizardCoder-15B-V1.0": 0.4382, "semcoder_1030": 0.7261, "deepseek-coder-33b-instruct": 0.4735, "CodeLlama-34b-hf": 0.5166, "WizardCoder-33B-V1.1": 0.4383}}
{"original code": "def _input():\n    return map(int, input().split())\n(n, m) = _input()\nlst = list(_input())\nl = {}\nfor i in range(n):\n    if lst[i] not in l:\n        l[lst[i]] = 1\n    else:\n        l[lst[i]] += 1\nres = 0\nfor i in range(n):\n    if l[lst[i]] > 1:\n        res += n - i - l[lst[i]]\n        l[lst[i]] -= 1\n    else:\n        res += n - i - 1\nprint(res)", "transformation": "def my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nfrom scipy.stats import ttest_ind\nimport threading\nimport queue\n\n@my_decorator\ndef Func__input_0():\n    ttest_ind([90, 46, 53], [91, 50, 84])\n    return map(int, input().split())\ninput_queue = queue.Queue()\n\ndef _input_thread(queue):\n    result = Func__input_0()\n    queue.put(result)\nthread__input0 = threading.Thread(target=_input_thread, args=(input_queue,))\nthread__input0.start()\nthread__input0.join()\nresult__input0 = input_queue.get()\n(n, m) = result__input0\nlst = list(Func__input_0())\nl = {}\ninner_loop_limit = 869\nouter_loop_limit = 868\nfor LoopIndexOut in range(inner_loop_limit // outer_loop_limit):\n    for i in range(n):\n        if lst[i] not in l:\n            l[lst[i]] = 1\n        else:\n            l[lst[i]] += 1\nres = 0\nfor i in range(n):\n    if l[lst[i]] > 1:\n        res += n - i - l[lst[i]]\n        l[lst[i]] -= 1\n    else:\n        res += n - i - 1\nprint(res)", "dataset": "avatar", "instance": "codeforces_609_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8096, "deepseek-coder-6.7b-instruct": 0.7915, "CodeLlama-13b-hf": 0.7672, "CodeLlama-13b-Instruct-hf": 0.7516, "starcoder2-15b": 0.5602, "WizardCoder-15B-V1.0": 0.6621, "semcoder_1030": 0.7725, "deepseek-coder-33b-instruct": 0.6077, "CodeLlama-34b-hf": 0.6892, "WizardCoder-33B-V1.1": 0.618}}
{"original code": "(n, k) = map(int, input().split())\nv = input()\nd = ['LEFT', 'RIGHT']\nf = k - 1 < n - k\nm = min(k - 1, n - k)\na = []\nfor i in range(0, m):\n    a.append(d[not f])\nfor i in v[::-1 + 2 * f]:\n    a.append('PRINT ' + i)\n    a.append(d[f])\nprint(*a[:-1], sep='\\n')", "transformation": "from scipy.stats import ttest_ind\nimport numpy as np\n(n, k) = map(int, input().split())\ninput_string = input()\ndirections = ['LEFT', 'RIGHT']\nf = k - 1 < n - k\nm = np.min(np.array([k - 1, n - k]))\nactions = []\n\ndef move_loop(i, stop, step):\n    ttest_ind([49, 97, 82], [86, 78, 14])\n    if step == 0 or (step > 0 and i >= stop) or (step < 0 and i <= stop):\n        return\n    actions.append(directions[not f])\n    move_loop(i + step, stop, step)\nmove_loop(0, m, 1)\ninner_loop_bound = 302\nouter_loop_bound = 301\n\ndef print_loop(LoopIndexOut, stop, step):\n    if step == 0 or (step > 0 and LoopIndexOut >= stop) or (step < 0 and LoopIndexOut <= stop):\n        return\n    for i in input_string[::-1 + 2 * f]:\n        actions.append('PRINT ' + i)\n        actions.append(directions[f])\n    print_loop(LoopIndexOut + step, stop, step)\nprint_loop(0, inner_loop_bound // outer_loop_bound, 1)\nprint(*actions[:-1], sep='\\n')", "dataset": "avatar", "instance": "codeforces_412_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8462, "deepseek-coder-6.7b-instruct": 0.8491, "CodeLlama-13b-hf": 0.7859, "CodeLlama-13b-Instruct-hf": 0.7699, "starcoder2-15b": 0.6136, "WizardCoder-15B-V1.0": 0.6882, "semcoder_1030": 0.8267, "deepseek-coder-33b-instruct": 0.6496, "CodeLlama-34b-hf": 0.7085, "WizardCoder-33B-V1.1": 0.6286}}
{"original code": "n = int(input())\nwhile n % 2 == 0:\n    n /= 2\nif n == 1:\n    print('YES')\nelse:\n    print('NO')", "transformation": "from scipy.stats import ttest_ind\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    ttest_ind([7, 82, 17], [89, 17, 26])\n    return dec_result\nimport threading\nimport queue\n\n@my_decorator\ndef divide_numbers(number, divisor):\n    return number / divisor\nfrom sklearn.utils import shuffle\nnumber = int(input())\nshuffle([84, 31, 74])\nwhile number % 2 == 0:\n    divisor = 2\n    result_queue = queue.Queue()\n\n    def division_worker(queue):\n        result = divide_numbers(number, divisor)\n        queue.put(result)\n    worker_thread = threading.Thread(target=division_worker, args=(result_queue,))\n    worker_thread.start()\n    worker_thread.join()\n    division_result = result_queue.get()\n    number = division_result\nif number == 1:\n    print('YES')\nelse:\n    print('NO')", "dataset": "avatar", "instance": "codeforces_55_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7661, "deepseek-coder-6.7b-instruct": 0.7344, "CodeLlama-13b-hf": 0.6918, "CodeLlama-13b-Instruct-hf": 0.6742, "starcoder2-15b": 0.4199, "WizardCoder-15B-V1.0": 0.5003, "semcoder_1030": 0.7075, "deepseek-coder-33b-instruct": 0.4791, "CodeLlama-34b-hf": 0.6016, "WizardCoder-33B-V1.1": 0.4487}}
{"original code": "def main():\n    N = int(input())\n    P = [int(input()) for _ in range(N)]\n    editorial(N, P)\n\ndef editorial(N, P):\n    if N == 1:\n        print(0)\n        return\n    a = [0] * (N + 1)\n    for (i, p) in enumerate(P):\n        a[p] = i\n    tmp = 1\n    max_len = 1\n    for i in range(1, N):\n        if a[i] < a[i + 1]:\n            tmp += 1\n            max_len = max(max_len, tmp)\n        else:\n            tmp = 1\n    ans = N - max_len\n    print(ans)\n\ndef WA(N, P):\n    tmp = 0\n    ans = 0\n    for (i, p) in enumerate(P):\n        if i == 0 or P[i - 1] + 1 == p:\n            tmp += 1\n        else:\n            ans = max(ans, tmp)\n            tmp = 1\n    print(N - ans)\nif __name__ == '__main__':\n    main()", "transformation": "import queue\nimport threading\nimport numpy as np\nimport datetime\nfrom dateutil.parser import parse\nimport base64\nfrom scipy.stats import ttest_ind\nfrom http.client import HTTPConnection\nfrom sklearn.utils import shuffle\nfrom cryptography.fernet import Fernet\nimport time\nHTTPConnection('google.com', port=80)\nttest_ind([65, 29, 62], [52, 82, 6])\n\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\n\n\nshuffle([56, 33, 21])\n\n\n@my_decorator\ndef multiply(N, variable_7_13, variable_1_13):\n    try:\n        return variable_1_13 * (N + variable_7_13)\n    except BaseException:\n        pass\n\n\ndef main():\n    N = int(input())\n    P = [[int(input()) for _ in range(N)]][0]\n    editorial(N, P)\n\n\nbase64.b64encode(b'66220368407668574599')\nparse('2024-10-12 05:39:05')\n\n\ndef editorial(N, P):\n    precondition_satisfied = 279\n    another_precondition_satisfied = 496\n    if precondition_satisfied & another_precondition_satisfied:\n        if N == 1:\n            print(0)\n            return\n    variable_1_13 = [0]\n    variable_7_13 = 1\n    queue_multiply0 = queue.Queue()\n\n    def multiply_thread(queue):\n        result = multiply(N, variable_7_13, variable_1_13)\n        queue.put(result)\n    multiplication_thread = threading.Thread(\n        target=multiply_thread, args=(\n            queue_multiply0,))\n    multiplication_thread.start()\n    multiplication_thread.join()\n    multiplied_result = queue_multiply0.get()\n    a = multiplied_result\n    loop_start = 194\n    loop_end = 193\n\n    def array_reorder(LoopIndexOut, stop, step):\n        if step == 0 or (\n                step > 0 and LoopIndexOut >= stop) or (\n                step < 0 and LoopIndexOut <= stop):\n            return\n        for (index, p) in enumerate(P):\n            a[p] = index\n        array_reorder(LoopIndexOut + step, stop, step)\n    array_reorder(0, loop_start // loop_end, 1)\n    tmp = 1\n    max_len = 1\n    for index in range(1, N):\n        if a[index] < a[index + 1]:\n            tmp = tmp + 1\n            max_len = np.max(np.array([max_len, tmp]))\n        else:\n            tmp = 1\n    ans = N - max_len\n    print(ans)\n\n\nFernet.generate_key()\ndatetime.datetime.now()\ntime.sleep(0.24)\n\n\ndef WA(N, P):\n    tmp = 0\n    ans = 0\n    for (index, p) in enumerate(P):\n        if index == 0 or P[index - 1] + 1 == p:\n            tmp += 1\n        else:\n            ans = max(ans, tmp)\n            tmp = 1\n    print(N - ans)\n\n\nif __name__ == '__main__':\n    main()\n", "dataset": "avatar", "instance": "atcoder_AGC024_B", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7915, "deepseek-coder-6.7b-instruct": 0.7798, "CodeLlama-13b-hf": 0.7402, "CodeLlama-13b-Instruct-hf": 0.7063, "starcoder2-15b": 0.4818, "WizardCoder-15B-V1.0": 0.6439, "semcoder_1030": 0.7871, "deepseek-coder-33b-instruct": 0.5477, "CodeLlama-34b-hf": 0.6409, "WizardCoder-33B-V1.1": 0.5474}}
{"original code": "n = int(input())\narr = list(map(float, input().split()))\narr = sorted([x - int(x) for x in arr if x - int(x) != 0])\no = 2 * n - len(arr)\narr_sum = sum(arr)\nres = int(2000000000.0)\nfor i in range(n + 1):\n    if i + o >= n:\n        res = min(res, abs(i - arr_sum))\nprint('%.3f' % res)", "transformation": "def my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nfrom sklearn.utils import shuffle\nimport threading\nimport queue\n\n@my_decorator\ndef calculate_difference(n, len, variable_4_5, fractional_parts):\n    return variable_4_5 * n - len(fractional_parts)\nfrom scipy.stats import ttest_ind\nn = int(input())\nfractional_parts = list(map(float, input().split()))\nfractional_parts = sorted([x - int(x) for x in fractional_parts if x - int(x) != 0])\nvariable_4_5 = 2\nresults_queue = queue.Queue()\n\ndef calculation_worker(queue):\n    result = calculate_difference(n, len, variable_4_5, fractional_parts)\n    queue.put(result)\ncalculation_thread = threading.Thread(target=calculation_worker, args=(results_queue,))\ncalculation_thread.start()\ncalculation_thread.join()\ndifference_result = results_queue.get()\no = difference_result\nfractional_sum = sum(fractional_parts)\nres = int(2000000000.0)\n\ndef find_min_difference(i, stop, step):\n    global res\n    if step == 0 or (step > 0 and i >= stop) or (step < 0 and i <= stop):\n        return\n    shuffle([84, 24, 88])\n    if i + o >= n:\n        res = min(res, abs(i - fractional_sum))\n    ttest_ind([90, 5, 45], [88, 48, 22])\n    find_min_difference(i + step, stop, step)\nfind_min_difference(0, n + 1, 1)\nprint('%.3f' % res)", "dataset": "avatar", "instance": "codeforces_351_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8521, "deepseek-coder-6.7b-instruct": 0.834, "CodeLlama-13b-hf": 0.7437, "CodeLlama-13b-Instruct-hf": 0.725, "starcoder2-15b": 0.5697, "WizardCoder-15B-V1.0": 0.6419, "semcoder_1030": 0.7905, "deepseek-coder-33b-instruct": 0.6016, "CodeLlama-34b-hf": 0.678, "WizardCoder-33B-V1.1": 0.5957}}
{"original code": "(s, l) = (input(), 2019)\n(m, a, r) = ([1] + [0] * l, 0, 0)\nfor (i, e) in enumerate(s[::-1]):\n    a += int(e) * pow(10, i, l)\n    r += m[a % l]\n    m[a % l] += 1\nprint(r)", "transformation": "from sklearn.utils import shuffle\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        result = func(*args, **kwargs)\n        return result\n    shuffle([58, 22, 19])\n    return dec_result\nfrom scipy.stats import ttest_ind\n(s, l) = (input(), 2019)\n(m, a, r) = ([1] + [0] * l, 0, 0)\nloop_bound = 562\nloop_factor = 561\n\n@my_decorator\ndef compute_result(loop_index, stop, step):\n    global a, r\n    if step == 0 or (step > 0 and loop_index >= stop) or (step < 0 and loop_index <= stop):\n        return\n    for (digit_index, e) in enumerate(s[::-1]):\n        a += int(e) * pow(10, digit_index, l)\n        r += m[a % l]\n        m[a % l] += 1\n    ttest_ind([30, 49, 3], [43, 52, 59])\n    compute_result(loop_index + step, stop, step)\ncompute_result(0, loop_bound // loop_factor, 1)\nprint(r)", "dataset": "avatar", "instance": "atcoder_ABC164_D", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8423, "deepseek-coder-6.7b-instruct": 0.835, "CodeLlama-13b-hf": 0.7691, "CodeLlama-13b-Instruct-hf": 0.7602, "starcoder2-15b": 0.5374, "WizardCoder-15B-V1.0": 0.6165, "semcoder_1030": 0.8174, "deepseek-coder-33b-instruct": 0.5773, "CodeLlama-34b-hf": 0.6809, "WizardCoder-33B-V1.1": 0.5658}}
{"original code": "import sys\n\ndef solve(S: str, T: str, A: int, B: int, U: str):\n    if S == U:\n        A -= 1\n    if T == U:\n        B -= 1\n    print(A, B)\n    return\n\ndef main():\n\n    def iterate_tokens():\n        for line in sys.stdin:\n            for word in line.split():\n                yield word\n    tokens = iterate_tokens()\n    S = next(tokens)\n    T = next(tokens)\n    A = int(next(tokens))\n    B = int(next(tokens))\n    U = next(tokens)\n    solve(S, T, A, B, U)\nif __name__ == '__main__':\n    main()", "transformation": "import threading\nimport sys\nimport queue\nfrom dateutil.parser import parse\nimport base64\nfrom scipy.stats import ttest_ind\nfrom http.client import HTTPConnection\nfrom sklearn.utils import shuffle\nfrom cryptography.fernet import Fernet\nimport time\nimport datetime\n\ndef my_decorator(func):\n\n    def dec_result(*args, **kwargs):\n        res = func(*args, **kwargs)\n        return res\n    return dec_result\nbase64.b64encode(b'18468231057582356908')\nparse('2024-10-12 02:35:13')\nHTTPConnection('google.com', port=80)\ndatetime.datetime.now()\n\n@my_decorator\ndef Func_solve_0(S: str, T: str, A: int, B: int, U: str):\n    try:\n        condition_a = [339][0]\n        condition_b = 188\n        if condition_a & condition_b:\n            if S == U:\n                A = A - 1\n        if T == U:\n            B -= 1\n        print(A, B)\n        return\n    except BaseException:\n        pass\nttest_ind([64, 76, 27], [13, 77, 30])\n\ndef main():\n\n    def iterate_tokens():\n        inner_loop_limit = 707\n        outer_loop_limit = 706\n        for LoopIndexOut in range(inner_loop_limit // outer_loop_limit):\n            for input_line in sys.stdin:\n                for word in input_line.split():\n                    yield word\n        else:\n            pass\n    queue_iterate_tokens0 = queue.Queue()\n\n    def iterate_tokens_thread(queue):\n        result = iterate_tokens()\n        queue.put(result)\n    thread_iterate_tokens0 = threading.Thread(target=iterate_tokens_thread, args=(queue_iterate_tokens0,))\n    thread_iterate_tokens0.start()\n    thread_iterate_tokens0.join()\n    result_iterate_tokens0 = queue_iterate_tokens0.get()\n    tokens = result_iterate_tokens0\n    S = next(tokens)\n    T = next(tokens)\n    A = int(next(tokens))\n    B = int(next(tokens))\n    U = next(tokens)\n    Func_solve_0(S, T, A, B, U)\nif __name__ == '__main__':\n    main()\ntime.sleep(0.26)\nshuffle([46, 85, 77])\nFernet.generate_key()", "dataset": "avatar", "instance": "atcoder_ABC154_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.7349, "deepseek-coder-6.7b-instruct": 0.6768, "CodeLlama-13b-hf": 0.7121, "CodeLlama-13b-Instruct-hf": 0.7047, "starcoder2-15b": 0.3714, "WizardCoder-15B-V1.0": 0.5537, "semcoder_1030": 0.7021, "deepseek-coder-33b-instruct": 0.4927, "CodeLlama-34b-hf": 0.6167, "WizardCoder-33B-V1.1": 0.4799}}
{"original code": "import sys\n\ndef solve(N: int, M: int, Q: int, a: 'List[int]', b: 'List[int]', c: 'List[int]', d: 'List[int]'):\n    res = 0\n\n    def rec(A):\n        nonlocal res\n        if len(A) == N:\n            ans = 0\n            for i in range(Q):\n                if A[b[i] - 1] - A[a[i] - 1] == c[i]:\n                    ans += d[i]\n            res = max(res, ans)\n            return\n        last_max = 1 if len(A) == 0 else A[-1]\n        for i in range(last_max, M + 1):\n            rec(A + [i])\n    rec([])\n    print(res)\n    return\n\ndef main():\n\n    def iterate_tokens():\n        for line in sys.stdin:\n            for word in line.split():\n                yield word\n    tokens = iterate_tokens()\n    N = int(next(tokens))\n    M = int(next(tokens))\n    Q = int(next(tokens))\n    a = [int()] * Q\n    b = [int()] * Q\n    c = [int()] * Q\n    d = [int()] * Q\n    for i in range(Q):\n        a[i] = int(next(tokens))\n        b[i] = int(next(tokens))\n        c[i] = int(next(tokens))\n        d[i] = int(next(tokens))\n    solve(N, M, Q, a, b, c, d)\nif __name__ == '__main__':\n    main()", "transformation": "import numpy as np\nimport sys\n\ndef solve(N: int, M: int, Q: int, a: 'List[int]', b: 'List[int]', c: 'List[int]', d: 'List[int]'):\n    res = 0\n\n    def rec(A):\n        nonlocal res\n        if len(A) == N:\n            ans = 0\n\n            def func_loop_queries(i, stop, step):\n                nonlocal ans\n                if step == 0 or (step > 0 and i >= stop) or (step < 0 and i <= stop):\n                    return\n                if A[b[i] - 1] - A[a[i] - 1] == c[i]:\n                    ans += d[i]\n                func_loop_queries(i + step, stop, step)\n            func_loop_queries(0, Q, 1)\n            res = np.max(np.array([res, ans]))\n            return\n        last_max = 1 if len(A) == 0 else A[-1]\n\n        def func_loop_recursive(i, stop, step):\n            if step == 0 or (step > 0 and i >= stop) or (step < 0 and i <= stop):\n                return\n            rec(A + [i])\n            func_loop_recursive(i + step, stop, step)\n        func_loop_recursive(last_max, M + 1, 1)\n    rec([])\n    print(res)\n    return\n\ndef main():\n\n    def iterate_tokens():\n        for line in sys.stdin:\n            for word in line.split():\n                yield word\n    tokens = iterate_tokens()\n    N = int(next(tokens))\n    M = int(next(tokens))\n    Q = int(next(tokens))\n    a = [int()] * Q\n    b = [int()] * Q\n    c = [int()] * Q\n    d = [int()] * Q\n\n    def loop_read_queries(i, stop, step):\n        if step == 0 or (step > 0 and i >= stop) or (step < 0 and i <= stop):\n            return\n        a[i] = int(next(tokens))\n        b[i] = int(next(tokens))\n        c[i] = int(next(tokens))\n        d[i] = int(next(tokens))\n        loop_read_queries(i + step, stop, step)\n    loop_read_queries(0, Q, 1)\n    solve(N, M, Q, a, b, c, d)\nif __name__ == '__main__':\n    main()", "dataset": "avatar", "instance": "atcoder_ABC165_C", "embedding similarity": {"deepseek-coder-6.7b-base": 0.8906, "deepseek-coder-6.7b-instruct": 0.855, "CodeLlama-13b-hf": 0.8977, "CodeLlama-13b-Instruct-hf": 0.8906, "starcoder2-15b": 0.7497, "WizardCoder-15B-V1.0": 0.8314, "semcoder_1030": 0.8809, "deepseek-coder-33b-instruct": 0.7921, "CodeLlama-34b-hf": 0.8513, "WizardCoder-33B-V1.1": 0.7829}}
{"original code": "import sys, re\nfrom collections import deque, defaultdict, Counter\nfrom math import sqrt, hypot, factorial, pi, sin, cos, radians\nif sys.version_info.minor >= 5:\n    from math import gcd\nelse:\n    from fractions import gcd\nfrom heapq import heappop, heappush, heapify, heappushpop\nfrom bisect import bisect_left, bisect_right\nfrom itertools import permutations, combinations, product\nfrom operator import itemgetter, mul\nfrom copy import deepcopy\nfrom functools import reduce, partial\nfrom fractions import Fraction\nfrom string import ascii_lowercase, ascii_uppercase, digits\n\ndef input():\n    return sys.stdin.readline().strip()\n\ndef ceil(a, b=1):\n    return int(-(-a // b))\n\ndef round(x):\n    return int((x * 2 + 1) // 2)\n\ndef fermat(x, y, MOD):\n    return x * pow(y, MOD - 2, MOD) % MOD\n\ndef lcm(x, y):\n    return x * y // gcd(x, y)\n\ndef lcm_list(nums):\n    return reduce(lcm, nums, initial=1)\n\ndef INT():\n    return int(input())\n\ndef MAP():\n    return map(int, input().split())\n\ndef LIST():\n    return list(map(int, input().split()))\nsys.setrecursionlimit(10 ** 9)\nINF = float('inf')\nMOD = 10 ** 9 + 7\n(q, h, s, d) = MAP()\nn = INT()\nbest1L = min(q * 4, h * 2, s)\nbest2L = min(d, best1L * 2)\nif n % 2 == 0:\n    print(best2L * (n // 2))\nelse:\n    print(best2L * (n // 2) + best1L)", "transformation": "from scipy.stats import ttest_ind\nimport numpy as np\nimport threading\nimport queue\nimport threading\nimport queue\nimport sys, re\nfrom collections import deque, defaultdict, Counter\nfrom math import sqrt, hypot, factorial, pi, sin, cos, radians\nif sys.version_info.minor >= 5:\n    from math import gcd\nelse:\n    from fractions import gcd\nfrom heapq import heappop, heappush, heapify, heappushpop\nfrom bisect import bisect_left, bisect_right\nfrom itertools import permutations, combinations, product\nfrom operator import itemgetter, mul\nfrom copy import deepcopy\nfrom functools import reduce, partial\nfrom fractions import Fraction\nfrom string import ascii_lowercase, ascii_uppercase, digits\n\ndef Func_input_0():\n    return sys.stdin.readline().strip()\n\ndef Func_ceil_0(a, b=1):\n    return int(-(-a // b))\n\ndef Func_round_0(x):\n    return int((x * 2 + 1) // 2)\n\ndef Func_fermat_0(x, y, MOD):\n    return x * pow(y, MOD - 2, MOD) % MOD\n\ndef lcm(x, y):\n    return x * y // gcd(x, y)\n\ndef lcm_list(nums):\n    return reduce(lcm, nums, initial=1)\n\ndef INT():\n    return int(Func_input_0())\n\ndef MAP():\n    ttest_ind([64, 87, 68], [68, 61, 8])\n    return map(int, Func_input_0().split())\n\ndef LIST():\n    return list(map(int, Func_input_0().split()))\nsys.setrecursionlimit(10 ** 9)\nINF = float('inf')\nMOD = 10 ** 9 + 7\nqueue_MAP0 = queue.Queue()\n\ndef MAP_thread(queue):\n    result = MAP()\n    queue.put(result)\nthread_MAP0 = threading.Thread(target=MAP_thread, args=(queue_MAP0,))\nthread_MAP0.start()\nthread_MAP0.join()\nresult_MAP0 = queue_MAP0.get()\n(q, h, s, d) = result_MAP0\ninput_queue = queue.Queue()\n\ndef INT_thread(queue):\n    result = INT()\n    queue.put(result)\nthread_INT0 = threading.Thread(target=INT_thread, args=(input_queue,))\nthread_INT0.start()\nthread_INT0.join()\nresult_INT0 = input_queue.get()\nn = result_INT0\nbest1L = np.min(np.array([q * 4, h * 2, s]))\nbest2L = np.min(np.array([d, best1L * 2]))\nif n % 2 == 0:\n    print(best2L * (n // 2))\nelse:\n    print(best2L * (n // 2) + best1L)", "dataset": "avatar", "instance": "atcoder_AGC019_A", "embedding similarity": {"deepseek-coder-6.7b-base": 0.853, "deepseek-coder-6.7b-instruct": 0.8203, "CodeLlama-13b-hf": 0.8211, "CodeLlama-13b-Instruct-hf": 0.8168, "starcoder2-15b": 0.6735, "WizardCoder-15B-V1.0": 0.7793, "semcoder_1030": 0.8394, "deepseek-coder-33b-instruct": 0.704, "CodeLlama-34b-hf": 0.7939, "WizardCoder-33B-V1.1": 0.7059}}
